{
  "https://github.com/isl-org/OpenBot/blob/master/README.md": {
    "summary": "OpenBot turns smartphones into robot brains, featuring an affordable electric vehicle body and advanced robotics software that supports person following and autonomous navigation. Instructions for building the robot body, installing software, and programming are provided. Showcase projects highlight various applications of OpenBot. Users can access community support via Slack and email, and contributions are welcome. A research paper for citation is available.",
    "content": "<a href=\"https://www.openbot.org/\" target=\"_blank\">\n  <img align=\"center\" alt=\"Banner\" width=\"100%\" src=\"docs/images/banner.jpg\" />\n</a>\n\n<h1 align=\"center\"><a>Turning Smartphones into Robots</a></h1>\n\n<p align=\"center\">\n   <img alt=\"GitHub build\" src=\"https://img.shields.io/github/actions/workflow/status/isl-org/OpenBot/gradle.yml?branch=master\"></a>\n   <img alt=\"GitHub issues\" src=\"https://img.shields.io/github/issues/isl-org/OpenBot\"></a>\n   <img alt=\"GitHub pull requests\" src=\"https://img.shields.io/github/issues-pr/isl-org/OpenBot\"></a>\n   <img alt=\"GitHub forks\" src=\"https://img.shields.io/github/forks/isl-org/OpenBot\"></a>\n   <img alt=\"GitHub stars\" src=\"https://img.shields.io/github/stars/isl-org/OpenBot\"></a>\n   <img alt=\"Github downloads\" src=\"https://img.shields.io/github/downloads/isl-org/OpenBot/total\"></a>\n   <img alt=\"Github size\" src=\"https://img.shields.io/github/repo-size/isl-org/OpenBot\"></a>\n   <img alt=\"Github license\" src=\"https://img.shields.io/github/license/isl-org/OpenBot\"></a>\n</p>\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nOpenBot leverages smartphones as brains for low-cost robots. We have designed a small electric vehicle that costs about $50 and serves as a robot body. Our software stack for Android smartphones supports advanced robotics workloads such as person following and real-time autonomous navigation.\n\n## Get started with OpenBot\n\n- Read the [Disclaimer](DISCLAIMER.md)\n- Build your own [Robot Body](body/README.md)\n- Flash the [Arduino Firmware](firmware/README.md)\n- Install the [Android Apps](android/README.md)\n- Drive the robot via a [Controller](controller/README.md)\n- Program your robot in the [Playground](open-code/README.md)\n- Train your own [Driving Policy](policy/README.md)\n\n## Get the source code\n\n- You can download the repo as a [zip file](https://github.com/intel-isl/OpenBot/archive/master.zip) and extract it into a folder of your choice.\n- You can clone the OpenBot repository from GitHub with the following command:\n    ```bash\n    git clone https://github.com/intel-isl/OpenBot.git\n    ```\n- You can fork the OpenBot repository and then clone your local copy. This is recommended, especially if you want to [contribute](CONTRIBUTING.md).\n\n## Videos\n\n<a href=\"https://www.youtube.com/watch?v=RbzPXywJifA\" >\n  <img align=\"center\" width=\"300\" alt=\"youtube video\" src=\"https://img.youtube.com/vi/RbzPXywJifA/hqdefault.jpg\" />\n</a>\n\n<a href=\"https://www.youtube.com/watch?v=qc8hFLyWDOM\" >\n  <img align=\"center\" width=\"300\" alt=\"youtube video\" src=\"https://img.youtube.com/vi/qc8hFLyWDOM/hqdefault.jpg\" />\n</a>\n\n## Cool projects using OpenBot\n\nThere are a lot of cool projects using OpenBot already. Below is a small selection. Click on the images to be redirected to the respective projects.\n\n<p float=\"left\">\n  <a href=\"https://www.thingiverse.com/thing:4670884\" target=\"_blank\">\n    <img alt=\"Tank OpenBot\" width=\"24%\" src=\"docs/images/openbot_tank.jpg\" />\n  </a>\n  <a href=\"https://diyrobocars.com/2020/12/14/an-improved-version-of-the-intel-openbot\" target=\"_blank\">\n    <img alt=\"2WD OpenBot\" width=\"24%\" src=\"docs/images/openbot_2wd.jpg\" />\n  </a>\n  <a href=\"https://custom-build-robots.com/raspberry-pi-robot-cars/openbot-your-smartphone-controls-a-robot-car-introduction/13860?lang=en\" target=\"_blank\">\n    <img alt=\"Cardboard OpenBot\" width=\"24%\" src=\"docs/images/chassis_cardboard_1.jpg\" />\n  </a>\n  <a href=\"https://www.youtube.com/watch?v=PEj8jWapGt4\" target=\"_blank\">\n    <img alt=\"Baby Yoda OpenBot\" width=\"24%\" src=\"docs/images/openbot_yoda.jpg\" />\n  </a>\n</p>\n\n## Contact\n\n- Join our [Slack](https://join.slack.com/t/openbot-community/shared_invite/zt-jl8ygxqt-WNRNi9yzh7Lu60qui6Nh6w) channel to connect with the OpenBot community.\n- Contact us via [Email](mailto:openbot.team@gmail.com)\n\n## Contribute\n\nPlease read the [contribution guidelines](CONTRIBUTING.md). If you are not sure where to start have a look at the [open issues](https://github.com/intel-isl/OpenBot/issues).\n\n## Citation\n\nPlease cite our [paper](https://arxiv.org/abs/2008.10631) if you use OpenBot.\n\n```bib\n@inproceedings{mueller2021openbot,\n    title     = {OpenBot: Turning Smartphones into Robots},\n    author    = {M{\\\"u}ller, Matthias and Koltun, Vladlen},\n    booktitle = {Proceedings of the International Conference on Robotics and Automation (ICRA)},\n    year = {2021},\n}\n```\n\n<a href=\"https://www.openbot.org//\" target=\"_blank\">\n  <img align=\"center\" alt=\"Footer\" width=\"100%\" src=\"docs/images/footer.gif\" />\n</a>\n"
  },
  "https://github.com/isl-org/OpenBot/blob/master/android/README.md": {
    "summary": "This README provides instructions for Android apps development within the OpenBot project. It covers features and installation methods for the Robot and Controller apps. To build the apps, users require Android Studio, an Android device, and specific SDK versions. The detailed build process includes Gradle synchronization, USB debugging setup, and running instructions. Troubleshooting tips are also provided for version compatibility issues.",
    "content": "# Android Apps\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n## Features\n\nClick on the links below to read about the features of the apps.\n\n- [Robot App](robot/README.md)\n- [Controller App](controller/README.md)\n\n## Install the apps\n\nThe easiest way to get either of the apps is to download it directly to the phone using the corresponding QR code. If you are on the phone browser, you can also just click on the QR code. You can then open the apk on your phone and [install](https://www.lifewire.com/install-apk-on-android-4177185) it. Note that the apk is only signed with a debug key.\n\n<table style=\"width:100%;border:none;text-align:center\">\n  <tr>\n    <td>  <a href=\"https://app.openbot.org/robot\" target=\"_blank\">\n    <img alt=\"ðŸ¤– App\" width=\"50%\" src=\"../docs/images/robot_app_qr_code.png\" />\n  </a>\n    </td>\n    <td>\n  <a href=\"https://app.openbot.org/controller\" target=\"_blank\">\n    <img alt=\"ðŸŽ® App\" width=\"50%\" src=\"../docs/images/controller_app_qr_code.png\" />\n  </a>\n      </td>\n  </tr>\n  <tr>\n    <td>ðŸ¤– App</td>\n    <td>ðŸŽ® App</td>\n  </tr>\n</table>\n\n\nAlternatively, you can download the apks from the assets of any [release](https://github.com/intel-isl/OpenBot/releases). If you want the latest app from the master branch, you can also download it from the build artifacts [here](https://github.com/intel-isl/OpenBot/actions?query=workflow%3A%22Java+CI+with+Gradle%22). Note, that it may not be stable. If you would like to make changes to the app later, follow the steps below to compile the app and deploy it on your phone.\n\n## Build the apps\n\n### Prerequisites\n\n- [Android Studio Electric Eel | 2022.1.1 or later](https://developer.android.com/studio/index.html) for building and installing the apks.\n- Android device and Android development environment with minimum API 21.\n- Currently, we use API 33 as compile SDK and API 32 as target SDK. It should get installed automatically, but if not you can install the SDK manually. Go to Android Studio -> Preferences -> Appearance & Behaviour -> System Settings -> Android SDK. Make sure API 33 is checked and click apply.\n\n![Android SDK](../docs/images/android_studio_sdk.jpg)\n\n### Build process\n\n1. Open Android Studio and select *Open an existing Android Studio project*.\n2. Select the OpenBot/android directory and click OK.\n3. If you want to install the [OpenBot app](app/README.md) make sure to select the *app* configuration. If you want to install the [Controller app](controller/README.md), select the *controller* configuration. Confirm Gradle Sync if neccessary. To perform a Gradle Sync manually, click on the gradle icon.\n  ![Gradle Sync](../docs/images/android_studio_bar_gradle.jpg)\n4. Connect your Android device and make sure USB Debugging in the [developer options](https://developer.android.com/studio/debug/dev-options) is enabled. Depending on your development environment [further steps](https://developer.android.com/studio/run/device) might be necessary. You should see your device in the navigation bar at the top now.\n  ![Phone](../docs/images/android_studio_bar_phone.jpg)\n5. Click the Run button (the green arrow) or select Run > Run 'android' from the top menu. You may need to rebuild the project using Build > Rebuild Project.\n  ![Run](../docs/images/android_studio_bar_run.jpg)\n6. If it asks you to use Instant Run, click *Proceed Without Instant Run*.\n\n### Troubleshooting\n\n#### Versions\n\nIf you get a message like `The project is using an incompatible version (AGP 7.4.0) of the Android Gradle plugin. Latest supported version is AGP 7.3.0` you need to upgrade Android Studio or downgrade your gradle plugin. You can read more about the version compatablility between Android Studio and the gradle plugin [here](https://developer.android.com/studio/releases/gradle-plugin#android_gradle_plugin_and_android_studio_compatibility).\n\n"
  },
  "https://github.com/isl-org/OpenBot/blob/master/android/controller/README.md": {
    "summary": "This Android app is a remote controller for the OpenBot vehicle, providing similar functionality to PS3/4 or Xbox controllers. It establishes a connection with the robot's app, enabling control via tilt or on-screen sliders. The app features left/right turn indicators, a brake/accelerator system, and a full-screen \"tilt mode\" for accelerometer control. Future enhancements include sensor information display, video streaming, and gyroscope integration for enhanced control and crash/bump notifications.",
    "content": "# Controller App\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nThis Android app serves as a `remote controller` for the [OpenBot](https://www.openbot.org) vehicle.  Basically it performs similar function as PS3/4 or Xbox remote controller, but running on another Android device.\n\n## Connection\n\nWhen the controller app is started, it immediately tries to connect to the robot. We see the following screen:\n\n<p float=\"left\">\n  <img src=\"../../docs/images/controller_pre_connect.png\" width=\"50%\" />\n</p>\n\nTo connect the controller to the robot, place the robot's app control setting into the **Phone** mode.\n\n<p float=\"left\">\n  <img src=\"../../docs/images/app_controller_settings_1.png\" width=\"25%\" />\n  <img src=\"../../docs/images/app_controller_settings_2.png\" width=\"25%\" />\n</p>\n\nYou can also connect to the controller from the `FreeRoamFragment` by selecting the phone as the controller:\n\n<p float=\"left\">\n  <img src=\"../../docs/images/free-roam-fragment-selection.png\" width=\"50%\" />\n</p>\n\nIn a few seconds, you will hear a beep, and the controller will change its screen to:\n\n<p float=\"left\">\n  <img src=\"../../docs/images/controller_command_buttons.png\" width=\"50%\" />\n</p>\n\nHere you can select to drive the robot by tilting the phone, or by using the on-screen controls.\n\n***Note:*** This should be sufficient to connect, but if the connection cannot be established after 30 seconds, toggle the `Control` setting on the bot app to `Gamepad` and then to `Phone` again to re-initiate the connection. If that fails, exit the controller app and start it again. Toggle the Control mode again on the robot app.\n\n## Operation\n\n### On-screen controls\nThis mode allows the user to control the robot car via two sliders in `Dual Drive` mode. You can turn left/right by moving the slider thumb up and down on each side. The wheels on each side turn forward/backward when moving the thumb above/below the center of the slider.\n\n<p float=\"left\">\n  <img src=\"../../docs/images/controller_main_screen.png\" width=\"50%\" />\n</p>\n\nYou can also set the left/right turn indicators \n<img src=\"../../docs/images/keyboard_arrow_left-24px.svg\" height=\"24\"/> \n<img src=\"../../docs/images/keyboard_arrow_right-24px.svg\" height=\"24\"/> \nby clicking on the arrows on the top-left of the screen, and the red button between them to cancel.\n\n### Tilt to drive\nThe controller can also use its accelerometer motion sensor to drive the robot. If you select this option, the controller will enter a full-screen (Zen) mode with only the video showing and a `brake` and `accelerator` pedals. To exit this mode, double-tap on the screen.\n\nHere is a picture of the `tilt mode` screen:\n\n<p float=\"left\">\n  <img src=\"../../docs/images/tilt-mode-controller.jpg\" width=\"50%\" />\n</p>\n\nUse the `accelerator` and `brake` buttons to move forward/backward.\n\n- Pressing the `acceletator` will accelerate the robot to full speed within 2 seconds. When you release the button, the robot will slow down to a stop (stop speed set to 0% of the maximum speed, can be adjusted).\n- Pressing the `brake` button will immedately stop the robot. If we hold the brake for another second, the robot will start moving backwards until it reaches the maximim reverse speed in one second. When we let go of the brake, the robot will come to a stop.\n- We steer the robot by tilting the controller left or right.\n\n## Future Development\n\nSome of the features we are looking to add are:\n\n- Add information on the controller for more robot sensors, such as battery level and speed.\n- Video Stream from the robot's camera to the controller\n- Use controller's gyroscope sensor co control the robot\n- Send crash and bump events from the robot to the controller for a more realistic experience\n\nHere is a [Technical Overview](../../docs/technical/OpenBotController.pdf) of the controller app.\n"
  },
  "https://github.com/isl-org/OpenBot/blob/master/android/robot/README.md": {
    "summary": "**Robot App**\n\nThe Robot App is a mobile application for controlling and interacting with an OpenBot robot. The app offers various features, including:\n\n- Main Menu: Provides access to all available screens, including Settings, Free Roam, Data Collection, Controller Mapping, Robot Info, Autopilot, Object Tracking, Point Goal Navigation, Model Management, and more.\n\n- Settings Menu: Allows users to configure USB connection, Bluetooth settings, video streaming, and permissions.\n\n- Free Roam: Enables simple robot control with real-time updates and information on battery, speed, and distance from surfaces.\n\n- Data Collection: Provides a streamlined UI for collecting data sets for training machine learning models.\n\n- Controller Mapping: Displays the button and joystick mapping of a connected BT controller.\n\n- Robot Info: Shows robot information, such as type and capabilities, and allows control of basic functions.\n\n- Autopilot: Facilitates the execution of trained autopilot models on the robot.\n\n- Object Tracking: Enables tracking of objects from 80 different classes, with various model options and settings.\n\n- Point Goal Navigation: Specifies a goal for the robot to reach, using AI policies to navigate and avoid obstacles.\n\n- Model Management: Provides a list of available models, including information on performance and inference speed, and allows model downloads.\n\n- Benchmark: Compares the performance of various models on different phone devices, including FPS and mAP results.\n\n**Additional Notes:**\n\n- Safety warnings are provided to emphasize the importance of operating the robot in a safe environment.\n- The app is under development and may exhibit unexpected behavior.\n- The app supports communication via USB and Bluetooth connections.",
    "content": "# Robot App\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n## DISCLAIMERS\n\n1. **Safety:** Always make sure you operate in a safe environment. Keep in mind, that your phone could be damaged in a collision! Special care is necessary when using automated control (e.g. person following or driving policy). Make sure you always have a game controller connected and are familiar with the key mapping, so you can stop the vehicle at any time. Use at your own risk!\n2. **App under development:** The application is under development and may crash or exhibit unexpected behaviour depending on your phone model and version of the operating system. Make sure to test all functionalities with no wheels connected. Use at your own risk!\n\n## App Screens\n\n### Main Menu\n\nThe app starts with a menu screen that shows all available screens. The settings screen can be opened with a click on the icon at the top right corner. By clicking on the other icons the user can access various screens whose functionalities are explained in the following.\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_main.jpg\" alt=\"Main Menu\" width=\"21.6%\"/>\n<img src=\"../../docs/images/screen_settings.jpg\" alt=\"Settings Menu\" width=\"20%\"/>\n<img src=\"../../docs/images/dialog_stream_mode.jpg\" alt=\"Settings Menu\" width=\"20%\"/>\n<img src=\"../../docs/images/dialog_connectivity_mode.jpg\" alt=\"Settings Menu\" width=\"20%\"/>\n</p>\n\n### Settings Menu\n\n#### USB Connection\n\nTap the USB icon to open the USB options. The drop-down menu is used to set the baud rate. The default is 115200, and you should not need to change this unless you mess with the Arduino firmware. The app will attempt to connect automatically, but in case you encounter issues you can use this switch to disconnect/connect.\n\n<p align=\"left\">\n<img src=\"../../docs/images/usb_disconnected.jpg\" alt=\"Connecting device\" width=\"25%\"/>\n<img src=\"../../docs/images/usb_connected.jpg\" alt=\"Disconnect button\" width=\"25%\"/>\n</p>\n\n#### Permissions\n\nHere you can check the permissions of the app and adjust them if needed.\n\n#### Video Streaming\n\nYou can choose between `WebRTC` and `RTSP` for streaming video to an external device. The phone controller app and node-js server both need this to be set to `WebRTC`. The python controller expects the stream to be set to `RTSP`.\n\n#### Bluetooth connection\n\nMake sure that your Android device has BLE (Bluetooth Low Energy) support. If your Android version is greater than or equal to 7.0, you also need to turn on the location service and allow the location permission in the settings in order to search for nearby BLE devices. To enable BLE, change the connectivity mode from USB to Bluetooth in the settings menu. You will get a Bluetooth icon at the top of the home screen. Tap the Bluetooth icon to start BLE scanning; it takes 4 seconds to scan and get a list of all nearby OpenBot BLE devices. Connect with your OpenBot by tapping on the `Connect` button. After successful connection the `Connect` button will change to `Disconnect`. You can now go back to the Home screen.\n\n<p align=\"left\">\n<img src=\"../../docs/images/ble_devices_list.jpg\" alt=\"BLE devices\" width=\"25%\"/>\n<img src=\"../../docs/images/ble_device_connecting.jpg\" alt=\"Connecting device\" width=\"25%\"/>\n<img src=\"../../docs/images/ble_device_connected.jpg\" alt=\"Disconnect button\" width=\"25%\"/>\n</p>\n\n### Free Roam\n\nFree Roam offers simple robot control with real time updates and information about battery, speed and distance from surfaces.\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_free_roam.jpg\" alt=\"Free Roam\" width=\"50%\" />\n</p>\n\n- **Battery**: The battery icon shows realtime battery levels of the connected robot.\n- **Drive State**: There are 3 drive states displayed on the view:\n  - D -> Drive, when the robot is driving forward\n  - N -> Neutral, when the robot is stationary\n  - R -> Reverse, when the robot is moving backwards\n  The steering wheel rotates proportionally to the steering angle.\n- **Speed**: The speedometer shows the speed of the robot.\n- **Sonar**: The free distance in front of the robot in cm.\n- **Control**: Controller, Drive Mode and Speed are used to control robot settings as described in the [control section](#control).\n\n### Data Collection\n\nSimple UI for collection of data sets.\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_data_collection.jpg\" alt=\"Data Collection\" width=\"50%\" />\n</p>\n\n- **Server**: If you have the [web app](../../policy#web-app) for policy training running, you can select it here to automatically upload data.\n- **Preview Resolution**: Used to switch between resolutions of camera preview. There are 3 settings:\n  - ***FULL_HD*** (1920x1080p)\n  - ***HD*** (1280x720p)\n  - ***SD*** (640x360)\n- **Model Resolution**: Used to switch between resolutions of images saved for training different models.\n- **Save/Discard the Collected Data**: the data collection process can be controlled from the screen or remotely, for instance from a bluetooth controller. When using a bluetooth controller, you may:\n  - Press the **A button** to **start** the data collection process\n  - Press the **A button again** to **stop** data collection and save the collected data in a .zip file\n  - Alternatively press the **R1 button** to **stop** data collection **without saving** the collected data (for instance because of an unexpected collision with the environment)\n  - Remember to use the controller mapping fragment to ensure you are using the correct buttons.\n\n### Controller Mapping\n\nSimple UI to check the button and joystick mapping of a connected BT controller.\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_controller_mapping.jpg\" alt=\"Controller Mapping\" width=\"50%\" />\n</p>\n\n### Robot Info\n\nSimple UI to get robot info and test basic functionality. The **Robot Type** as configured in the firmware is displayed as text and animation. The checkmarks in the sections **Sensors**, **Wheel Odometry** and **LEDs** show which features are supported by the connected robot. The section **Readings** provides the most important sensor measurements. In the section **Send Commands**, users can send basic motor commands by pressing the corresponding buttons and control the front and rear LEDs with a slider.\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_robot_info.gif\" alt=\"Robot Info\" width=\"50%\" />\n</p>\n\n### Autopilot\n\nSimple UI for running autopilot models.\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_autopilot.jpg\" alt=\"Autopilot\" width=\"50%\" />\n</p>\n\n- **Server**: If you have the [web app](../../policy#web-app) for policy training running, you can select it here and send trained autopilot models to the robot.\n- **Model**: Choose a trained model to use for autopilot mode.\n- **Device**: Use CPU, GPU or NNAPI for inference (more details [here](#device)).\n- **Threads**: Number of threads to use (only makes a difference when CPU is selected as device).\n- **Control**: Controller, Drive Mode and Speed are used to control robot settings as described in the [control section](#control).\n\n### Object Tracking\n\nSimple UI for tracking objects of 80 different classes. A short description of the different AI models for object tracking and performance benchmarks can be found in [Model Management](#model-management).\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_object_tracking_1.jpg\" alt=\"Alt text\" width=\"49%\" />\n<img src=\"../../docs/images/screen_object_tracking_2.jpg\" alt=\"Alt text\" width=\"49%\" />\n</p>\n\n- **Dynamic Speed**: reduces the robot speed in \"Auto Mode\" if it gets closer to the tracked object.\n  The speed is scaled based on the area of the bounding box (works best in landscape orientation).\n- **Model**: Choose an object detector based on your phone performance (see below for [benchmarking results](#benchmark)).\n- **Object**: Pick the object you want to track. The models can detect the 80 COCO [object classes](https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/).\n- **Confidence**: Confidence threshold to determine if detections are accepted. Increase if you get false detections, decrease if the object of interest it not detected.\n- **Device**: Use CPU, GPU or NNAPI for inference (more details [here](#device)).\n- **Threads**: Number of threads to use (only makes a difference when CPU is selected as device).\n- **Control**: Controller, Drive Mode and Speed are used to control robot settings as described in the [control section](#control).\n\n\n### Point Goal Navigation\n\nNote that this fragment requires ARCore and camera permission. If your device does not support ARCore and you continue anyway, the app will crash. In this screen you can specify a goal via a 2D vector with respect to the current position and orientation of the robot. The 2D vector contains the distance to the front and left of the robot in meters. Both values can also be negative and correspond to back and right of the robot in that case. After specifying the goal and pressing `Start` the robot will exectue an AI policy that attempts to reach the goal while avoiding obstacles.\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_point_goal_nav.gif\" alt=\"Alt text\" width=\"50%\" />\n</p>\n\n### Model Management\n\nAll models are quantized for better performance on embedded devices. Please refer to section below for a short description of the available models and benchmarking results. The [mean Average Precision (mAP)](https://kharshit.github.io/blog/2019/09/20/evaluation-metrics-for-object-detection-and-segmentation) is computed on the validation set of the [COCO Detection 2017](https://cocodataset.org/#detection-2017) dataset. Each model is run for about 1 minute; the inference time is averaged across the last 100 frames and reported in frames per second (fps). Note that models with larger input resolution might be better for smaller objects despite lower mAP.\n\n<p align=\"left\">\n<img src=\"../../docs/images/screen_model_management.gif\" alt=\"Model Management\" width=\"25%\" />\n</p>\n\n### Benchmark\n\n#### Phones\n\n| Model Name       | Chipset        | RAM  | OS |\n|------------------|----------------|------|----|\n| Samsung S22 Ultra| Exynos 2200    | 12GB | 12 |\n| Samsung S20FE 5G | Snapdragon 865 |  6GB | 12 |\n| Huawei P30 Pro   | Kirin 980      |  8GB | 10 |\n| Google Pixel 6XL | Google Tensor  | 12GB | 12 |\n| Xiaomi Mi9       | Snapdragon 855 |  6GB | 10 |\n| Google Pixel 4XL | Snapdragon 855 |  6GB | 13 |\n\n#### MobileNetV1-300 (pre-installed) - mAP: 18%\n\nSSD object detector with [MobileNet V1](https://tfhub.dev/tensorflow/lite-model/ssd_mobilenet_v1/1/metadata/2) backbone and input resolution of 300x300.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra|  33 |  13 |   30  |\n| Samsung S20FE 5G |  34 |  57 |   87  |\n| Huawei P30 Pro   |  36 |  25 |   10  |\n| Google Pixel 6XL |  35 |  42 |   53  |\n| Xiaomi Mi9       |  22 |  41 |   33  |\n| Google Pixel 4XL |  37 |  36 |   45  |\n\n#### MobileNetV3-320 - mAP: 16%\n\nSSD object detector with MobileNet V3 backbone and input resolution of 320x320.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra|  30 |  17 |   30  |\n| Samsung S20FE 5G |  34 |  42 |   28  |\n| Huawei P30 Pro   |  32 |  27 |   23  |\n| Google Pixel 6XL |  33 |  43 |   27  |\n| Xiaomi Mi9       |  20 |  45 |   10  |\n| Google Pixel 4XL |  32 |  38 |   21  |\n\n#### YoloV4-tiny-224 - mAP: 22%\n\nTiny version of [YoloV4](https://arxiv.org/abs/2004.10934) with input resolution of 224x224.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra|  31 |  12 |   31  |\n| Samsung S20FE 5G |  30 |  21 |   14  |\n| Huawei P30 Pro   |  27 |  17 |   22  |\n| Google Pixel 6XL |  29 |  24 |   19  |\n| Xiaomi Mi9       |  16 |  14 |  9.3  |\n| Google Pixel 4XL |  22 |  19 |   14  |\n\n#### YoloV4-tiny-416 - mAP: 29%\n\nTiny version of [YoloV4](https://arxiv.org/abs/2004.10934) with input resolution of 416x416.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra|  13 | 9.8 |   13  |\n| Samsung S20FE 5G |  12 | 9.4 |  7.7  |\n| Huawei P30 Pro   | 8.4 | 7.6 |  6.9  |\n| Google Pixel 6XL |  10 | 9.6 |  7.2  |\n| Xiaomi Mi9       | 9.0 | 7.3 |  5.0  |\n| Google Pixel 4XL | 7.2 | 7.4 |  6.2  |\n\n#### YoloV4-224 - mAP: 40%\n\n[YoloV4](https://arxiv.org/abs/2004.10934) with input resolution of 224x224.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra| 3.7 | 5.6 |  3.5  |\n| Samsung S20FE 5G | 3.1 | 7.1 |  4.2  |\n| Huawei P30 Pro   | 2.4 | 6.2 |  0.7  |\n| Google Pixel 6XL | 2.7 |  11 |  0.9  |\n| Xiaomi Mi9       | 2.1 | 6.4 |  1.7  |\n| Google Pixel 4XL | 1.8 | 5.0 |  3.7  |\n\n#### YoloV5s-320 - mAP: 28%\n\n[YoloV5](https://github.com/ultralytics/yolov5) with input resolution of 320x320.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra|  21 |  10 |   21  |\n| Xiaomi Mi9       |  13 |  15 |  0.8  |\n| Google Pixel 4XL |  12 |  17 |   18  |\n\n#### YoloV5s-640 - mAP: 34%\n\n[YoloV5](https://github.com/ultralytics/yolov5) with input resolution of 640x640.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra| 5.5 | 4.9 |  5.0  |\n| Xiaomi Mi9       | 4.1 | 4.6 |   -   |\n| Google Pixel 4XL | 3.7 | 4.6 |  4.6  |\n\n#### YoloV5m-320 - mAP: 35%\n\n[YoloV5](https://github.com/ultralytics/yolov5) with input resolution of 320x320.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra|  13 | 8.2 |   11  |\n| Xiaomi Mi9       | 9.7 | 9.9 |   -   |\n| Google Pixel 4XL | 7.9 | 9.2 |   15  |\n\n#### YoloV5l-320 - mAP: 38%\n\n[YoloV5](https://github.com/ultralytics/yolov5) with input resolution of 320x320.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra| 7.6 | 3.4 |  7.6  |\n| Xiaomi Mi9       | 5.5 | 5.0 |   -   |\n| Google Pixel 4XL | 5.3 | 4.0 |  5.3  |\n\n#### EfficientDet-L0-320 - mAP: 26%\n\n[EfficientDet-L0](https://tfhub.dev/tensorflow/lite-model/efficientdet/lite0/detection/metadata/1) with input resolution of 320x320. Note: Model performance deteriorates in landscape mode; the confidence threshold might need to be adjusted.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra|  18 |  10 |   16  |\n| Xiaomi Mi9       |  16 |  20 |  1.2  |\n| Google Pixel 4XL |  17 |  17 |   16  |\n\n#### EfficientDet-L1-384 - mAP: 31%\n\n[EfficientDet-L1](https://tfhub.dev/tensorflow/lite-model/efficientdet/lite1/detection/metadata/1) with input resolution of 384x384. Note: Model performance deteriorates in landscape mode; the confidence threshold might need to be adjusted.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra|  12 | 9.2 |   10  |\n| Xiaomi Mi9       |  10 |  13 |    -  |\n| Google Pixel 4XL |  11 |  11 |   10  |\n\n#### EfficientDet-L2-448 - mAP: 34%\n\n[EfficientDet-L2](https://tfhub.dev/tensorflow/lite-model/efficientdet/lite2/detection/metadata/1) with input resolution of 448x448. Note: Model performance deteriorates in landscape mode; the confidence threshold might need to be adjusted.\n\n|phone/device (fps)| CPU | GPU | NNAPI |\n|------------------|-----|-----|-------|\n| Samsung S22 Ultra| 9.8 | 8.4 |  8.2  |\n| Xiaomi Mi9       | 6.4 | 9.4 |   -   |\n| Google Pixel 4XL | 7.7 | 8.3 |  7.6  |\n\n### Default\n\nThe [DefaultActivity](src/main/java/org/openbot/original/DefaultActivity.java) includes the most important features of the OpenBot app in a single screen. It displays the connection status to the vehicle and reports measurements from vehicle sensors. The robot can be controlled by standard BT game controllers or another smartphone running the OpenBot [controller app](../controller). We have also implemented a data logger to collect datasets with the robot. Currently, we record readings from following sensors: camera, gyroscope, accelerometer, magnetometer, ambient light sensor, and barometer. Using the Android API, we are able to obtain the following sensor readings: RGB images, angular speed, linear acceleration, gravity, magnetic field strength, light intensity, atmospheric pressure, latitude, longitude, altitude, bearing, and speed. In addition to the phone sensors, we record body sensor readings (wheel odometry, obstacle distance and battery voltage), which are transmitted via the serial link. We also record and timestamp control signals received from a connected controller, if present. Lastly, we integrate several neural networks for person following and autonomous navigation.\n\n<p align=\"left\">\n  <img src=\"../../docs/images/screen_default.jpg\" alt=\"App GUI\" width=\"50%\"/>\n</p>\n\n#### USB Connection\n\nSame as in the [settings menu](#settings-menu).\n\n#### Vehicle Status\n\nThe field **Battery** displays the battery voltage as measured by the Arduino via the voltage divider. The field **Speed (l,r)** reports the left and right speed of the (front) wheels in rpm. It is measured by the Arduino via the optical wheel speed sensors. The field **Sonar** shows the free space in front of the car in centimeters. It is measured by the Arduino via the ultrasonic sensor. Note, you will only receive values a few seconds after the USB connections has been established.\n\n#### Control\n\nThe first button is for selecting the **control mode**. There are two different control modes:\n\n- **Gamepad**: The app receives controls from a connected BT controller.\n- **Phone**:  The robot can be controlled via another smartphone with the controller app installed or though a Python script running on a computer connected to the same network.\n\nThe second button is for selecting the **drive mode**. There are three different drive modes when using a game controller (e.g. PS4):\n\n- **Game**: Use the right and left shoulder triggers (R2, L2) for forward and reverse throttle and either joystick for steering. This mode imitates the control mode of car racing video games.\n- **Joystick**: Use either one of the joysticks to control the robot.\n- **Dual**: Use the left and right joystick to control the left and right side of the car. This is raw differential steering.\n\nThe third button is for selecting the **speed mode**. There are three different speed modes:\n\n- **Slow**: The voltage applied to the motors is limited to 50% of the input voltage (~6V).\n- **Normal**: The voltage applied to the motors is limited to 75% of the input voltage (~9V).\n- **Fast**: There is no limit. The full input voltage will be applied to the motors at full throttle (~12V). *This is the default setting for running the neural networks.*\n\nRunning at higher speeds will reduce the lifetime of the motors but is more fun. The controls that are sent to the robot are displayed on the right side. When using the game controller, the speed mode can be increased by pressing down the right joystick (R3) and decrased by pressing down the left joystick (L3).\n\n#### Data Log\n\nThere are four different logging modes:\n\n- **only_sensors**: All sensor data but no images are saved.\n- **crop_img**: All sensor data and a cropped images that have the input size of the network are saved. This is the default setting and is what should be used for data collection.\n- **preview_img**: All sensor data and a full-size images are saved. This will require a lot of memory and can be slow. However, it is nice for compiling FPV videos.\n- **all_imgs**: All sensor data and both cropped and full-size images are saved. This will require a lot of memory and can be slow.\n\nThe switch on the right is used to toggle logging on and off. On the game controller this switch can be toggled with the X button.\n\n#### Camera\n\nThe first item shows the preview resolution. The second item shows the crop resolution. This is the image that is used as input to the neural networks. You will notice that this resolution changes depending on which model you select below. If you train your own autopilot, make sure to select the `AUTOPILOT_F` model. The crop resolution should show `256x96`. The switch on the right is used to toggle between the rear and the front camera.\n\n#### Model\n\nThere are two models that come with the app:\n\n- **MobileNetV1-300**: This model is used for person following. It uses a SSD object detector with MobileNet V1 backbone. The model is quantized for better performance on embedded devices. It comes with the app.\n- **CIL-Mobile**: This model is used for autonomous navigation. It will predict controls directly from the camera input. Chances are that it will not work in your environment. You should follow our instructions to train your own [Driving Policy](../../policy) and replace it.\n\nAdditional models can be downloaded from the Model Management screen.\n\nThe switch on the right is used to turn the network on and off. When the network is running, it produces the controls for the robot and the game controller is disabled. However, you may still use the buttons on the game controller, for example to toggle this switch with the R1 trigger button to regain control of the robot.\n\n#### Device\n\nUse the drop-down menu to select the device on which the neural network should be executed. You have the following choices:\n\n- **CPU**: Using the CPU works on most phones and is the default choice. You can adjust the number of threads to optimize performance.\n- **GPU**: Most smartphones have a GPU. Networks with large inputs such as images often run faster on a GPU.\n- **NNAPI**: This will use the [TensorFlow Lite NNAPI delegate](https://www.tensorflow.org/lite/performance/nnapi). Modern smartphones often come with dedicated AI accelerators. The [Neural Network API](https://developer.android.com/ndk/guides/neuralnetworks) (NNAPI) provides acceleration for TensorFlow Lite models on Android devices with Graphics Processing Unit (GPU), Digital Signal Processor (DSP) and Neural Processing Unit (NPU). Note that on some older phones this can be very slow!\n\nIf a model is active, the inference speed in [ms] will be displayed next to the device which is running the model.\n\n### Projects Screen\n\nThe Projects Screen displays a list of your OpenBot Playground projects if you are signed in with your Google account. You can execute these projects to connect with your OpenBot, or scan their QR codes by clicking the scanner icon in the top right corner. If you are not signed in, the screen will display a Google Sign-In button, but you can still scan your project's QR code without signing in. If you get the message `Oops, no project found` on the screen after signing in, make sure that the account has projects stored on Google Drive.\n\nIf you don't see your latest projects in the project list, you can reload them by pulling down on the project screen.\n<p align=\"left\">\n<img src=\"../../docs/images/projects_tab_screen.gif\" alt=\"Project Screen\" width=\"24.7%\"/>\n<img src=\"../../docs/images/no_projects_found.jpg\" alt=\"No project screen\" width=\"25%\"/>\n<img src=\"../../docs/images/reload_projects.gif\" altq=\"Reload project screen\" width=\"24.5%\"/>\n</p>\n\n- **Google Drive projects**: To run a Google Drive project, tap on the project you want to execute and wait for the contents of the project file to be read. If the file is successfully retrieved without any errors, a pop-up will appear with two buttons: `Start` and `Cancel`. The pop-up will also display the name of the project you are about to run. To execute the project, click on the Start button. If you want to stop the activity, click on the Cancel button. If you receive a pop-up message stating `Something went wrong`, there may be an error with the Google Drive file. To resolve this issue, refresh the project screen by pulling down and then repeating the same process.\n\n\n- **Qr code scanner**: To scan the QR code of a Playground project, click on the QR code icon located in the top right corner of the screen. Grant camera access to the app so that it can scan the QR code. Once the code is scanned, wait for the contents of the file to be read. If the file is retrieved successfully without any errors, a pop-up will appear with two buttons: `Start` and `Cancel`. The pop-up will also display the name of the project you are about to run. To execute the project, click on the Start button. If you want to stop the activity, click on the Cancel button. If you receive a pop-up message stating `Something went wrong`, there may be an error with the Google Drive file. To resolve this issue, generate a new QR code in Playground and repeat the process.\n\n\n- **Executing Project**: If your OpenBot Playground project runs successfully, the screen will display the names of code blocks along with a stop button that can be used to stop the execution of playground block commands.\n\n\n- **Delete Project**: To delete a project, long-press on the project you wish to delete. This will bring up a popup screen asking to confirm the deletion. Tap on 'Yes' to delete the project.\n\n<p align=\"left\">\n<img src=\"../../docs/images/android_google_drive_projects_execute.gif\" alt=\"Google Drive project execute\" width=\"25%\"/>\n<img src=\"../../docs/images/android_qr_code_scanning.gif\" alt=\"Qr code scanner project execute\" width=\"25%\"/>\n<img src=\"../../docs/images/android_delete_project.jpg\" alt=\"Delete Project\" width=\"24.7%\"/>\n</p>\n\n### Profile Screen\nThe Profile Screen in the app provides different options based on whether the user is signed in or not.\nIf the user is not signed in, a `Google Sign-in` button will appear, prompting the user to sign in their Google account. Once signed in, the user will be able to access their profile and other features.\nIf the user is signed in, two buttons will be listed in the  `Profile` tab: `Edit Profile` and `Logout`.\n\n<p align=\"left\">\n<img src=\"../../docs/images/android_logged_out_profile_screen.jpg\" alt=\"Logged out profile screen\" width=\"25%\"/>\n<img src=\"../../docs/images/android_logged_in_profile_screen.jpg\" alt=\"Logged in profile screen\" width=\"24.9%\"/>\n</p>\n\n- **Edit Profile**: Tapping on this button will open a new screen where the user can update their profile information, such as their name and profile picture.\n\n\n- **Logout**: This button allows the user to log out of their account. Tapping on this button will log the user out and return them to the login screen.\n\n  <p align=\"left\">\n  <img src=\"../../docs/images/android_edit_profile.jpg\" alt=\"Edit profile screen\" width=\"25%\"/>\n  <img src=\"../../docs/images/android_logout_dialog_box.jpg\" alt=\"Logout dialog box\" width=\"24.4%\"/>\n  </p>\n\n### OpenBot PlayGround Screen\n\nTo access OpenBot Playground services, click on the OpenBot Playground icon located at the top of the screen in the toolbar options. If you want to learn more about OpenBot Playground, [click here](../../open-code/README.md).\n\n<p align=\"left\">\n<img src=\"../../docs/images/android_playground_sign-in.gif\" alt=\"openBot playground Sign-in\" width=\"25%\"/>\n<img src=\"../../docs/images/android_playground_services.gif\" alt=\"openBot playground Services\" width=\"25%\"/>\n</p>\n\n## Add your own fragment\n\nPlease refer to the [ContributionGuide](ContributionGuide.md) to learn how to add your own fragments to the OpenBot app.\n\n## Code Structure\n\nThe [TensorFlow Lite Object Detection Android Demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android) was used as starting point to integrate TFLite models and obtain the camera feed. The [DefaultActivity](src/main/java/org/openbot/robot/DefaultActivity.java) runs the main thread and inherits from the [CameraActivity](src/main/java/org/openbot/robot/CameraActivity.java) to manage the camera and UI. The [SensorService](src/main/java/org/openbot/robot/SensorService.java) reads all other phone sensors and logs them. The [ServerService](src/main/java/org/openbot/robot/ServerService.java) and [NsdService](src/main/java/org/openbot/robot/NsdService.java) establish a connection to a local [Python server](../../policy/README.md#web-app) with a React frontend. If you collect data it can be uploaded automatically for visualization, training ML models and downloading trained models to the robot. The [env](src/main/java/org/openbot/env) folder contains utility classes such as the [Vehicle](src/main/java/org/openbot/env/Vehicle.java) interface, [GameController](src/main/java/org/openbot/env/GameController.java) interface, [PhoneController](src/main/java/org/openbot/env/PhoneController.java) interface and an [AudioPlayer](src/main/java/org/openbot/env/AudioPlayer.java) for the audible feedback. The [tflite](src/main/java/org/openbot/tflite) folder contains the model definitions for the [Autopilot](src/main/java/org/openbot/tflite/Autopilot.java) and [Detector](src/main/java/org/openbot/tflite/Detector.java) networks.\n\n## Next (optional)\n\nTrain your own [Driving Policy](../../policy/README.md)\n"
  },
  "https://github.com/isl-org/OpenBot/blob/master/android/robot/src/main/java/org/openbot/googleServices/README.md": {
    "summary": "Google Firebase is a platform for mobile and web app development. It offers services like real-time database, authentication, and hosting. Its Firebase Google Sign-In Authentication feature allows users to sign in using their Google credentials. To integrate this into an Android app, developers should create a Firebase project and obtain an SHA-1 signing key. The setup includes adding a Google services JSON file to the app. For Google Sign-In, developers should enable the service in the Firebase Console.",
    "content": "## Google Firebase\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nGoogle Firebase is a mobile and web application development platform that offers a variety of services and tools to help developers build high-quality apps quickly and efficiently. It includes features such as real-time database, user authentication, hosting, cloud storage and many more, all these are integrated into a single platform. Firebase provides a convenient and scalable solution for developers to manage their backend infrastructure, allowing them to focus on building great user experiences.\n\n- ### Firebase Google Sign-In Authentication\n\n  Firebase Google Sign-In Authentication is a feature of the Firebase platform that allows users to sign in to mobile or web apps using their Google credentials. This service provides a secure and convenient way for users to access apps without having to remember and manage separate login credentials. Firebase manages the entire authentication process, from verifying the user's identity with Google to providing a unique user ID that can be used to personalize the user's experience within the app. This feature also includes additional security measures, such as two-factor authentication, to help protect user's account from unauthorized access.\n\n- ### Usage\n  In this application, we use Firebase for Google Sign-In authentication to access [OpenBot Playground](../../../../../../../../open-code/README.md) projects uploaded on Google Drive. If you plan to clone this Android application and build it on your device, it's important to note that you will need to set up your own [Firebase Project](#set-up-your-firebase-project). This is because the SHA-1 key is required for Google Sign-In authentication. \n  \n  And you will need to [set up Firebase](../../../../../../../../open-code/README.md) for the [OpenBot Playground](https://www.playground.openbot.org/) web application as well. This is because the Android app retrieves files from the user's Google Drive, which is created by Firebase Google Drive services. It's important to use the same Firebase project for both the Android and web applications for Google Drive services to work properly.\n  \n  If you do not want to use OpenBot Playground services, you do not need to set up Firebase authentication or Google Sign-In authentication.\n\n### Prerequisites\nTo integrate Firebase into an Android OpenBot application for Google Sign-In, we will need a few prerequisites.\n- **Google Account:** To use Google Sign-In with Firebase, you must have a Google account. If you don't have one, click here to [create](https://accounts.google.com/signup) free Google account.\n- **Firebase Account:** You need to have a Firebase account and create a new Firebase project for your Android application. You can create a new Firebase project from the [Firebase Console](https://console.firebase.google.com/).\n****\n\n### Set up your Firebase project\n\n- Go to the [Firebase Console](https://console.firebase.google.com/) and create a `new project` following these steps.\n  1. Click on the \"Create Project\" button.\n  2. Enter a name for your Firebase project and click \"Next\" button.\n  3. Google Analytics can be disabled if you do not want to use them.\n  4. Click on the \"Create Project\" button.\n<p>\n<img src=\"../../../../../../../../docs/images/firebase_create_app_project.jpg\" alt=\"Create project\" width=\"25%\"/>\n<img src=\"../../../../../../../../docs/images/firebase_enter_project_name.jpg\" alt=\"Enter project name\" width=40%\"/>\n<img src=\"../../../../../../../../docs/images/firebase_disable_analytics.jpg\" alt=\"Disable analytics\" width=\"27.5%\"/>\n</p>\n\n- To add a new Android app to your Firebase project, do the following:\n  1. Click on the Android icon in the Firebase project.\n  2. Enter `package name` of your Android app. This should be `unique` for Firebase.\n  3. Enter your app's nickname.\n  4. The **SHA-1 key** is **mandatory** for Firebase Google SignIn service to sign your application's APK. Enter it in the appropriate field.\n  5. Click on the `Register` button.\n  \n\n- About the `SHA-1` fingerprint/key is a unique identifier for your `app's signing certificate`, and is used by Firebase to verify the authenticity of your app when communicating with Firebase servers. If you plan to use Firebase Authentication in your app, you will need to provide an `SHA-1` key `for the signing certificate` used to sign the `release version` of your app.\n  \n<p>\n<img style=\"width: 47%\" src=\"../../../../../../../../docs/images/firebase_add_android_app.jpg\" alt=\"Add Android Application\" width=\"40%\"/>\n<img src=\"../../../../../../../../docs/images/firebase_package_name.jpg\" alt=\"Package Name\" width=\"36%\"/>\n</p>\n\n- To obtain the `SHA-1` key, you can use the `keytool` (command-line tool) that is included with the `Java SDK`. Here's how to use it on `Mac` and `Windows`:\n  \n\n  - **On Mac**\n    ```shell\n    keytool -list -v -keystore ~/.android/debug.keystore -alias androiddebugkey -storepass android -keypass android\n    ```\n    This command will list the details of the debug signing certificate located at `~/.android/debug.keystore`. The `-alias` flag specifies the alias name used to identify the debug signing certificate. The `-storepass` and `-keypass` flags specify the passwords for the keystore and key, respectively.\n  \n\n  - **On Windows**\n    ```shell \n    keytool -list -v -keystore \"%USERPROFILE%.android\\debug.keystore\" -alias androiddebugkey -storepass android -keypass android\n    ```\n    This command is similar to the Mac command, but uses a `different path` to locate the debug.keystore file. `%USERPROFILE%` is a system environment variable that points to the current user's profile directory, which contains the `.android` directory where the `debug.keystore` file is located.\n\n- Download the `google-services.json` file and `add` it to your Application's `app directory` and also `assets directory`.\n- Click on the next button, And you have to skip the third step because we already **add firebase SDK** in gradle file for this project.\n- Continue to the Firebase Console to configure the Firebase services you want to use in your Android app.\n\n<p>\n<img style=\"width: 40%\" src=\"../../../../../../../../docs/images/firebase_google_service_json_file.jpg\" alt=\"Google services json file\" width=\"41%\"/>\n<img src=\"../../../../../../../../docs/images/firebase_continue_to_console.jpg\" alt=\"Continue to console\" width=\"40.2%\"/>\n</p>\n\n- To `enable Google Sign-In authentication` for your Firebase project, follow these steps:\n  1. Go to the Firebase Console and select your project.\n  2. Click on the `All products` option in the left `sidebar menu`.\n  3. Click on `Authentication`.\n  4. Click on the `Get Started` button.\n  5. Click on the `Google icon`.\n  6. Click on the `toggle button` to `enable` Google Sign-In authentication.\n\n<p>\n<img style=\"width:36%\" src=\"../../../../../../../../docs/images/firebase_product_services.jpg\" alt=\"Firebase product services\" width=\"50%\"/>\n<img src=\"../../../../../../../../docs/images/firebase_app_authentication.jpg\" alt=\"Firebase authentication\" width=\"39%\"/>\n</p>\n<p>\n<img src=\"../../../../../../../../docs/images/firebase_app_google_signin.jpg\" alt=\"Google Sign-In\" width=\"50%\"/>\n<img src=\"../../../../../../../../docs/images/firebase_google_signin_enable.jpg\" alt=\"Google Sign-In enable\" width=\"26.1%\"/>\n</p>\n\n\n- If you have `skipped the step to add the SHA-1 key` to your Firebase project during the setup process, you can `still add` it later by following these steps:\n\n  - Go to your `Firebase console` and select `your project`.\n  - Click on the `gear icon` in the `upper-left corner` and select `Project settings`.\n  - Under `Your apps` section, select the `Android app` you want to `add the SHA-1 key`.\n  - `Scroll down` to the `SHA-1 certificate fingerprints` section and click on `Add fingerprint`.\n  - Enter the `SHA-1 key` for your app's signing certificate.\n  - Click on `Save` to add the SHA-1 key to your Firebase project.\n\n<p>\n<img style=\"width: 44%;\" src=\"../../../../../../../../docs/images/firebase_gear_icon.jpg\" alt=\"Gear icon\" width=\"30%\"/>\n<img style=\"width: 53%\" src=\"../../../../../../../../docs/images/firebase_add_sha1.jpg\" alt=\"Add SHA-1\" width=\"43%\"/>\n</p>\n\n- If you have `already implemented Firebase authentication` before adding the SHA-1 key, you may need to `update` your app's `configuration`. This can be done by `replacing` the `google-services.json` file in project directory with the `updated google-services.json` file from Firebase project setting.\n\n<p>\n<img src=\"../../../../../../../../docs/images/firebase_updated_google_service_json_file.jpg\" alt=\"Updated Google service json file\" width=\"40%\"/>\n</p>\n"
  },
  "https://github.com/isl-org/OpenBot/blob/master/android/robot/ContributionGuide.md": {
    "summary": "The application follows the single activity architecture with a MainFragment that uses Navigation to route to features. ControlsFragment and CameraFragment provide reusable functionality for controlling the robot and camera preview. To add a new feature, create a fragment, extend ControlsFragment or CameraFragment as needed, add it to FeatureList, and add it to the navigation graph.",
    "content": "# Contribution Guide\n\nThe application codebase follows a single activity architecture. \n\nIt launches with `MainActivity.java` which holds `MainFragment.java` as it's default fragment. \n\n`MainFragment.java` has a recyclerview which is used to route to different screens and features using Android's Navigation component. The recycler view adapter is loaded with data curated from `FeatureList.java` class.\n\nThe project contains two `abstract` classes `ControlsFragment.java` and `CameraFragment.java` which can be extended to inherit the relvevant functionalities.\n\n#### `ControlsFragment.java`\n\nThis class contains all relevant code required to operate the robot via a controller. Just extending this class will give your feature the ability to control the robot in one go. It uses two `private` methods,\n\n```\nprivate void processKeyEvent(KeyEvent keyCode)\n```\n\nand \n\n```\nprivate void handlePhoneControllerEvents()\n```\n\n to process game controller, and  phone controller key actions, and pass the processed String data to \n`protected abstract void processControllerKeyData(String data)` which is exposed to inheriting classes, which can be used to update the UI accordingly. \n\n\n\n#### `CameraFragment.java`\n\nThis class uses CameraX API to enable camera preview in the app. It extends the functionality of `ControlsFragment.java` to support robot connection and integration by default. \n\nTo add camera preview to your feature:\n\n1. Replace `extends Fragment`  with `extends CameraFragment` like this:\n\n   â€‹\t`public class AIFragment extends CameraFragment`\n   \n2. To overlay your own UI over this camera preview, `CameraFragment.java` offers two protected methods.\n\n   â€‹\ta.) `View inflateFragment(ViewBinding viewBinding, LayoutInflater inflater, ViewGroup container)`\n   â€‹\tb.) `View inflateFragment(int resId, LayoutInflater inflater, ViewGroup container)`\n\n    Depending on whether you use ViewBinding or resource file to inflate your view, use the relevant method, and in the `onCreateView` method of your fragment, return it like this:\n\n    ```\n    @Override\n    public View onCreateView(\n        @NotNull LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) {\n      // Inflate the layout for this fragment\n      binding = FragmentAiBinding.inflate(inflater, container, false);\n    \n      return inflateFragment(binding, inflater, container);\n    }\n    ```\n    or\n    ```\n     @Override\n     public View onCreateView(\n         @NotNull LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) {\n        // Inflate the layout for this fragment\n        View mView = inflater.inflate(R.layout.fragment_ai, container, false);\n        \n        return inflateFragment(mView, inflater, container);\n     }\n    ```\n## To add a new feature:\n\n1. Create a new fragment and it's respective layout file.\n\n2. Depending on whether camera preview is needed or not, extend either of `ControlsFragment.java` or `CameraFragment.java` class.\n\n3. Based on the category and subcategory this feature falls in, add it in `FeatureList.java`, along with it's title, icon and color. Here's an example for the same.\n\n   ```\n   ArrayList<SubCategory> subCategories = new ArrayList<>();\n   subCategories.add(new SubCategory(DEFAULT, R.drawable.openbot_icon, \"#4B7BFF\"));\n   subCategories.add(new SubCategory(FREE_ROAM, R.drawable.ic_game, \"#FFFF6D00\"));\n   subCategories.add(new SubCategory(DATA_COLLECTION, R.drawable.ic_storage, \"#93C47D\"));\n   subCategories.add(new SubCategory(AI_MODELS, R.drawable.ic_person_search, \"#FFD966\"));\n   categories.add(new Category(ALL, subCategories));\n   ```\n\n3. In `nav_graph.xml`, using the Design Editor, add your fragment to the graph, and link in with `mainFragment`.\n\n4. Finally, inside switch block in `onItemClick` method of `MainFragment.java` , add your feature title as a new case and navigate to the screen using it's action id like this.\n\n   ```\n   Navigation.findNavController(requireView())\n       .navigate(R.id.action_mainFragment_to_AIFragment);\n   ```\n\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/README.md": {
    "summary": "OpenBot offers a range of robot body options:\n\n- **Ready-to-run (RTR):** RTR-TT and RTR-520 available for purchase from Amazon.\n- **DIY:** Build your own wheeled robot using the provided 3D-printed body and hardware.\n- **OpenBot Lite:** A simplified, education-friendly variant of DIY.\n- **RC Truck:** 3D-printed body designed for commercial 1:16 RC trucks.\n- **Multi-Terrain Vehicle:** Blueprints for an outdoor platform.\n\nVisit the links provided for specific build instructions and details. The next step is to flash the Arduino Firmware to complete setup.",
    "content": "# OpenBot: Robot Body\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nYou can buy a [ready-to-run (RTR)](rtr) OpenBot on Amazon:\n- [RTR-TT](https://buy.openbot.org/rtr-tt)\n- [RTR-520](https://buy.openbot.org/rtr-520)\n\nFor larger order requests, please contact us via email.\n\n## Building your own\n\nYou can build any wheeled robot body around a microcontroller such as the Arduino Nano to use with the OpenBot software stack. We have designed a [3D-printed body](diy) for a wheeled robot which relies on low-cost, readily available hobby hardware. [OpenBot Lite](lite) is a smaller and simplified variant of the OpenBot DIY version developed for education. Even if you do not want to build it, you may find the [step-by-step video guides](lite/#step-by-step-video-guides) helpful. We have also designed a [3D-printed body](rc_truck) for commercially available 1:16 RC-Trucks (such as [this](https://www.amazon.de/dp/B00M3J7DJW) one). We also provide blueprints for building a [multi-terrain vehicle](mtv), as a general-purpose platform for outdoor projects using the OpenBot framework. \n\nBelow are a number of examples with build instructions and further details:\n\n<table style=\"width:100%;border:none;text-align:center\">\n  <tr>\n  <td>  <a href=\"diy\">\n    <img  alt=\"DIY\" src=\"../docs/images/assembly.gif\" />\n  </a>\n  </td>\n  <td>\n  <a href=\"lite\">\n    <img alt=\"Lite\" src=\"../docs/images/openbot_lite.jpg\" />\n  </a>\n  </td>\n  <td>\n  <a href=\"rc_truck\">\n    <img  alt=\"RC Truck\" src=\"../docs/images/add_covers_2.JPG\" />\n  </a>\n  </td>\n  <td>\n  <a href=\"mtv\">\n    <img alt=\"Multi-Terrain Vehicle\" src=\"../docs/images/MTV/MTV.jpg\" />\n  </a>\n  </td>\n  <td>\n  <a href=\"rtr\">\n    <img alt=\"RTR\" src=\"../docs/images/rtr_tt_assembly.gif\" />\n  </a>\n  </td>\n  </tr>\n  <tr>\n    <td><a href=\"diy\"> DIY </a></td>\n    <td><a href=\"lite\"> Lite </a></td>\n    <td><a href=\"rc_truck\"> RC Truck </a></td>\n    <td><a href=\"mtv\"> Multi-Terrain Vehicle </a></td>\n    <td><a href=\"rtr\"> RTR </a></td>\n  </tr>\n</table>\n\n## Next\n\nFlash the [Arduino Firmware](../firmware/README.md)\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/diy/cad/block_body/README.md": {
    "summary": "The \"Blocky Body\" robot chassis provides extra height for electronics and features a lego-compatible top. It offers structural integrity, increased internal space, and supports smaller print beds while maintaining protective bumpers. The bottom part is printed along with one of five top part options: basic, lego-compatible, or larger versions with or without lego compatibility. For optimal printing, recommended settings include a 0.2mm layer height, 3 wall lines, 5 top layers, 25% concentric infill, 50mm/s print speed, and concentric support with a 15% density and support brim.",
    "content": "# Blocky Body with Additional Space and Lego Support\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nThis robot chassis provides some extra height to make it easier to fit in all the electronics and a lego-compatible top. This version offers the same structural integrity capabilities as the [regular body](../regular_body/), with additional features such as extra space inside the OpenBot shell, a lego-compatible top for play and learning and a footprint suitable for smaller print bed sizes while maintaining bumpers. \n\n![Block CAD](../../../../docs/images/block_cad.jpg)\n\n## Parts\n\nYou will need to print the bottom part and one of the top parts:\n\n- `block_body_bottom`([STL](block_body_bottom.stl), [STEP](block_body_bottom.step)): bottom part of the body\n- `block_body_top`([STL](block_body_top.stl), [STEP](block_body_top.step)): basic top part of the body\n- `block_body_top_lego`([STL](block_body_top_lego.stl), [STEP](block_body_top_lego.step)): basic top part of the body with lego-compatible surface\n- `block_body_top_big`([STL](block_body_top_big.stl), [STEP](block_body_top_big.step)): big top part of the body with additional volume for electronics\n- `block_body_top_lego`([STL](block_body_top_big_lego.stl), [STEP](block_body_top_big_lego.step)): big top part of the body with lego-compatible surface\n\nFor the above parts, your build plate needs to be at least 221x150mm.\n\n## Print Settings\n\nFor best results, we recommend using the following print settings:\n\n- Layer height: 0.2mm\n- Wall line count: 3 (more walls for better structural integrity of larger surfaces)\n- Top Layers: 5\n- Bottom Layers: 4\n- Infill: 25%\n- Infill Pattern: Concentric (this setting seems to save time and plastic)\n- Print Speed: 50mm/sec\n- Generate Support: Yes\n- Support Pattern: Concentric\n- Support density: 15%\n- Enable Support Brim: Yes\n- Build Plate Adhesion Type: None\n\nHappy robot building!\n\n![Block Body](../../../../docs/images/block_body.jpg)\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/diy/cad/glue_body/README.md": {
    "summary": "The \"Glueable Body\" folder provides 3D-printable parts designed for printers with smaller build volumes. The OpenBot body is split into four sections (Bottom A/B, Top A/B) that can be printed separately and then glued together, with optional connector pieces for added gluing surface area.",
    "content": "# Glueable Body\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nSome 3D printers have build volumes that are too small to print the full size OpenBot body.\nThis folder contains the OpenBot body split into 4 pieces.\nIt can be printed with a build plate as small as 150mmx140mm, and then glued together.\n\n![Glueable Body](../../../../docs/images/glue_body.jpg)\n\n## Parts\n\nRequired parts:\n\n1) `glue_body_bottom_A` ([STL](glue_body_bottom_A.stl), [STEP](glue_body_bottom_A.step))\n2) `glue_body_bottom_B` ([STL](glue_body_bottom_B.stl), [STEP](glue_body_bottom_B.step))\n3) `glue_body_top_A` ([STL](glue_body_top_A.stl), [STEP](glue_body_top_A.step))\n4) `glue_body_top_B` ([STL](glue_body_top_B.stl), [STEP](glue_body_top_B.step))\n\nOptional parts:\n\nThese pieces give extra surface area for gluing, which can help if your print experiences warping.\n\n* `glue_connector_bottom` ([STL](glue_connector_bottom.stl), [STEP](glue_connector_bottom.step))\n* `glue_connector_top_A` ([STL](glue_connector_top_A.stl), [STEP](glue_connector_top_A.step))\n* `glue_connector_top_B` ([STL](glue_connector_top_B.stl), [STEP](glue_connector_top_B.step))\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/diy/cad/regular_body/README.md": {
    "summary": "The README provides instructions for building the \"Regular Body\" part of the OpenBot robot. It specifies the parts required (body_bottom and body_top) and their file formats (STL and STEP). The minimum build plate size needed is 240mmx150mm. The document also provides recommended print settings for an Ultimaker S5 printer, including layer height, wall thickness, infill density, and print speed. It mentions that PLA, ABS, and CPE materials can be used for printing, and that while print settings don't significantly affect the outcome, slower printing with smaller layer height can improve the print quality. Support structures can also be used to enhance the print but may require additional work to remove afterward.",
    "content": "# Regular Body\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n![Assembly](../../../../docs/images/assembly.gif)\n\n## Parts\n\nYou will need to print the following parts in order to build your OpenBot.\n\n- `body_bottom` ([STL](body_bottom.stl), [STEP](body_bottom.step))\n- `body_top` ([STL](body_top.stl), [STEP](body_top.step))\n\nFor the above parts, your build plate needs to be at least 240mmx150mm.\n\n## Print Settings\n\nOn an Ultimaker S5, we achieved good results with the following settings:\n\n- layer height: 0.2mm\n- wall thickness: 1.5mm\n- infill density: 20%\n- infill pattern: grid\n- print speed 80 mm/s\n- no support\n\nWe were able to print the chassis with PLA, ABS and CPE. In our experience the print was not affected very much by the print settings. However, if you have the patience, printing slower and with smaller layer height will improve the print. Also adding a support structure can improve the print, but it will require additional work to remove afterwards.\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/diy/cad/slim_body/README.md": {
    "summary": "This repository contains a slim version of the OpenBot body, designed for printers with smaller build volumes (220mmx220mm). The parts can be printed by rotating them 45 degrees. The repository includes two main parts: a bottom and a top, and optionally a top with a larger rim. To fit the print, adjust settings to minimize the overall size and disable unnecessary features like brim and prime blob.",
    "content": "# Slim Body\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nSome 3D printers have build volumes that are too small to print the full size OpenBot body.\nThis folder contains the slim version of the OpenBot body.\nIt can be printed with a build plate of 220mmx220mm when the parts are rotated 45 degrees.\n\n![Slim Body](../../../../docs/images/slim_body.jpg)\n\n## Parts\n\n1) `slim_body_bottom` ([STL](slim_body_bottom.stl), [STEP](slim_body_bottom.step))\n2) `slim_body_top` ([STL](slim_body_top.stl), [STEP](slim_body_top.step))\n\nIn order to make it fit you may have to adjust the following settings to get the maximum print area.\n\n- Set *Build Plate Adhesion Type* to \"None\" (Brim, Skirt and Raft increase the overall size of your print)\n- Disable prime blob (in *Build Plate* section)\n- Disable the second extruder (if your printer has one)\n\nIf you do have a little extra space (223mmx223mm), you can also print the `slim_body_top_rim` ([STL](slim_body_top_rim.stl), [STEP](slim_body_top_rim.step)). It has a slightly larger rim making it easier to take the top off.\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/diy/pcb/README.md": {
    "summary": "The custom PCB for OpenBot serves as a carrier board for Arduino Nano and features integrated motor drivers, voltage divider circuit, and LED resistors. Users can plug in the Arduino and connect sensors and LEDs via Dupont cables. The latest version (v2) includes several upgrades, including relocation of a sensor for interrupt functionality, addition of a Power LED, updated components, and more convenient motor connectors. PCB assembly options include DIY, vendor, or turnkey solutions.",
    "content": "# Custom PCB\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nThe custom PCB acts as a carrier board for the Arduino Nano and integrates modern motor drivers, the voltage divider circuit and resistors for the LEDs. The Arduino is simply plugged into the pin header and all sensors and LEDs are connected via Dupont cables to the appropriate connectors.\n\n![PCB_2D](../../../docs/images/pcb_2d_v2.png)\n![PCB_3D](../../../docs/images/pcb_3d_v2.png)\n\nThe latest PCB is [version 2](v2). Here are the changes compared to [version 1](v1):\n\n- Move the right speed sensor to pin D3 to enable interrupt functionality\n- Add Power LED for main battery\n- Update some components which are more commonly available\n- Update voltage divider to 20k/10k for better precision\n- Change motor connectors to upright version for easier access\n\nIf you have already ordered [version 1](v1) of the PCB ([2D view](../../../docs/images/pcb_2d_v1.png), [3D view](../../../docs/images/pcb_3d_v1.png)), don't worry it will work fine. Just make sure to set the correct flag in the firmware.\n\nThe custom PCB involves the following steps:\n\n1) **Order the PCB**: Download the [Gerber](v2/gerber_v2.zip) files and order the PCB at the vendor of your choice. You can also order the PCB directly on [PCBWay](https://www.pcbway.com/project/shareproject/OpenBot__Turning_Smartphones_into_Robots.html) where we have shared a project for OpenBot.\n2) **Order the components:** Download the [BOM](v2/BOM_v2.csv) and order the compenents at the vendor of your choice, for example [LCSC](https://lcsc.com).\n3) **Assembly of the PCB:** You can either assemble the PCB yourself or have them assembled by a vendor. For automated assembly you will need the [Centroid File](v2/centroid_file_v2.csv). If you order the PCB at [JLCPCB](https://jlcpcb.com/), you can use their SMT assembly service. Then you will only need to order and solder the through-hole components yourself. We found this to be the most convenient, cheapest and fastest option. In [version 2](v2) of the PCB, we have updated the components to make sure all of them are available from [JLCPCB](https://jlcpcb.com/) directly.\n\nYou can also find vendors that will provide you a TurnKey solution covering all 3 steps. They will manufacture the PCB, source the components and assemble the PCB. This is very convenient and also not too expensive. However, delivery times are often very long (1-3 months).\n\nWhen requesting a quote at [PCBWay](https://www.pcbway.com/orderonline.aspx), you can select the assembly service after uploading the Gerber file.\n![Assembly Service](../../../docs/images/assembly_service.jpg)\nIn the next step, you will need to upload the [BOM](v2/BOM_v2.csv) and the [Centroid File](v2/centroid_file_v2.csv). Your quote will then be reviewed and updated within a few days. You can then choose to proceed with payment after reviewing cost and delivery time.\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/diy/README.md": {
    "summary": "OpenBot is an economical DIY robot chassis design featuring a 3D-printed body and readily available hobby hardware components. Builders can choose between two assembly options: the DIY approach employs a basic L298N motor driver and requires some wiring, while the PCB option offers a cleaner build and simplifies wiring. The robot utilizes 4 motors, 3 batteries, and a phone mount. Optional components include a speed sensor, ultrasonic sensor, on/off switch, LEDs, and an OLED display. The provided assembly instructions guide users through the DIY and PCB options, including motor installation, wiring, and optional component attachment. Once assembled, the robot requires flashing with Arduino Firmware to enable functionality.",
    "content": "# OpenBot DIY\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nWe have designed a body for a wheeled robot which relies on low-cost, readily available hobby hardware. You can find instructions for building you own robot below. If you have any further questions or concerns, please feel free to contact us. Happy robot building!\n\n## Chassis\n\n### 3D printing\n\nYou will need to print and assemble the following parts in order to build your OpenBot.\n\n#### Robot body\n\nThere are several options for the robot body depending on your needs and capabilities of your 3D printer. We encourage you to design and build your own, but here are some options as starting point: \n\n- [Regular body](cad/regular_body/README.md): This is the standard body we designed; it requires a build plate with least 240mmx150mm.\n- [Slim body](cad/slim_body/README.md): Since a lot of common 3D printers have a smaller build volume, we have also designed a smaller version without bumpers which fits on a 220mmx220mm build plate at 45 degrees.\n- [Glueable body](cad/glue_body/README.md): For printing on 3D printers with even smaller build volumes, there is also a modular body designed by @sloretz with serveral parts that need to be glued together; it fits on a 150mmx140mm build plate.\n- [Blocky body](cad/block_body/README.md): This body designed by @Christos-Ps provides multiple variants with options for extra space inside the shell and a lego-compatible top while maintaining a small footprint that requires only 221mmx150mm for printing.\n\n#### Phone mount\n\nIn addition, you will need to print a phone mount to be fixed to robot body.\n\n- phone_mount_bottom ([STL](../phone_mount/phone_mount_bottom.stl), [STEP](../phone_mount/phone_mount_bottom.step))\n- phone_mount_top ([STL](../phone_mount/phone_mount_top.stl), [STEP](../phone_mount/phone_mount_top.step))\n\n#### Cleaning\n\nBefore you proceed with the build, you may need to clean the 3D print.\n<p float=\"left\">\n  <img src=\"../../docs/images/clean_3d_print_1.jpg\" width=\"32%\" />\n  <img src=\"../../docs/images/clean_3d_print_2.jpg\" width=\"32%\" /> \n  <img src=\"../../docs/images/clean_3d_print_3.jpg\" width=\"32%\" />\n</p>\n\n### Alternatives\n\nIf you do not have access to a 3D printer, there are several Arduino robot car kits available which you can use as a starting point. These kits come with a chassis, motors and accessories. We recommend to get a basic kit, since you won't need a lot of the electronics and sensors of the more expensive kits. Here are some options:\n\n- Perseids DIY Robot Smart Car Chassis Kit ([EU](https://www.amazon.de/dp/B07DNXBNHY), [US](https://www.amazon.com/dp/B07DNXBFQN))\n- SZDoit 4WD Smart Metal Robot Car Chassis Kit ([US](https://www.amazon.com/dp/B083K4RKBP), [AE](https://www.aliexpress.com/item/33048227237.html))\n- Joy-it Robot Car Kit 01 ([EU](https://www.amazon.de/dp/B073ZGJF28))\n- Smart Car Kit 4WD Smart Robot Car Chassis Kit ([AE](https://www.aliexpress.com/item/4001238626191.html))\n\nYou will also need a phone mount. Here are some options:\n\n- Phone Mount ([EU](https://www.amazon.de/dp/B06XDYJNSR), [US](https://www.amazon.com/dp/B09CY8MC2R))\n\nYou can also get creative and build your own OpenBot chassis and phone mount using a material of your choice (e.g. wood, cardboard, styrofoam, etc.). If you do, please post some pictures on the [Slack channel](https://github.com/intel-isl/OpenBot#contact) so others can admire your creativity. Here is one example by [@custom-build-robots](https://custom-build-robots.com/roboter/openbot-dein-smartphone-steuert-ein-roboter-auto-chassis-bauen/13636):\n\n<p float=\"left\">\n  <img src=\"../../docs/images/chassis_cardboard_1.jpg\" width=\"32%\" />\n  <img src=\"../../docs/images/chassis_cardboard_2.jpg\" width=\"32%\" />\n  <img src=\"../../docs/images/chassis_cardboard_3.jpg\" width=\"32%\" />\n</p>\n\n## Assembly\n\nThere are two different options for assembly of the robot, DIY and PCB. The DIY approach relies on the popular L298N motor driver and is recommended for hobbyists with some electronics experience. It requires a fair amount of wiring, especially if all the sensors and LEDs are installed. However, all components are readily available in most contries and especially for single builds or just to try out the project, the DIY option is recommended. In order to reduce the wiring and make assembly easier, we have also developed a [custom PCB](pcb). This is recommended if you desire a cleaner build or want to build multiple OpenBots.\n\n### Bill of materials\n\nOur robot body relies on readily available hobby electronics. We provide links for Germany (EU) and the United States (US) with fast shipping. If you have the patience to wait a bit longer, you can also get the components a lot cheaper from AliExpress (AE). You will need the following components.\n\n#### Required components\n\n- 1x Arduino Nano ([EU](https://www.amazon.de/dp/B01MS7DUEM), [US](https://www.amazon.com/dp/B00NLAMS9C), [AE](https://www.aliexpress.com/item/32866959979.html))\n- 4x TT motors with tires ([EU](https://www.conrad.de/de/p/joy-it-com-motor01-getriebemotor-gelb-schwarz-passend-fuer-einplatinen-computer-arduino-banana-pi-cubieboard-raspbe-1573543.html), [US](https://www.amazon.com/dp/B081YQM55P), [AE](https://www.aliexpress.com/item/4000126948489.html))\n- 3x 18650 battery ([EU](https://www.conrad.de/de/p/conrad-energy-18650-usb-spezial-akku-18650-li-ion-3-7-v-1400-mah-1525536.html), [US](https://www.amazon.com/dp/B083K4XSKG), [AE](https://www.aliexpress.com/item/32352434845.html))\n- 1x 18650 battery holder([EU](https://www.amazon.de/dp/B075V25QJ9), [US](https://www.amazon.com/dp/B07DWQYD7H), [AE](https://www.aliexpress.com/item/33037738446.html))\n- 1x USB OTG cable ([EU](https://www.amazon.de/gp/product/B075M4CQHZ) ,[US](https://www.amazon.com/dp/B07LBHKTMM), [AE](https://www.aliexpress.com/item/10000330515850.html))\n- 1x spring or rubber band ([EU](https://www.amazon.de/gp/product/B01N30EAZO/), [US](https://www.amazon.com/dp/B008RFVWU2), [AE](https://www.aliexpress.com/item/33043769059.html))\n- 16x M3x25 screw ([EU](https://www.amazon.de/dp/B07KFL3SSV), [US](https://www.amazon.com/dp/B07WJL3P3X), [AE](https://www.aliexpress.com/item/4000173341865.html))\n- 16x M3 nut ([EU](https://www.amazon.de/dp/B07JMF3KMD), [US](https://www.amazon.com/dp/B071NLDW56), [AE](https://www.aliexpress.com/item/32977174437.html))\n- 6x M3x5 screw ([EU](https://www.amazon.de/dp/B01HBRG3W8), [US](https://www.amazon.com/dp/B07MBHMLL2), [AE](https://www.aliexpress.com/item/32892594230.html))\n- Dupont cables ([EU](https://www.amazon.de/dp/B07KYHBVR7), [US](https://www.amazon.com/dp/B07GD2BWPY), [AE](https://www.aliexpress.com/item/4000766001685.html))\n\n#### Optional components\n\n- 2 x Speed Sensor ([EU](https://www.conrad.de/de/p/joy-it-sen-speed-erweiterungsmodul-passend-fuer-einplatinen-computer-arduino-banana-pi-cubieboard-raspberry-pi-pc-1646891.html), [US](https://www.amazon.com/dp/B081W2TY6Q), [AE](https://www.aliexpress.com/i/32850602744.html))\n- 1x Ultrasonic Sensor ([EU](https://www.amazon.de/dp/B00LSJWRXU), [US](https://www.amazon.com/dp/B0852V181G/), [AE](https://www.aliexpress.com/item/32713522570.html))\n- 1x On/Off Switch ([EU](https://www.amazon.de/dp/B07QB22J62), [US](https://www.amazon.com/dp/B01N2U8PK0), [AE](https://www.aliexpress.com/item/1000005699023.html))\n- 2x Orange LED 5mm ([EU](https://www.amazon.de/gp/product/B01NCL0UTQ), [US](https://www.amazon.com/dp/B077XD7MVB), [AE](https://www.aliexpress.com/item/4000329069943.html))\n- 1x OLED display ([EU](https://www.amazon.de/dp/B079H2C7WH), [US](https://www.amazon.com/dp/B085NHM5TC), [AE](https://www.aliexpress.com/item/4001268387467.html))\n\n#### DIY components (Option 1)\n\n- 1x L298N Motor Driver ([EU](https://www.conrad.de/de/p/joy-it-motormodul-2-u-4-phasen-6-bis-12v-1573541.html), [US](https://www.amazon.com/dp/B085XSLKFQ), [AE](https://www.aliexpress.com/item/32994608743.html))\n- (Optional) Resistors (2x 150<span>&#8486;</span> for the LEDs and a 20 k<span>&#8486;</span> and 10k<span>&#8486;</span> for the voltage divider)\n- (Combo) 4x TT motors & tires + 2x L298N + dupont cables ([US](https://www.amazon.com/dp/B07ZT619TD))\n- (Combo) 4x TT motors & tires + wires + screws ([US](https://www.amazon.com/dp/B07DRGTCTP))\n\n#### PCB components (Option 2)\n\n- 1x [Custom PCB](pcb)\n- 5x Micro JST PH 2.0 cable ([EU](https://www.amazon.de/gp/product/B07449V33P), [US](https://www.amazon.com/dp/B09JZC28DP), [AE](https://www.aliexpress.com/item/32963304134.html))\n\n### Build instructions\n\n**Tip:** Click on the images to open them in full resolution in a new tab.\n\n#### Option 1: DIY\n\n<p float=\"left\">\n  <img src=\"../../docs/images/diy_parts.jpg\" height=\"300\" />\n  <img src=\"../../docs/images/wiring_diagram.png\" height=\"300\" /> \n</p>\n\n**Tip:** To make all the wiring easier you can build a small power distributor for the 5V and GND connections by soldering a 6x2 male header to a perfboard. Then connect the power distributor with the 5V / GND of the motor driver.\n\n1. Solder wires to the motors and add the encoder disks to the two front motors if you intend to use the speed sensors.\n    <p float=\"left\">\n      <img src=\"../../docs/images/add_wires_motor.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/add_disk_motor.jpg\" width=\"32%\" /> \n    </p>\n2. Insert the positive and negative leads of the two left motors into OUT1 (+) and OUT2 (-) of the L298N board. Insert the positive and negative leads of the two right motors into OUT4 (+) and OUT3 (-) of the L298N board.\n3. Mount the motors with eight M3x25 screws and nuts.\n    <p float=\"left\">\n      <img src=\"../../docs/images/attach_motors_1.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/attach_motors_2.jpg\" width=\"32%\" /> \n      <img src=\"../../docs/images/attach_motors_3.jpg\" width=\"32%\" />\n    </p>\n4. Mount the L298N with four M3x5 screws\n5. (Optional) Install the ultrasonic sensor and replace the angled connector with a straigt one (or carefully bend the pins).\n    <p float=\"left\">\n      <img src=\"../../docs/images/sonar_front.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/sonar_back.jpg\" width=\"32%\" /> \n      <img src=\"../../docs/images/sonar_bend_pins.jpg\" width=\"32%\" />\n    </p>\n6. (Optional) Install the orange LEDs for the indicator signals.\n    <p float=\"left\">\n      <img src=\"../../docs/images/led_insert.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/led_left.jpg\" width=\"32%\" /> \n      <img src=\"../../docs/images/led_right.jpg\" width=\"32%\" />\n    </p>\n7. Mount the bottom of the phone mount to the top plate using two M3x25 screws and nuts.\n    <p float=\"left\">\n      <img src=\"../../docs/images/install_camera_mount_1.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/install_camera_mount_2.jpg\" width=\"32%\" /> \n      <img src=\"../../docs/images/install_camera_mount_3.jpg\" width=\"32%\" />\n    </p>\n8. Insert the top of the phone mount and install the spring or rubber band.\n    <p float=\"left\">\n      <img src=\"../../docs/images/install_spring_1.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/install_spring_2.jpg\" width=\"32%\" /> \n    </p>\n9. Replace the angled connector with a straigt one (or carefully bend the pins) and then mount the speed sensors with one M3x5 screw each.\n    <p float=\"left\">\n      <img src=\"../../docs/images/install_speed_sensor_1.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/install_speed_sensor_2.jpg\" width=\"32%\" /> \n      <img src=\"../../docs/images/install_speed_sensor_3.jpg\" width=\"32%\" />\n    </p>\n10. Install the battery case (e.g. velcro).\n    <p float=\"left\">\n      <img src=\"../../docs/images/install_battery_1.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/install_battery_2.jpg\" width=\"32%\" /> \n      <img src=\"../../docs/images/install_battery_3.jpg\" width=\"32%\" />\n    </p>\n11. (Optional) Insert the on/off switch put it in the current path.\n    1. Push the switch into the appropriate opening until you hear a click.\n    2. Solder the red wires (12V) of the battery case and the power cable each to one of the pins of the switch. Connect the black wires (GND), and cover the connection with some heatshrink.\n    3. Fix the cables with some tape.\n    <p float=\"left\">\n      <img src=\"../../docs/images/install_switch_1.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/install_switch_2.jpg\" width=\"32%\" /> \n      <img src=\"../../docs/images/install_switch_3.jpg\" width=\"32%\" />\n    </p>\n12. (Optional) Attach the OLED display.\n13. Connect the PWM inputs of the L298N to pins D5, D6, D9 and D10 of the Arduino.\n14. Connect the speed sensors and ultrasonic sensor to 5V and GND.\n15. Connect pin D0 of the speed sensors to pins D2 (left) and D3 (right) of the Arduino.\n16. Connect pins Echo and Trigger of the ultrasonic sensor to pins D11 and D12 of the Arduino respectively.\n17. (Optional) Connect the LEDs to pins D4 (left) and D7 (right) of the Arduino and GND. We recommend to add a 150 Ohm resistor in series to limit the current draw.\n18. (Optional) Connect the voltage divider to pin A7 of the Arduino. It is used to measure the battery voltage.\n19. (Optional) Connect the OLED display (SSD1306 chip) via the I2C bus to the Arduino Nano\n    1. Connect the VIN and GND pins of the display to 5V and GND.\n    2. Connect the SCL pin of the display to the A5 pin.\n    3. Connect the SDA pin of the display to the A4 pin.\n20. Connect the power cables to +12V and GND of the L298N.\n21. Connect the USB cable to the Arduino and route it through the top cover.\n22. Insert six M3 nuts into the bottom plate and mount the top cover with six M3x25 screws.\n23. Install the wheels.\n\n#### Option 2: Custom PCB\n\n1. Solder wires with Micro JST PH 2.0 connectors to the motors and add the encoder disks to the two front motors if you intend to use the speed sensors.\n    <p float=\"left\">\n      <img src=\"../../docs/images/add_wires_motor.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/add_disk_motor.jpg\" width=\"32%\" /> \n    </p>\n2. Mount the motors with eight M3x25 screws and nuts.\n    <p float=\"left\">\n      <img src=\"../../docs/images/attach_motors_1.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/attach_motors_2.jpg\" width=\"32%\" /> \n      <img src=\"../../docs/images/attach_motors_3.jpg\" width=\"32%\" />\n    </p>\n3. Connect the left two motors to M3 and M4 and the right two motors to M1 and M2.\n    <p float=\"left\">\n      <img src=\"../../docs/images/connect_motors_pcb.jpg\" width=\"32%\" />\n    </p>\n4. Mount the PCB with four M3x5 screws and the motors with eight M3x25 screws and nuts.\n    <p float=\"left\">\n      <img src=\"../../docs/images/attach_pcb.jpg\" width=\"32%\" />\n      <img src=\"../../docs/images/chassis_motors_pcb.jpg\" width=\"32%\" />\n    </p>\n5. Follow steps 5-12 from the DIY option.\n6. Connect the ultrasonic sensor (VCC/+, Trig, Echo, GND/-) to the 4-pin header labeled *SONAR* on the PCB.\n    <p float=\"left\">\n      <img src=\"../../docs/images/connect_sonar_sensor.jpg\" width=\"32%\" />\n    </p>\n7. Connect the left and right indicator signals (orange LEDs) to the 2-pin headers labeled *SIGNAL_L* and *SIGNAL_R* on the PCB. The longer leg is + and the shorter one -.\n8. Connect the left and right speed sensors (VCC/+, GND/-, D0) to the 3-pin headers labeled *SPEED_L* and *SPEED_R*.\n9. (Optional) Connect the OLED display (SSD1306 chip) to the IO2 header on the PCB.\n    1. Connect the VIN and GND pins of the display to 5V and GND.\n    2. Connect the SCL pin of the display to the A5 pin.\n    3. Connect the SDA pin of the display to the A4 pin.\n10. Connect the power cables to Vin (Micro JST PH 2.0 connector) of the PCB.\n11. Follow steps 21-23 from the DIY option.\n\n## Next\n\nFlash the [Arduino Firmware](../../firmware/README.md)\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/lite/README.md": {
    "summary": "ITE's eSpace provides an educational curriculum for AI and robotics utilizing the OpenBot Lite platform. The curriculum offers:\n\n* Assembly and configuration of OpenBot Lite (Arduino or micro:bit)\n* Person following capabilities\n* Autonomous driving policy learning\n* Step-by-step video guides for both Arduino and micro:bit versions\n\nEducators have tested the curriculum, and over 100 students have benefited from it. The curriculum is designed for home-based learning with a 2.4m x 1.8m playfield.",
    "content": "# OpenBot for Education\r\n\r\n<p align=\"center\">\r\n  <span>English</span> |\r\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\r\n  <a href=\"README.de-DE.md\">Deutsch</a> |\r\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\r\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\r\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\r\n</p>\r\n\r\nITE's eSpace has developed a [curriculum](#curriculum) for economical and scalable AI and robotics education around the OpenBot software stack. It comes in the form of [step-by-step YouTube videos](#step-by-step-video-guides) which guides you through the assembly of the [OpenBot Lite](#openbot-lite-arduino), installing the necessary software, using the person following and training and deploying your own autonomous driving policy.\r\n\r\n## OpenBot Lite\r\n\r\nOpenBot Lite is a smaller and simplified variant of the OpenBot DIY version. This minimalist version was developed by ITE's eSpace to leverage the great potential of the OpenBot software stack for economical and scalable AI and robotics education. OpenBot Lite supports either a [micro:bit](https://microbit.org/) (+ propriotary IO board) or Ardunio Nano. The image below shows the micro:bit variant on the left and the Arduino variant on the right.\r\n\r\n<p float=\"left\">\r\n  <img src=\"../../docs/images/openbot_lite.jpg\" width=\"480px\" />\r\n</p>\r\n\r\n## Curriculum\r\n\r\nThe curriculum has been tested by educators in South Korea and Germany and more than 100 students have already learned about AI and robotics using this curriculum. Here are some results of our online trainings:\r\n\r\n* [South Korea](https://fb.watch/bDK2Vjgm3g/)\r\n* [Germany](https://www.facebook.com/EspaceCW/posts/5087394677946975)\r\n\r\nPerson following in action:\r\n\r\n<p float=\"left\">\r\n  <img src=\"../../docs/images/objectnav_320.gif\" width=\"480px\" />\r\n</p>\r\n\r\nThe policy learning is based on a 2.4m x 1.8m playfield with a street layout. The robot learns to drive autonomously on this street and avoid obstacles. This makes the curriculum ready for home-based learning.\r\n\r\n<p float=\"left\">\r\n  <img src=\"../../docs/images/playfield.jpg\" width=\"480px\" />\r\n</p>\r\n\r\nTrained Autopilot in action:\r\n\r\n<p float=\"left\">\r\n  <img src=\"../../docs/images/autopilot_320.gif\" width=\"480px\" />\r\n</p>\r\n\r\n## Step-by-Step Video Guides\r\n\r\nBelow are the YouTube playlists in sequence:\r\n\r\nArduino Version:\r\n1. [Assembly of OpenBot Lite (Arduino)](https://youtube.com/playlist?list=PLNKFHX5MRn52za5VeteCmvLNcL1Kowtw2)\r\n2. [Person Following](https://youtube.com/playlist?list=PLNKFHX5MRn501oWvPbKzP1zkcqhLU5TOh)\r\n3. [Policy Learning](https://youtube.com/playlist?list=PLNKFHX5MRn5233AyCWhcn71JdB9qIEa-E)\r\n\r\nmicro:bit Version:\r\n1. [Assembly of OpenBot Lite (micro:bit)](https://youtube.com/playlist?list=PLNKFHX5MRn51xVKHo2VCY-KbOFQrkOm2R)\r\n2. [Person Following](https://youtube.com/playlist?list=PLNKFHX5MRn51crWis1lwFJXj69DN9evG1)\r\n3. [micro:bit Code Explained](https://youtube.com/playlist?list=PLNKFHX5MRn51DfspxVo16BkfXz8y9uR7N)\r\n4. [Policy Learning](https://youtube.com/playlist?list=PLNKFHX5MRn5233AyCWhcn71JdB9qIEa-E)\r\n\r\n## Acknowledgement\r\n\r\nIf you find this material helpful, please like the videos and subscribe to the eSpace Channel. If you were able to build your own OpenBot Lite, get the person following and/or Autopilot to work, feel free to share your success stories and OpenBot videos on social media and on [Slack](https://join.slack.com/t/openbot-community/shared_invite/zt-jl8ygxqt-WNRNi9yzh7Lu60qui6Nh6w). You can also support and follow Willam Tan and the eSpace team who are developing the education materials on social media.\r\n\r\n* [OpenBot Slack Channel](https://join.slack.com/t/openbot-community/shared_invite/zt-jl8ygxqt-WNRNi9yzh7Lu60qui6Nh6w)\r\n* [eSpace's Facebook](https://www.facebook.com/EspaceCW)\r\n* [eSpace's Instagram](https://www.instagram.com/EspaceCW/)\r\n\r\nWe are looking forward to your success stories and videos.  Have fun!\r\n\r\n## Next\r\n\r\nFlash the [Arduino Firmware](../../firmware/README.md)\r\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/mtv/pcb/README.md": {
    "summary": "The Mars Terrain Vehicle (MTV) has a control architecture with high-level commands computed on a smartphone via OpenBot, passed to an ESP32 board for PWM and sensor communication. The ESP32 communicates with the smartphone via serial-USB.\n\nThe MTV's component architecture includes six DC motors with planetary gearboxes and encoders, heavy-duty motor drivers, and a rechargeable LiPo battery. The PCB is split into a main PCB for major components and a power distribution PCB for converting power. Custom 2-layer PCBs were designed for power generation and control, featuring modularity, component separation, and future expansion capability.",
    "content": "## Electronics and Control Development \n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n### Control architecture overview of the MTV\n\nThe MTV control architecture is of cascaded type. The high level commands are computed on a smartphone, running the Intel [OpenBot](https://www.openbot.org/) framework. These commands are then passed to a ESP32 low-level control board which handles PWM generation as well as communication with the different MTV sensors (e.g. encoders, sonars and so on).\n\n<p align=\"center\">\n  <img src=\"../../../docs/images/MTV/Ctrl_arch.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nThe ESP32 low-level control board communicates with the smartphone through a dedicated serial-USB interface. \n\n### Component architecture and PCB development  \n\nThe locomotion of the MTV is built around six 12V DC motors, namely three motors on each side of the rover. Each motor is equipped with a planetary gearbox as well as an inbuilt magnetic encoder, allowing velocity estimation. Therefore, 2 single motor drivers were selected for the development.  Due to the required high current consummation, heavy duty motor drivers were added to the design. Off-the-shelf motor drivers were proposed for this development due to the modularity i.e., ability to change motor drivers when needed. The overall component architecture of the MTV is illustrated in the follwing figure:\n\n<p align=\"center\">\n  <img src=\"../../../docs/images/MTV/Comp_arch.svg\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\nThe Overall size was a considered as one of the limiting factors while designing the PCB. Therefore, the design of the PCB was split in to two main parts as illustrated below. i.e., Main PCB and Power distribution PCB. The Main PCB accommodates the main components of the system, such as ESP32 MCU, 2 Motor drivers, motor connections, etc. The power distribution PCB was designed to covert the 11.1V-12V input battery supply in to 12V and 5V. i.e. 12V supply: Motor drivers. 5V supply: ESP 32, Motor Encoders, Front & rear lights. A rechargeable 11.1V LiPo battery was used for the design of the MTV. Therefore, a voltage display was added as a battery level indicator.\n\n<p align=\"center\">\n  <img src=\"../../../docs/images/MTV/PCB_split.svg\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n\nA set of custom build 2-layer PCBs were designed for power generation and control purposes:\n<p align=\"center\">\n  <img src=\"../../../docs/images/MTV/PCB_1.jpg\" width=\"600\" alt=\"App GUI\"/>\n</p>\n<p align=\"center\">\n  <img src=\"../../../docs/images/MTV/PCB_2.jpg\" width=\"600\" alt=\"App GUI\"/>\n</p>\n<p align=\"center\">\n  <img src=\"../../../docs/images/MTV/PCB_3.jpg\" width=\"600\" alt=\"App GUI\"/>\n</p>\nAll the component interface ports of the PCB were designed with the modularity and easy plug-and-play capability. Moreover, 12V power lines and 5V signal lines were kept apart in order to minimize potential interferences. Few additional 5V and 12 V power output ports were added to the design in order to allow future expansions. Moreover, additional pin headers were added in parallel with the ESP32, so the users can use the PCB as a development board for future expansion activities. Prototyped (partially wired and with ESP 32 and motor drivers) PCBs are illustrated in the following figures: \n<p align=\"center\">\n  <img src=\"../../../docs/images/MTV/PCB_4.jpg\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n<p align=\"center\">\n  <img src=\"../../../docs/images/MTV/PCB_5.jpg\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/mtv/README.md": {
    "summary": "The MTV body is an all-terrain alternative to the original OpenBot vehicle. It is based on inexpensive and easily printable components. The design is inspired by exploration vehicle concepts developed over the past decades for lunar and Martian exploration. The MTV is designed around a set of 6 actuated wheels organized in a Rocker-Bogie configuration. It contains a 6-axis Inertial Measurement Unit (IMU), a voltage display, a dedicated power control board, multiple power switches, and a Micro USB port for programming and debugging.",
    "content": "# OpenBot: Multi-Terrain Vehicle (MTV) body\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nWe here propose an all-terrain alternative to the original [OpenBot](https://www.openbot.org/) vehicle. Developed in collaboration with **Ivy Tech LTD**, the Multi-Terrain Vehicle (MTV) is also based on inexpensive and easily printable components. The MTV is inspired by several exploration vehicle concepts developed over the past decades for lunar and Martian exploration. The MTV is designed around a set of 6 actuated wheels, organized in a Rocker-Bogie configuration. Unlike most lunar or Martian rovers, the wheels cannot rotate radially. The vehicle therefore operates in the same way as a tank, which makes manual control rather intuitive.\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/MTV.jpg\" width=\"400\" alt=\"App GUI\"/>\n</p>\n\n## I. 3D printing\n\nYou will need to print the following parts in order to build your OpenBot MTV.\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/CAD_Assembly.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\n<table>\n    <thead>\n        <tr>\n            <th>ID </th>\n            <th>Group</th>\n            <th>Item Name</th>\n            <th>Quantity</th>\n            <th>Picture (not to scale)</th>\n            <th>Material</th>\n            <th>Duration</th>\n            <th>Cost</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>A1</td>\n            <td rowspan=3>Motor assembly</td>\n            <td>Motor Enclosure Top <br> (<a href=\"cad/MotorAssembly/MotorEnclosure_Top.stl\">STL</a>, <a href=\"cad/MotorAssembly/MotorEnclosure_Top.step\">STEP</a>) </td>\n            <td>6</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A1.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td rowspan=2>498g</td>\n            <td rowspan=2>36h</td>\n            <td rowspan=2>â‚¬23.51</td>\n        </tr>\n        <tr>\n            <td>A2</td>\n            <td>Motor Enclousre Bottom <br> (<a href=\"cad/MotorAssembly/MotorEnclosure_Bottom.stl\">STL</a>, <a href=\"cad/MotorAssembly/MotorEnclosure_Bottom.step\">STEP</a>) </td>\n            <td>6</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A2.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A3</td>\n            <td>Motor Bracket <br> (<a href=\"cad/MotorAssembly/Motor_Bracket.stl\">STL</a>, <a href=\"cad/MotorAssembly/Motor_Bracket.step\">STEP</a>) </td>\n            <td>6</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A3.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>251g</td>\n            <td>17.5h</td>\n            <td>â‚¬11.98</td>\n        </tr>\n        <tr>\n            <td>A4</td>\n            <td rowspan=4>Joints</td>\n            <td>90 deg Joint <br> (<a href=\"cad/Joints/90deg_Joint.stl\">STL</a>, <a href=\"cad/Joints/90deg_Joint.step\">STEP</a>) </td>\n            <td>2</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A4.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td rowspan=4>228g</td>\n            <td rowspan=4>20.5h</td>\n            <td rowspan=4>â‚¬15.05</td>\n        </tr>\n        <tr>\n            <td>A5</td>\n            <td>100 deg Joint <br> (<a href=\"cad/Joints/100deg_Joint.stl\">STL</a>, <a href=\"cad/Joints/100deg_Joint.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A5.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A6</td>\n            <td>100 deg Joint Mirror <br> (<a href=\"cad/Joints/100deg_Joint_Mirror.stl\">STL</a>, <a href=\"cad/Joints/100deg_Joint_Mirror.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A6.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A7</td>\n            <td>End Joint <br> (<a href=\"cad/Joints/End_Joint.stl\">STL</a>, <a href=\"cad/Joints/End_Joint.step\">STEP</a>) </td>\n            <td>2</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A7.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A8</td>\n            <td rowspan=3>Legs</td>\n            <td>Front Leg <br> (<a href=\"cad/Legs/Front_Leg.stl\">STL</a>, <a href=\"cad/Legs/Front_Leg.step\">STEP</a>) </td>\n            <td>4</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A8.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td rowspan=3>317g</td>\n            <td rowspan=3>22.5h</td>\n            <td rowspan=3>â‚¬14.97</td>\n        </tr>\n        <tr>\n            <td>A9</td>\n            <td>Mid Leg <br> (<a href=\"cad/Legs/Mid_Leg.stl\">STL</a>, <a href=\"cad/Legs/Mid_Leg.step\">STEP</a>) </td>\n            <td>2</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A9.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A10</td>\n            <td>Rear Leg <br> (<a href=\"cad/Legs/Rear_Leg.stl\">STL</a>, <a href=\"cad/Legs/Rear_Leg.step\">STEP</a>) </td>\n            <td>2</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A10.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A11</td>\n            <td>Bearing Cover</td>\n            <td>Bearing Cover <br> (<a href=\"cad/BearingCover/BearingCover.stl\">STL</a>, <a href=\"cad/BearingCover/BearingCover.step\">STEP</a>) </td>\n            <td>4</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A11.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>13g</td>\n            <td>1.5h</td>\n            <td>â‚¬0.60</td>\n        </tr>\n        <tr>\n            <td>A12</td>\n            <td>Phone Mount Platform</td>\n            <td>Phone Mount Platform <br> (<a href=\"cad/PhoneMount/Phone_Mount.stl\">STL</a>, <a href=\"cad/PhoneMount/Phone_Mount.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A12.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>19g</td>\n            <td>2h</td>\n            <td>â‚¬0.91</td>\n        </tr>\n        <tr>\n            <td>A13</td>\n            <td rowspan=4>Front Buffer</td>\n            <td>Name Front <br> (<a href=\"cad/Buffer/Name_Front.stl\">STL</a>, <a href=\"cad/Buffer/Name_Front.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A13.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td rowspan=4>228g</td>\n            <td rowspan=4>20.5h</td>\n            <td rowspan=4>â‚¬15.04</td>\n        </tr>\n        <tr>\n            <td>A14</td>\n            <td>Name Back <br> (<a href=\"cad/Buffer/Name_Back.stl\">STL</a>, <a href=\"cad/Buffer/Name_Back.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A14.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A15</td>\n            <td>Buffer Left <br> (<a href=\"cad/Buffer/Buffer_Left.stl\">STL</a>, <a href=\"cad/Buffer/Buffer_Left.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A15.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A16</td>\n            <td>Buffer Right <br> (<a href=\"cad/Buffer/Buffer_Right.stl\">STL</a>, <a href=\"cad/Buffer/Buffer_Right.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A16.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A17</td>\n            <td rowspan=8>Compartment </td>\n            <td>Compartment Rear <br> (<a href=\"cad/Compartment/Compartment_Rear.stl\">STL</a>, <a href=\"cad/Compartment/Compartment_Rear.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A17.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>413g</td>\n            <td>32h</td>\n            <td>â‚¬22.75</td>\n        </tr>\n        <tr>\n            <td>A18</td>\n            <td>Compartment Front <br> (<a href=\"cad/Compartment/Compartment_Front.stl\">STL</a>, <a href=\"cad/Compartment/Compartment_Front.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A18.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>316g</td>\n            <td>22h</td>\n            <td>â‚¬17.42</td>\n        </tr>\n        <tr>\n            <td>A19</td>\n            <td>Roof Front <br> (<a href=\"cad/Compartment/Roof_Front.stl\">STL</a>, <a href=\"cad/Compartment/Roof_Front.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A19.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>58g</td>\n            <td>5.5h</td>\n            <td>â‚¬3.19</td>\n        </tr>\n        <tr>\n            <td>A20</td>\n            <td>Roof Rear <br> (<a href=\"cad/Compartment/Roof_Rear.stl\">STL</a>, <a href=\"cad/Compartment/Roof_Rear.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A20.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>140g</td>\n            <td>13.5h</td>\n            <td>â‚¬7.73</td>\n        </tr>\n        <tr>\n            <td>A21ab</td>\n            <td>Battery Mount P1 & P2 <br> (<a href=\"cad/Compartment/Compartment_Battery_Mount-P1.stl\">STL</a>, <a href=\"cad/Compartment/Compartment_Battery_Mount-P1.step\">STEP</a>)\n            <br> (<a href=\"cad/Compartment/Compartment_Battery_Mount-P2.stl\">STL</a>, <a href=\"cad/Compartment/Compartment_Battery_Mount-P2.step\">STEP</a>) </td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A21ab.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>15g</td>\n            <td>1.5h</td>\n            <td>â‚¬0.80</td>\n        </tr>\n        <tr>\n            <td>A22</td>\n            <td>Light End Caps <br> (<a href=\"cad/Compartment/Headlight_Rear.stl\">STL</a>, <a href=\"cad/Compartment/Headlight_Rear.step\">STEP</a>)</td>\n            <td>4</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A22.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td rowspan=3>47g</td>\n            <td rowspan=3>4h</td>\n            <td rowspan=3>â‚¬2.58</td>\n        </tr>\n        <tr>\n            <td>A23</td>\n            <td>Head Light <br> (<a href=\"cad/Compartment/Headlight_Front.stl\">STL</a>, <a href=\"cad/Compartment/Headlight_Front.step\">STEP</a>)</td>\n            <td>4</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A23.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n        <tr>\n            <td>A24</td>\n            <td>Battery Access Lid <br> (<a href=\"cad/Compartment/Compartment_Door.stl\">STL</a>, <a href=\"cad/Compartment/Compartment_Door.step\">STEP</a>)</td>\n            <td>1</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/A25.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n        </tr>\n    </tbody>\n</table>\n\nFor the above parts, your build plate needs to be at least 240mmx150mm.\n\nOn an Ultimaker S5, we achieved good results with the following settings:\n\n- layer height: 0.2mm\n- wall thickness: 1.5mm\n- infill density: 20%\n- infill pattern: grid\n- print speed 80 mm/s\n- no support\n\n## II. Electro-Mechanical Assembly\n\n### II.1. Bill of materials\n\nOur robot body relies on readily available hobby electronics. We provide links for Germany (EU) and the United States (US) with fast shipping. If you have the patience to wait a bit longer, you can also get the components a lot cheaper from AliExpress (AE). You will need the following components.\n\n<table>\n    <thead>\n        <tr>\n            <th>ID </th>\n            <th>Description</th>\n            <th>Picture</th>\n            <th>Supplier</th>\n            <th>Unit Price</th>\n            <th>Quantity</th>\n            <th>Cost</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>O1</td>\n            <td>JGB37-520 DC-Motor with encoders - 12V | 178RPM </td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O1.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://de.aliexpress.com/item/4001339371886.html?gatewayAdapt=glo2deu&spm=a2g0s.9042311.0.0.1fe54c4dR1WTdj/\">AE</a></td>\n            <td>$8.93 | â‚¬8.12</td>\n            <td>6</td>\n            <td>$53.58 | â‚¬48.72</td>\n        </tr>\n        <tr>\n            <td>O2</td>\n            <td>2.8\" Talon Tires (2 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O2.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td> <a href=\"https://www.robotshop.com/en/28-talon-tires-pair.html\">US</a> | <a href=\"https://www.robotshop.com/eu/en/28-talon-tires-pair.html\">EU</a></td>\n            <td>$26.95 | â‚¬23.06</td>\n            <td>6</td>\n            <td>$161.7 | â‚¬138.36</td>\n        </tr>\n        <tr>\n            <td>O3</td>\n            <td>7-Core Cable 0.5 mmÂ² (5m)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O3.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n          <td>  <a href=\"https://www.amazon.com/Heavy-Gauge-Conductor-Trailer-Cable/dp/B01N3Q0YGS/ref=sr_1_16?crid=3SK9Y7DSOR0OL&keywords=caravan+cable+7+wire&qid=1649847035&sprefix=carava+cable+7+wire%2Caps%2C190&sr=8-16\">US</a> | <a href=\"https://www.amazon.de/-/en/1119757-Classic-Control-Protective-Conductor/dp/B08CY2WPM4/ref=sr_1_5?crid=1QGOB5LF0GZYO&keywords=7+adriges+kabel+0%2C5mm%C2%B2&qid=1644173962&sprefix=7+core+cable+0.5mm+%2Caps%2C289&sr=8-5\">EU</a></td>\n            <td> $25.53 | â‚¬20.61</td>\n            <td>0.25</td>\n            <td>$6.38 | â‚¬5.15</td>\n        </tr>\n        <tr>\n            <td>O4</td>\n            <td>D-Line cable duct. 20mm x 10mm x 1m (2 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O4.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/D-Line-Raceway-1D3015W-Electrical-Paintable/dp/B07KFNYR7G/ref=sr_1_10?crid=137L39X59R8AQ&keywords=D-Line%2Bcable%2Bduct&qid=1649851731&refinements=p_36%3A1253503011&rnid=386442011&s=electronics&sprefix=d-line%2Bcable%2Bduct%2Caps%2C409&sr=1-10&th=1\">US</a> | <a href=\"https://www.amazon.de/-/en/D-Line-Micro-Cable-Management-Strip-White/dp/B082WVQXT5/ref=sr_1_fkmr0_1?crid=3CBV1RRPR6K9B&keywords=d-line%2Bmicro%2B%2Bkabelkanal%2B(2%2Bmeter)%2C%2Bselbstklebende%2Bkabelabdeckungen%2C%2Belektrische%2Bkabelf%C3%BChrung%2C%2Bbeliebte%2Bkabelmanagementl%C3%B6sung%2C%2B20%2Bmm%2B(b)%2Bx%2B10%2Bmm%2B(h)%2B-%2B2%2Bx%2B1%2Bm%2Bl%C3%A4nge%2B-%2Bschwarz&qid=1644149200&sprefix=d-line%2Bmicro%2B%2Bcable%2Btrunking%2B2-meter%2Bself-adhesive%2Bcable%2Bcovers%2Belectrical%2Bcable%2Btidy%2Bpopular%2Bcable%2Bmanagement%2Bsolution%2B20mm%2Bw%2Bx%2B10mm%2Bh%2B-%2B2%2Bx%2B1%2Bmeter%2Blengths%2B-%2Bblack%2B%2Caps%2C381&sr=8-1-fkmr0&th=1\">EU</a></td>\n            <td>$12.00 | â‚¬9.99</td>\n            <td>1</td>\n            <td>$12.00 | â‚¬9.99</td>\n        </tr>\n        <tr>\n            <td>O5</td>\n            <td>PG7 Cable Gland 3~6.5mm (50 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O5.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n          <td>  <a href=\"https://www.amazon.com/ARTGEAR-Waterproof-Adjustable-Connector-Protector/dp/B07JH2LPZF/ref=sr_1_11?crid=1UH8URDCXAHJJ&keywords=Cable+Gland+Set+Plastic+Cable+Glands+Adjustable+PG7+Waterproof+Closure+Cable+Screw+Connection+for+Diameter+3.5+mm+-+6.5+mm+Black+Pack+of+50&qid=1649852081&sprefix=cable+gland+set+plastic+cable+glands+adjustable+pg7+waterproof+closure+cable+screw+connection+for+diameter+3.5+mm+-+6.5+mm+black+pack+of+50+%2Caps%2C243&sr=8-11\"> US </a> | <a href=\"https://www.amazon.de/-/en/Plastic-Adjustable-Waterproof-Connection-Diameter/dp/B08Q458H3N/ref=sr_1_fkmr0_1?crid=1H5VCAQKXD2XZ&keywords=pg7+kabelverschraubung%2C+50+st%C3%BCck%2C+3-6%2C5+mm%2C+verstellbar%2C+wasserdicht%2C+kabelverschraubungen%2C+verbindungsst%C3%BCck+mit+dichtungen&qid=1644149525&sprefix=pg7+cable+gland+50+pack+3+6.5mm+adjustable+waterproof+cable+glands+joints+connector+with+gaskets+%2Caps%2C80&sr=8-1-fkmr0\">EU</a></td>\n            <td>$8.99 | â‚¬9.99</td>\n            <td>0.5</td>\n            <td>$4.49 | â‚¬4.99</td>\n        </tr>\n        <tr>\n            <td>O6</td>\n            <td>MR126ZZ Ball Bearings 6x12x4mm (4 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O6.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://de.aliexpress.com/item/1005001697683913.html?gatewayAdapt=glo2deu&spm=a2g0s.9042311.0.0.1fe54c4dR1WTdj\">AE</a></td>\n            <td>$5.52 | â‚¬3.45</td>\n            <td>1</td>\n            <td>$5.52 | â‚¬3.45</td>\n        </tr>\n        <tr>\n            <td>O7</td>\n            <td>INJORA 90mm RC Car Spring Shock Absorber (2pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O7.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://de.aliexpress.com/item/4000309686709.html?gatewayAdapt=glo2deu&spm=a2g0o.productlist.0.0.17b17ca7oMXyhJ&algo_pvid=c7d8ba55-28b2-4d27-97e4-f338994958f7&algo_exp_id=c7d8ba55-28b2-4d27-97e4-f338994958f7-14&pdp_ext_f=%7B%22sku_id%22%3A%2210000001286270094%22%7D&pdp_pi=-1%3B8.3%3B-1%3B-1%40salePrice%3BUSD%3Bsearch-mainSearch\">AE</a></td>\n            <td>$8.30 | â‚¬7.99</td>\n            <td>1</td>\n            <td>$8.30 | â‚¬7.99</td>\n        </tr>\n        <tr>\n            <td>O8</td>\n            <td>AXSPEED RC Car LED 4.2v-6v White 17mm (2 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O8.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.aliexpress.com/item/1005003306484898.html?spm=a2g0s.9042311.0.0.d4954c4dpsjiiC\">AE</a></td>\n            <td>$7.43 | â‚¬6.87</td>\n            <td>1</td>\n            <td>$7.43 | â‚¬6.87</td>\n        </tr>\n        <tr>\n            <td>O9</td>\n            <td>AXSPEED RC Car LED 4.2v-6v Red 17mm (2 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O9.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.aliexpress.com/item/1005003306484898.html?spm=a2g0s.9042311.0.0.d4954c4dpsjiiC\">AE</a></td>\n            <td>$7.43 | â‚¬6.87</td>\n            <td>1</td>\n            <td>$7.43 | â‚¬6.87</td>\n        </tr>\n        <tr>\n            <td>O10</td>\n            <td>Vibration Isolators M3 x 8mm Studs (4 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O10.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/MroMax-Rubber-Vibration-Isolator-Absorber/dp/B07Z76J5N5/ref=sr_1_5?crid=2LSR8ZMHRIL2O&keywords=m3+rubber+mount+shock+absorbers&qid=1649862366&sprefix=keesin+m3+rubber+mounts+shock+absorbers+%2Caps%2C362&sr=8-5\">US</a> | <a href=\"https://www.amazon.de/-/en/gp/product/B076SSPHP6/ref=ppx_yo_dt_b_asin_title_o03_s01?ie=UTF8&psc=1\">EU</a></td>\n            <td>$8.09 | â‚¬9.49</td>\n            <td>1</td>\n            <td>$8.09 | â‚¬9.49</td>\n        </tr>\n        <tr>\n            <td>O11</td>\n            <td>Zeadio Universal Smartphone holder</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O11.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td> <a href=\"https://www.amazon.com/SharingMoment-Smartphone-Horizontal-Rotatable-Adjustable/dp/B07S8TTH34/ref=sr_1_4?crid=X7XQ9LC110JJ&keywords=Zeadio+Smartphone+Tripod+Adapter%2C+Mobile+Phone+Holder&qid=1649862548&refinements=p_36%3A2491155011&rnid=2491154011&s=wireless&sprefix=zeadio+smartphone+tripod+adapter%2C+mobile+phone+holder+%2Caps%2C577&sr=1-4\">US</a> | <a href=\"https://www.amazon.de/-/en/Zeadio-Smartphone-Tripod-Adapter-Mobile/dp/B06XDYJNSR/ref=sr_1_8?crid=2ZH6V545D45E3&keywords=zeadio%2Buniversal%2Bsmartphone%2Bhalterung&qid=1644150427&sprefix=zeadio%2Buniversal%2Bsmartphone%2Bholder%2Caps%2C104&sr=8-8&th=1\">EU</a></td>\n            <td>$11.99 | â‚¬10.99</td>\n            <td>1</td>\n            <td>$11.99 | â‚¬10.99</td>\n        </tr>\n        <tr>\n            <td>O12</td>\n            <td>DC 12-24 V Car Voltmeter</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O12.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Nilight-Voltmeter-Waterproof-VoltVolt-Motorcycle/dp/B06ZZJ48VQ/ref=sr_1_fkmr1_2?crid=376857DCCJICB&keywords=mini+led+digital+voltmeter+batterietester+12+volt+%2F+24+volt+voltmeter&qid=1649862763&sprefix=mini+led+digital+voltmeter+batterietester+12+volt+%2F+24+volt+voltmeter%2Caps%2C404&sr=8-2-fkmr1\">US</a> | <a href=\"https://www.amazon.de/-/en/Intckwan-Digital-Voltmeter-Waterproof-Motorcycle/dp/B09T5XRYM9/ref=sr_1_5?crid=1GPFOX9O2VX85&keywords=mini+led+digital+voltmeter+batterietester+12+volt+%2F+24+volt+voltmeter&qid=1649862700&sprefix=mini+led+digital+voltmeter+battery+tester+12+volt+%2F+24+volt+voltmeter%2Caps%2C91&sr=8-5\">EU</a></td>\n            <td>$10.99 | â‚¬11.88</td>\n            <td>1</td>\n            <td>$10.99 | â‚¬11.88</td>\n        </tr>\n        <tr>\n            <td>O13</td>\n            <td>Mini Rocker Switch (20 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O13.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/DaierTek-250VAC-Rocker-KCD1-101-Plastic/dp/B07S2QJKTX/ref=sr_1_4?keywords=RUNCCI-YUN+20Pcs+Mini+Rocker+Switch&qid=1650638471&sr=8-4\">US</a> | <a href=\"https://www.amazon.de/-/en/RUNCCI-Rocker-Switches-Household-Appliances/dp/B07MW92CW8/ref=sr_1_2?keywords=RUNCCI-YUN+20+St%C3%BCck+Mini-Wippschalter&qid=1650638352&sr=8-2\">EU</a></td>\n            <td>$15.98 | â‚¬9.44</td>\n            <td>0.15</td>\n            <td>$2.4 | â‚¬1.42</td>\n        </tr>\n        <tr>\n            <td>O14</td>\n            <td>Duttek Micro USB Panel Mount Cable</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O14.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Duttek-Angled-Extension-Motorcycle-Dashboard/dp/B08RSGYV1S/ref=sr_1_1?keywords=Duttek+90+Degree+Micro+USB+Panel+Mount+Cable+Micro+USB+Mount+Extension+Cable+Male+to+Female+for+Car+Boat+Motorcycle+Truck+Dashboard+30cm&qid=1650638585&sr=8-1\">US</a> | <a href=\"https://www.amazon.de/-/en/Duttek-Degree-Extension-Motorcycle-Dashboard/dp/B08RSGYV1S/ref=psdc_1365661031_t1_B07ZCZ8NL1\">EU</a></td>\n            <td>$10.68 | â‚¬11.44</td>\n            <td>1</td>\n            <td>$10.68 | â‚¬11.44</td>\n        </tr>\n        <tr>\n            <td>O15</td>\n            <td>Custom PCB</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O15.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.eurocircuits.de/\">US</a> | <a href=\"https://www.eurocircuits.de/\">EU</a></td>\n            <td>$10.00 | â‚¬10.00</td>\n            <td>1</td>\n            <td>$10.00 | â‚¬10.00</td>\n        </tr>\n        <tr>\n            <td>O16</td>\n            <td>Cytron 30A 5-30V Single Brushed DC Motor Driver</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O16.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.robotshop.com/en/cytron-30a-5-30v-single-brushed-dc-motor-driver.html\">US</a> | <a href=\"https://www.robotshop.com/eu/en/cytron-30a-5-30v-single-brushed-dc-motor-driver.html\">EU </a></td>\n            <td>$34.38 | â‚¬37.15</td>\n            <td>2</td>\n            <td>$68.76 | â‚¬74.30</td>\n        </tr>\n        <tr>\n            <td>O17</td>\n            <td>LM2596S DC-DC Converter 12V-36V to 5V | 2A (4 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O17.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Adjustable-Converter-Step-Down-Regulator-Stabilizer/dp/B081N6WWJS/ref=sr_1_3?keywords=4+pieces+adjustable+LM2596S+DC-DC+down+converter&qid=1650638822&sr=8-3\">US</a> | <a href=\"https://www.amazon.de/-/en/adjustable-converter-regulator-stabiliser-voltmeter/dp/B081N6WWJS/ref=pd_sbs_6/262-3535180-9041508?pd_rd_w=m3EIw&pf_rd_p=7cf49d79-ae26-401a-94b7-1dec7a725ba4&pf_rd_r=KEN7A8F4YCHEBXB3ZK9B&pd_rd_r=b6829a4e-476a-48dd-8821-a64b9945da1d&pd_rd_wg=m3HQp&pd_rd_i=B081N6WWJS&psc=1\">EU</a></td>\n            <td>$15.99 | â‚¬16.99</td>\n            <td>0.25</td>\n            <td>$3.99 | â‚¬4.25</td>\n        </tr>\n        <tr>\n            <td>O18</td>\n            <td>4500mAh 3S-25C 11.1V LiPo Battery in Hard Case</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O18.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/HRB-50C-100C-Quadcopter-Helicopter-Airplane/dp/B06XNTHQRZ?ref_=ast_sto_dp&th=1&psc=1\">US</a> | <a href=\"https://www.amazon.de/-/en/Roaring-Battery-Deans-Connection-Aeroplane/dp/B08Z3JYK1X/ref=sr_1_5?crid=3TW2SFFYW1BQY&keywords=4500%2Bmah%2B3s%2B11%2C1v%2B55c%2Blipo&qid=1644164015&sprefix=4500mah%2B3s%2B11.1v%2B55c%2Blipo%2Caps%2C82&sr=8-5&th=1\">EU</a></td>\n            <td>$46.99 | â‚¬29.97</td>\n            <td>1</td>\n            <td>$46.99 | â‚¬29.97</td>\n        </tr>\n        <tr>\n            <td>O19</td>\n            <td>AITRIP ESP32-DevKitC Development Board (3 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O19.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Development-Microcontroller-Integrated-Antenna-Amplifiers/dp/B09GK74F7N/ref=sr_1_2?crid=2SK0PFZJXONGJ&keywords=3pcs+ESP32+DevKitC+Core&qid=1650638989&sprefix=3pcs+esp32+devkitc+core%2Caps%2C162&sr=8-2\">US</a> | <a href=\"https://www.amazon.de/-/en/DevKitC-Development-ESP32-WROOM-32D-Bluetooth-Arduino/dp/B09LS6SCF7/ref=sr_1_2?crid=8EUG1EBFJ9AX&keywords=aitrip+esp32-devkitc&qid=1644164236&sprefix=aitrip+esp32-devkitc+core%2Caps%2C192&sr=8-2\">EU</a></td>\n            <td>$19.99 | â‚¬21.00</td>\n            <td>0.33</td>\n            <td>$6.66 | â‚¬7.00</td>\n        </tr>\n        <tr>\n            <td>O20</td>\n            <td>5.08mm PCB Terminal Block (11 x 2 Pin + 11 x 4 Pin)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O20.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/LuoQiuFa10-4-Pin-5-08mm-Female-Terminal/dp/B093DNBV5D/ref=sr_1_2?crid=1W2RRUJFR1XY2&keywords=Cococity+22+Pairs+5.08+mm+2+Pins+PCB+Screw+Terminal+Connector+Pluggable+%2B+2+Pins+Plug+in+Screw+PCB+Terminal+Block+Plug+Right+Angle+%282+Pin+11+Pairs+4+Pin+11+Pairs%29+300V+10A+%28Green%29&qid=1650639050&sprefix=3pcs+esp32+devkitc+core%2Caps%2C186&sr=8-2\">US</a> | <a href=\"https://www.amazon.de/-/en/Cococity-Pairs-Terminal-Connector-Pluggable/dp/B083GNB8BY/ref=sr_1_7?crid=SJKL0W8ANGUI&keywords=4-polige+leiterplatten-schraubklemmleiste%2C+5%2C08+mm&qid=1644165018&sprefix=4+pin+5.08mm+pitch+pcb+screw+terminal+block%2Caps%2C82&sr=8-7\">EU</a></td>\n            <td>$7.99 | â‚¬11.99</td>\n            <td>1</td>\n            <td>$7.99 | â‚¬11.99</td>\n        </tr>\n        <tr>\n            <td>O21</td>\n            <td>M6 x 1m (1000mm) Zinc Plated Threaded Rod/Bar</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/O22.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Threaded-Plated-Thread-Length-Threads/dp/B00G3QM076/ref=sr_1_18?crid=1MBLSICIHE3FX&keywords=M6+x+1m+%281000mm%29+Zinc+Plated+Threaded+Rod%2FBar&qid=1650639302&sprefix=m6+x+1m+1000mm+zinc+plated+threaded+rod%2Fbar%2Caps%2C306&sr=8-18\">US</a> | <a href=\"https://www.amazon.de/-/en/Threaded-quality-galvanised-standard-parts/dp/B07X3LX6RX/ref=sr_1_21?crid=3UFFWWONRN5FQ&keywords=gewindestange%2C%2Bverzinkt%2C%2Bm6%2Bx%2B1%2Bm%2B(1000%2Bmm)%2C%2B10%2Bst%C3%BCck&qid=1644165235&sprefix=pack%2Bof%2B10%2Bm6%2Bx%2B1m%2B1000mm%2Bzinc%2Bplated%2Bthreaded%2Brod%2Fbar%2Caps%2C170&sr=8-21&th=1\">EU</a></td>\n            <td>$22.73 | â‚¬4.31</td>\n            <td>1</td>\n            <td>$22.73 | â‚¬4.31</td>\n        </tr>\n        <tr>\n            <td>O23</td>\n            <td>M4 x 50mm screws (30 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/M4x50.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/MroMax-M4x50mm-Machine-Stainless-Phillips/dp/B07ZPSWW24/ref=sr_1_2?crid=6FFC31FUFZC&keywords=M4+x+50mm+screws+30pcs&qid=1650639360&sprefix=m4+x+50mm+screws+30pc%2Caps%2C175&sr=8-2\">US</a> | <a href=\"https://www.amazon.de/-/en/M4-50-stainless-cylinder-DIN912/dp/B07YW6Q5VT/ref=sr_1_10?crid=24VLWXHS6RUKJ&keywords=m4x50%2Bmm%2Bsechskant&qid=1644166982&sprefix=m4%2Bx%2B50mm%2Bhex%2B%2Caps%2C94&sr=8-10&th=1\">EU</a></td>\n            <td>$11.39 | â‚¬9.83</td>\n            <td>1</td>\n            <td>$11.39 | â‚¬9.83</td>\n        </tr>\n        <tr>\n            <td>O24</td>\n            <td>M4 x 40mm screws (30 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/M4x40.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Uxcell-a15111200ux1682-Cabinet-Handles-Phillips/dp/B019ZESG9I/ref=sr_1_5?crid=3FFNS1NMT4XPE&keywords=m4+x+40mm+screws+30+pcs&qid=1650639393&sprefix=m4+x+40mm+screws+30pcs%2Caps%2C163&sr=8-5\">US</a> | <a href=\"https://www.amazon.de/-/en/M4-50-stainless-cylinder-DIN912/dp/B07YWDJS99/ref=sr_1_10?crid=24VLWXHS6RUKJ&keywords=m4x50%2Bmm%2Bsechskant&qid=1644166982&sprefix=m4%2Bx%2B50mm%2Bhex%2B%2Caps%2C94&sr=8-10&th=1\">EU</a></td>\n            <td>$10.56 | â‚¬9.13</td>\n            <td>1</td>\n            <td>$10.56 | â‚¬9.13</td>\n        </tr>\n        <tr>\n            <td>O25</td>\n            <td>M3 screws and nuts sets (440 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/M3.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Shapenty-100PCS-Stainless-Female-Fastener/dp/B071NLDW56/ref=sr_1_9?crid=I0ZQA6TBI3N9&keywords=M3+screws+and+nuts+sets+%28440+pcs%29&qid=1650639424&sprefix=m3+screws+and+nuts+sets+440+pcs+%2Caps%2C257&sr=8-9\">US</a> | <a href=\"https://www.amazon.de/-/en/pieces-screws-stainless-hexagon-socket/dp/B093GNHWKR/ref=sr_1_3?crid=36NK6MT1K8LSC&keywords=satz+m3+innensechskant&qid=1644166735&s=diy&sprefix=set+m3+hex+socket%2Cdiy%2C87&sr=1-3\">EU</a></td>\n            <td>$6.49 | â‚¬11.99</td>\n            <td>1</td>\n            <td>$6.49 | â‚¬11.99</td>\n        </tr>\n        <tr>\n            <td>O26</td>\n            <td>M4 x 120mm screws (15 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/M4x120.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td> <a href=\"https://www.amazon.com/XunLiu-Socket-Screws-Wrench-Knurled/dp/B07CHJ7ZPP/ref=sr_1_38?crid=1U3GJUWD14XQB&keywords=screw%2BM4%2Bx%2B120mm&qid=1650753655&sprefix=screw%2Bm4%2Bx%2B120mm%2Caps%2C167&sr=8-38&th=1\">US</a> | <a href=\"https://www.amazon.de/-/en/sourcing-Phillips-Furniture-Hanging-External/dp/B08JYCP7TD/ref=sr_1_64?crid=25999O4GLCN83&keywords=m4+x+120+mm&qid=1644165946&sprefix=m4+x+120mm+socket%2Caps%2C109&sr=8-64\">EU</a></td>\n            <td>$15.29 | â‚¬15.64</td>\n            <td>1</td>\n            <td>$15.29 | â‚¬15.64</td>\n        </tr>\n        <tr>\n            <td>O27</td>\n            <td>M6 x 100mm screws (2 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/M6.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/MroMax-Machine-Stainless-Phillips-Cabinet/dp/B07YFMN8FP/ref=sr_1_5?crid=3GFYNNIBEO5UA&keywords=M6+x+100mm+screws&qid=1650639588&sprefix=m6+x+100mm+screws+2+pcs+%2Caps%2C161&sr=8-5\">US</a> | <a href=\"https://www.amazon.de/-/en/AG-BOX%C2%AE-Cylinder-Screws-Stainless-Steel/dp/B09N3DNDZK/ref=sr_1_5?crid=1NROTQHUR7F2K&keywords=m6x100+mm&qid=1644171138&sprefix=m6+x+100mm%2Caps%2C90&sr=8-5\">EU</a></td>\n            <td>$3.84 | â‚¬4.18</td>\n            <td>1</td>\n            <td>$3.84 | â‚¬4.18</td>\n        </tr>\n        <tr>\n            <td>O28</td>\n            <td>Assorted Nuts (Full and Self Locking) and Washers M3, M4 & M5 (45 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/M3M4M5nuts.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td> <a href=\"https://www.amazon.com/Assortment-AETTL-Stainless-Assorted-Wrenches/dp/B098ND1GW8/ref=sr_1_2?crid=3AFZPJ5SIBJD9&keywords=Assorted+Nuts+%28Full+and+Self+Locking%29+and+Washers+M3%2C+M4+%26+M5+%2845+pcs%29&qid=1650639662&sprefix=assorted+nuts+full+and+self+locking+and+washers+m3%2C+m4+%26+m5+45+pcs+%2Caps%2C226&sr=8-2\">US</a> |  <a href=\"https://www.amazon.de/-/en/Assorted-Locking-Washers-Stainless-Steel/dp/B01CO9S1RI/ref=sr_1_98?crid=P8DDSVM9ZTG1&keywords=m3+m4+muttern+unterlegscheiben&qid=1644172060&sprefix=m3+m4+nuts+washers%2Caps%2C101&sr=8-98\">EU</a></td>\n            <td>$25.64 | â‚¬23.01</td>\n            <td>1</td>\n            <td>$25.64 | â‚¬23.01</td>\n        </tr>\n        <tr>\n            <td>O29</td>\n            <td>M6 Nuts/Washers Set (40 pcs)</td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/M6nuts.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Stainless-Washer-Machine-Thread-Assortment/dp/B09HNJBX1G/ref=sr_1_3?crid=1N4R1D32PS8W6&keywords=40-Piece+Nuts%2FWashers+Set+for+M6&qid=1650639826&sprefix=40-piece+nuts%2Fwashers+set+for+m6+threaded+rods+a2+stainless+steel%2Caps%2C227&sr=8-3\">US</a> | <a href=\"https://www.amazon.de/-/en/40-Piece-Washers-Threaded-Stainless-Steel/dp/B01G77C0DY/ref=sr_1_31?crid=EUR5CW3K5BLD&keywords=m6+muttern+und+unterlegscheiben&qid=1644172515&refinements=p_36%3A118557031&rnid=118555031&s=diy&sprefix=m6+nuts+and+washers%2Caps%2C87&sr=1-31\">EU</a></td>\n            <td>$13.99 | â‚¬8.99</td>\n            <td>1</td>\n            <td>â‚¬$13.99 | â‚¬8.99</td>\n        </tr>\n      <tr>\n            <td>O30</td>\n            <td>Stainless Steel Flat and Spring Washers Assortment </td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/washers2.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>  <a href=\"https://www.amazon.com/Split-Washer-Assortment-Stainless-Silver/dp/B08QN3ZR23/ref=sr_1_35?keywords=Stainless+Steel+Flat+and+Spring+Washers+Assortment+Kit&qid=1650753391&sr=8-35\">US</a> | <a href=\"https://www.amazon.de/-/en/300-pieces-Stainless-Washers-Assortment-M2-M3-M4-M5-M6/dp/B07CQX6NPP/ref=sr_1_15?keywords=m4+federscheibe&qid=1650753193&sr=8-15\">EU</a></td>\n            <td>$12.49 | â‚¬10.38</td>\n            <td>1</td>\n            <td>â‚¬$12.49 | â‚¬10.38</td>\n        </tr>\n    </tbody>\n</table>\n\nThe total cost of the externally sourced components is estimated to around **500â‚¬**, therefore resulting in a total cost of around **600â‚¬** by MTV.\n\n### II.2. Mechanical Assembly\n\n#### II.2.1. Overview\n\nThis chapter covers the assembly process of the MTV. Note that left and right are the port and starboard sides of the robot and will be used interchangeably in this document. Unless stated otherwise, all bolts are assumed to have flat washers to protect the 3D printed plastic. It should moreover be emphasized that the use of spring washers and nylocs usually allows preventing any loosening of the nuts due to vibrations. \n\nThe assembly process of the MTV can be divided into seven main steps, namely:\n1. assembly of the the 6 motor modules\n2. assembly of the legs\n3. assembly of the chassis\n4. assembly of the main compartment \n5. assembly of the vehicle\n6. assembly of the power unit, control unit and connection of the different components\n7. Testing, programming and use. \n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Rover_Assembly.jpg\" width=\"1000\" alt=\"App GUI\"/>\n</p>\n\n#### II.2.2. Assembly of the the motor modules\n\nEach of the motor modules consist of the following parts:\n\n- 1 x 3D-printed <a href=\"cad/MotorAssembly/MotorEnclosure_Top.stl\">Motor Enclosure Top</a> (A1)\n- 1 x 3D-printed <a href=\"cad/MotorAssembly/MotorEnclosure_Bottom.stl\">Motor Enclousre Bottom</a> (A2)\n- 1 x 3D-printed <a href=\"cad/MotorAssembly/Motor_Bracket.stl\">Motor Bracket</a> (A3)\n- 1 x JGB37-520 DC-Motor with encoders and wheel adapter (O1)\n- 1 x PG7 Cable Gland (O5)\n\nTo assemble a motor module:\n\n1. Start by connecting the control cable provided in the kit (O1) to the motor. It is strongly recommended to secure this connection with a bit of hot glue. \n2. Carefully align the motor fixture pattern with the 3D-printed motor housing (A1) hole pattern. Make sure not to apply any force onto the encoder, to avoid damaging it. Screw the motor to the 3D-printed motor housing (A1), using the screws provided in the kit (O1). \n3. Fix the coupling sleeve from the kit (01) to the motor shaft with the supplied allen key. Keep the nut that secures the wheel to the coupling sleeve safely screwed in the hex hub as you will later need this when attaching the tires (O2) to the vehicle.  \n4. Slot in the Motor bracket (A3) over the motor enclosure top (A1). This is a push fit, and may require some careful alignment when sliding. Note that the shoulder of the Motor bracket (as shown in figure below) should be facing towards the side of the motor shaft for a cleaner assembly. Make sure the Motor bracket (A3) has a tight fit with motor enclosure top (A1). Secure the assembly with hot glue or super glue.  \n5. Add the cable glands joints (O5) to the motor enclosure bottom (A2) and run the motor wire thought the gland.\n6. Carefully slot in the motor enclosure bottom (A2) onto the motor enclosure top (A1) until the motor enclosure bottom (A2) has travelled the full distance. Make sure the Motor bracket (A3) is flush with the motor enclosure top (A1). Take care not to jam the wires against the encoder - the encoder needs to be free to spin. \n7. The motor enclosure top (A2) with the motor bracket (A3) are fastened using M4 x 60mm bolts (O23) and nyloc nuts (O28)\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Motor_assemb.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Wheel.jpg\" width=\"400\" alt=\"App GUI\"/>\n</p>\n\n#### II.2.3. Assembly of the legs\n\nThe left leg of the MTV consists of the following parts:\n\n- 1 x 3D-printed <a href=\"cad/Joints/90deg_Joint.stl\">90 deg Joint </a> (A4)\n- 1 x 3D-printed <a href=\"cad/Joints/End_Joint.stl\">End Joint  </a> (A7)\n- 1 x 3D-printed <a href=\"cad/Joints/BearingCover.stl\">Bearing Cover </a> (A11)\n- 1 x 3D-printed <a href=\"cad/Joints/100deg_Joint.stl\">100 deg Joint </a> (A5)\n- 2 x 3D-printed <a href=\"cad/Legs/Front_Leg.stl\">Front Leg </a> (A8)\n- 1 x 3D-printed <a href=\"cad/Legs/Mid_Leg.stl\">Mid Leg </a> (A9)\n- 1 x 3D-printed <a href=\"cad/Legs/Rear_Leg.stl\">Rear Leg </a> (A10) \n- 1 x D-Line cable duct (O4)\n- 1 x 7-Core Cable (O3)\n- 1 x MR126ZZ Ball Bearing (O6)\n\nThe right leg of the MTV consists of the following parts:\n\n- 1 x 3D-printed <a href=\"cad/Joints/90deg_Joint.stl\">90 deg Joint </a> (A4)\n- 1 x 3D-printed <a href=\"cad/Joints/End_Joint.stl\">End Joint  </a> (A7)\n- 1 x 3D-printed <a href=\"cad/Joints/BearingCover.stl\">Bearing Cover </a> (A11)\n- 1 x 3D-printed <a href=\"cad/Joints/100deg_Joint_Mirror.stl\">100 deg Joint Mirror</a> (A6)\n- 2 x 3D-printed <a href=\"cad/Legs/Front_Leg.stl\">Front Leg </a> (A8)\n- 1 x 3D-printed <a href=\"cad/Legs/Mid_Leg.stl\">Mid Leg </a> (A9)\n- 1 x 3D-printed <a href=\"cad/Legs/Rear_Leg.stl\">Rear Leg </a> (A10)\n- 1 x D-Line cable duct (O4)\n- 1 x 7-Core Cable (O3)\n- 1 x MR126ZZ Ball Bearing (O6)\n\nAssemble the 90 degree joint (A4) and related legs (A8) (2x forward + mid) to form the forward leg assembly (right and left). The legs are secured to the joint by M4 x 40mm bolts (O24), flat washer (O30), spring washer (O30), and nuts (O28). Drill the guided holes provided with M4 in the leg assemblies (in the mid leg there are 3 guided holes, end 2 should be M4 and mid should be M3 which will be used to mount the shock absorbers).\nAttach the rear leg 100degree joint (A5) (resp. mirror A6) and the rear leg to form the port and starboard full leg assemblies and secure the leg using M4 x 40mm bolts (O24), flat washer (O30), spring washer (O30), and nuts (O28).  \n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Leg.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\n#### II.2.4. Assembly of the chassis\n\nAttach the motor brackets to the free ends of each leg (2 x forward and rear leg of both Left and right side) using M4 x 40mm bolts (O24), flat and spring washers (O30), and nuts (O28). Attach the tires (O2) to the hex hub and secure them with the wheel hub nut. The MTV motors contain an integrated magnetic encoder for velocity estimation and have a 6-pin interface, for namely `[Motor power +, Motor power - , Encoder power + , Encoder power - , Encoder data 1, Encoder data 2]`. Electrical connection between the motors and the control PCBs should be done using the (O3) 7-core cable:\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/MotAssembly.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nComplete the chassis assembly, including attaching the cable duct (O4) as required:\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Leg2.jpg\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n#### II.2.5. Assembly of the main compartment\n\nThe main compartment consist of the following parts:\n\n- 2 x 3D-printed <a href=\"cad/Joints/BearingCover.stl\">Bearing Cover </a> (A11)\n- 1 x 3D-printed <a href=\"cad/PhoneMount/Phone_Mount.stl\">Phone Mount Platform </a> (A12)\n- 1 x 3D-printed <a href=\"cad/Buffer/Name_Front.stl\">Name Front </a> (A13)\n- 1 x 3D-printed <a href=\"cad/Buffer/Name_Back.stl\">Name Back </a> (A14)\n- 1 x 3D-printed <a href=\"cad/Buffer/Buffer_Left.stl\">Buffer Left </a> (A15)\n- 1 x 3D-printed <a href=\"cad/Buffer/Buffer_Right.stl\">Buffer Right </a> (A16)\n- 1 x 3D-printed <a href=\"cad/Compartment/Compartment_Rear.stl\">Compartment Rear </a> (A17)\n- 1 x 3D-printed <a href=\"cad/Compartment/Compartment_Front.stl\">Compartment Front </a> (A18)\n- 1 x 3D-printed <a href=\"cad/Compartment/Roof_Front.stl\">Roof Front </a> (A19)\n- 1 x 3D-printed <a href=\"cad/Compartment/Roof_Rear.stl\">Roof Rear </a> (A20)\n- 1 x 3D-printed <a href=\"cad/Compartment/Compartment_Battery_Mount-P1.stl\">Compartment Battery Mount P1 </a> (A21a)\n- 1 x 3D-printed <a href=\"cad/Compartment/Compartment_Battery_Mount-P2.stl\">Compartment Battery Mount P2 </a> (A21b)\n- 4 x M4 x 120mm screws (O26)\n- 6 x PG7 Cable Gland (O5)\n- 1 x M6 threaded bar (O21) \n\nJoin the rear compartment (A17) with the forward compartment (A18) to form compartment assembly using M3 x 15mm (O25), flat washers (O28) nyloc nuts (O28). Use the guided holes to drill M3 holes for the joining purpose.\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Body.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nDrill the bearing connection holes onto the chassis where the guided holes are provided and insert the bearings (O6) into the bearing cover (A11) and secure the bearing assembly to the outside of the compartment assembly by the use of 4 M3 x 30mm bolts (O25), spring washers (O30), washers (O28) and nylocs (O28).\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Body1.jpg\" width=\"300\" alt=\"App GUI\"/>\n</p>\n\nAttach the cable gland joints (O5) to the six holes on the rear compartment (A17). The six gland joints are used to pass the motor wires into the compartment:\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Body2.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nAttach the left and right buffers (A15 & A16) to the compartment assembly using 4 M3 x 20mm bolts (O25), spring washers (O30), washers (O28) and nylocs (O28). \n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Front.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nAttach the battery mount P1 & P2 (A21 a & b) on to the rear compartment using M3 x 15mm bolts (O25) and nylocs (O28). Insert the M6 threaded bar (O21) into the chassis assembly though the centre hole of the bearings and the Battery mount P1&P2 assembly. As the threaded bar is inserted from one side, take care to add the required M6 nuts (O29) that are internal to the compartment.  \n- Note that there are two M6 nuts (O29) on the outside of the compartment that act as spacers between the chassis and the compartment assembly. \n- Also note that the threaded bar needs to be balanced between the left and the right to ensure space for chassis assembly. \n- Care must be taken when screwing in the threaded bar into the compartment to ensure no pretension is added to the side walls.\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Assembly.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\n#### II.2.6. Assembly of the vehicle\n\nAttach the chassis assembly to the M6 threaded bar either side of the compartment and secure using M6 Nuts (O29):\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/MTV_assemb.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nAttach the shock absorbers (O7) between the mid leg and the chassis:\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Damper.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nSwap the factory default springs in the shock absorbers with the medium compliance set provided (gold springs) to ensure the body of the robot remains leveled with the ground. Attach the piston end to the robot compartment using the spacer and bolt provided with the shock absorber (O10) and an M3 lock nut (O28). Fix the rod end using M3 x 40 bolts (O25) and nyloc (O28). Run the wires from the leg assembly to the main body and attach as per wiring guidelines (also make appropriate use of the cable management trunking). Attach the phone mount to the roof front (A19) \n- Attach the universal smart phone holder (O11) to the phone mount platform (A12). \n- Attach the vibration isolators (O11) to the phone mount platform (A12) and secure it to the roof front (A19) using lock nuts and washers as illustrated.   \n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Phone.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nFix the voltage display (O12), power control switches (O13), and Micro USB Panel Mount Cable (O14) on the roof rear's designated slots. Pull out the head and tail lights (O8 & O9) though the roof cut outs and attach the roof front (A19) and roof rear (A20) to the compartment assembly. Insert the head lights (O8) into headlight socket (A23), and tail lights (O9) into the taillight socket (A24) and fix to the respective slots in roof front (A19) and roof rear (A20). Seal the light sockets with light endcaps (A22) as shown in figure below and use super glue to attach them. Slide in the customised Name Front (A13) and Name Back (A14) plates. \n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/LightMount.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\n### II.3. Electronics Assembly \n\nThis part only covers the integration of the electronic boards into the vehicle. The reader will find complementary details about the architecture and components of the different PCBs via the the [following link](./pcb). The pototyped PCBs are illustrated in the following figures: \n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/PCB_4.jpg\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n#### II.3.1. Battery â€“ PCB connection \nThe rechargeable Lipo battery selected for the MTV is connected to the Power distribution PCB using a set of dedicated connectors. A switch allows preventing spark damages on the battery connectors. Since this switch is mounted on the lid of the MTV, a set of splicing connectors can be used for maintenance purposes:\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Bat.jpg\" width=\"500\" alt=\"App GUI\"/>\n</p>\n\n#### II.3.2. PCB â€“ voltage display connection \n\nA dedicated voltage display provides relevant indication of the battery state. It should be connected to the Power distribution PCB.\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/V_disp.jpg\" width=\"500\" alt=\"App GUI\"/>\n</p>\n\n#### II.3.3. PCB â€“ lights connection \n\nThe front and rear lights should be connected to the MTV's main PCB. A switch should placed on the lid of the MTV to control them.  \n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Light.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/LightMount.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\n#### II.3.4. Power distribution PCB assembly\n\nThe power distribution board is mounted into the MTV main housing. The motor cables are pulled through the mounting slots after the power distribution board is in place. The main PCB is then attached to the MTV as shown in the following figure:\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/PCB_mount.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\nOnce the main PCB is in place, the motor connection cables are shortened and connected to the main board using 2-pin, 5.08 mm pitch screw terminals. Next are the lighting connections.  The 12V and 5V voltage connections of the power distribution PCB are connected to the MTV in the final step. \n\n<table>\n    <thead>\n        <tr>\n            <th>PCB </th>\n            <th>Name printed on the PCB</th>\n            <th>Picture</th>\n            <th>Comments </th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td rowspan=2>Power Distribution PCB </td>\n            <td>\n            Mount_1 \n            Mount_2\n            Mount_3\n            Mount_4\n            </td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/Mount_1.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>These M3 type mounting holes were designed to connect the Power distribution PCB to the connection points on the MTV with the use of screws and nuts.  </td>\n        </tr>\n        <tr>\n            <td>\n            VC_Mount_1 \n            VC_Mount_2\n            VC_Mount_3\n            VC_Mount_4\n            </td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/VC_Mount_1.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>These M3 type mounting holes were designed to connect the Voltage converter on to the power distribution PCB with the use of screws and nuts.</td>\n        </tr>\n        <tr>\n            <td rowspan=2>Main PCB </td>\n            <td>\n            Mount_1 \n            Mount_2\n            Mount_3\n            Mount_4\n            </td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/Mount_2.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>These M3 type mounting holes were designed to connect the Main PCB to the connection points on the MTV with the use of screws and nuts.</td>\n        </tr>\n        <tr>\n            <td>\n            MD_Mount_1 \n            MD_Mount_2\n            MD_Mount_3\n            MD_Mount_4\n            </td>\n            <td><p align=\"center\"> <img src=\"../../docs/images/MTV/MD_Mount_4.jpg\" width=\"150\" alt=\"App GUI\" /></p></td>\n            <td>These M3 type mounting holes were designed to connect the motor drivers on to the Main PCB with the use of screws and nuts. </td>\n        </tr>\n</table>\n\n#### II.3.4. MTV roof cables assembly \n\nOnce the main PCB was attached, switches and displays in the roof / lid of the of the MTV were connected using Splicing Connectors.  Also, the Micro USB program port of the ESP 32 was connected to a â€œleft angled 90 Degree Micro USB mount extension cable (Male to Female). The Female end of the panel mount USB extension was connected on to the lid of the MTV. So, users can plug the USB cables without the need of removing the lid / roof. \n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Roof_cables.jpg\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\n\n### II.4. Safety disclaimer \n\n*It is assumed that the MTV will be constructed by individuals who have an intermediate or advanced level of expertise in assembling mechanical and electronic devices. Please be aware of your own safety as you assemble and operate the robot. Neither **Ivy Tech LTD** nor **Intel Deutschland GmbH** are responsible for the result of any accidents caused by the user's negligence.*\n\n- Read through the manual carefully before assembly.\n- Beware of the sharp edges of 3D printed components. \n- Keep a safe distance from the robot during operation.\n- Be careful to not get fingers stuck between the robot joints and wheels.\n- Do not store the robot under direct sunlight.\n- This product is **not waterproof**. We do not recommend operating the MTV in rainy or wet environments. \n- Do not use the MTV near fire or any source of heat.\n- Do not drop the MTV from hights.\n- Use only the designated/recommended tools to assemble the robot.\n- Do not use excessive force on nuts, bolts or robot parts.\n- Avoid activating the robot at heights to prevent sudden drop.\n- Do not damage or place the Li-Po battery in water. \n- Do not connect or let the Li-Po battery come in contact with other conductors apart from the suggested terminals.\n- When the robot is out of charge, it is recommended to take the battery out of the robot and to place it in a Li-Po Safe Bag before charging it. The battery, once fully charged can be inserted back into the robot as illustrated below\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Lipo_1.jpg\" width=\"400\" alt=\"App GUI\" />\n</p>\n\n<p align=\"center\">\n  <img src=\"../../docs/images/MTV/Lipo_2.jpg\" width=\"1000\" alt=\"App GUI\" />\n</p>\n\n## III: Next\n\nFlash the [Arduino Firmware](../../firmware/README.md)\n\n\n\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/rc_truck/README.md": {
    "summary": "## OpenBot RC-Truck Body\n\nThis project provides a 3D-printed body for 1:16 scale RC toys, allowing you to transform them into robots. The body is designed for a variety of 1:16 scale toy trucks and includes components for a generic wheeled robot that can be built with low-cost hardware.\n\n**Chassis**\n\nThe chassis consists of:\n\n- A 1:16 scale RC toy truck\n- Custom-designed 3D-printed parts:\n    - `main_frame`: Main frame of the OpenBot RC-Truck\n    - `side_cover` (x2): Side covers\n    - `phone_mount_bottom`: Base of the phone mount\n    - `phone_mount_top`: Top of the phone mount\n\nOptional parts for compactness and aesthetics:\n\n- `camera_elevator`: Adjusts the vertical height of the phone mount\n- `electronics_cover` (x2): Covers for the electronics at the back\n- `spacer` (x4): Spacers for mounting the PCB\n- `front_light_spacer` (x2): Spacers for securing the front LED lamps\n\n**Assembly**\n\nThe recommended assembly method involves using the OpenBot [custom PCB](/body/pcb). This provides a clean build and allows you to use the same components for multiple OpenBot bodies.\n\n**Required Components**\n\n- RC toy truck\n- Arduino Nano\n- OpenBot [Custom PCB](/body/pcb)\n- USB OTG cable\n- Screws and nuts\n- Dupont cables\n\n**Optional Components**\n\n- Ultrasonic sensor\n- On/Off switches\n- LEDs (orange, red)\n- White LED lamps\n- Variable resistor\n\n**Build Instructions**\n\n1. Disassemble the RC toy truck.\n2. Install optional switches and sensors.\n3. Run cables through the rectangular opening on the back of the `main_frame`.\n4. Mount the `phone_mount_bottom` with screws and nuts.\n5. Add the `camera_elevator` (optional) and the `phone_mount_top`.\n6. Insert the `side_covers`.\n7. Mount the `main_frame` onto the RC truck body.\n8. Mount the PCB, Arduino Nano, and USB OTG cable.\n9. Connect the ultrasonic sensor, LED cables, and servo cables to the PCB or Arduino Nano.\n10. Connect the battery and cover the electronics with the `electronics_cover`.\n\n**Next Steps**\n\n- Flash the [Arduino Firmware](../../firmware/README.md)",
    "content": "# OpenBot: RC-Truck Body\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nWe have designed a robot body for widely available 1:16 scale RC-toy trucks/buggies (such as [this](https://www.amazon.de/dp/B00M3J7DJW) on Amazon).\n\n![RC-Truck-Banner](/docs/images/rc-truck-banner.jpg)\n\nWe also have a generic [body](/body/) designed for a simple wheeled robot which relies on low-cost, readily available hobby hardware. Build instructions for the regular OpenBot can be found [here](/body/README.md). \n\n## Chassis\n\nThe chassis of OpenBot RC-Truck consists of two main components: (a) A 1:16 scale RC-toy truck of your choice and (b) a number of custom-designed parts which we provide and can be 3D-printed.\n\n### 1:16 RC-toy truck\n\nTo build your own OpenBot RC-Truck, you will need a 1:16 scale RC-toy truck/buggy. We provide Amazon links to compatible RC-toy trucks for Germany ([EU](https://www.amazon.de/dp/B00M3J7DJW)), ([EU](https://www.amazon.de/dp/B088FGVYNW)), and the United States ([US](https://www.amazon.com/gp/product/B09C8XMPQ9)) with fast shipping. A number of similar 1:16 scale toy trucks can also be found on other online retailers such as ebay, Alibaba, or AliExpress, often for discounted price but with slow shipping speed. \n\nIrrespective of the retailer and the version of RC-toy truck you choose for your build, make sure that it is indeed a 1:16 scale RC-truck. This is important because the 3D printed parts we provide are currently designed to fit only 1:16 scale trucks with some minor adjustments (more on this later). Some examples of compatible 1:16 scale RC-toy trucks/buggies are shown below.\n\n<p float=\"left\">\n  <a href=\"https://www.amazon.de/dp/B00M3J7DJW\" target=\"_blank\"> <img src=\"/docs/images/rc_toy_1.jpg\" width=\"34%\" /> &nbsp\n  </a>\n  <a href=\"https://www.amazon.com/gp/product/B09C8XMPQ9\" target=\"_blank\"> <img src=\"/docs/images/rc_toy_2.jpg\" width=\"27%\" /> &nbsp &nbsp &nbsp &nbsp\n  </a>\n  <a href=\"https://www.amazon.de/dp/B088FGVYNW\" target=\"_blank\"> <img src=\"/docs/images/rc_toy_3.jpg\" width=\"27%\" />\n  </a>\n</p>\n\n\n### 3D printing\n\nYou will need to print the following parts in order to build your OpenBot RC-Truck.\n\n1) ```main_frame``` ([STL](cad/rc_truck_body/main_frame.stl), [STEP](cad/rc_truck_body/main_frame.step))\n2) ```side_cover``` \\[x2\\] ([STL](cad/rc_truck_body/side_cover.stl), [STEP](cad/rc_truck_body/side_cover.step))\n3) ```phone_mount_bottom``` ([STL](../phone_mount/phone_mount_bottom.stl), [STEP](../phone_mount/phone_mount_bottom.step))\n4) ```phone_mount_top``` ([STL](../phone_mount/phone_mount_top.stl), [STEP](../phone_mount/phone_mount_top.step))\n\nNotice that \\[xN\\] indicates the number of copies (i.e., N) you need to print of a particular part (wherever applicable).\n\nFollowing parts are optional (but recommended) to make your OpenBot RC-Truck more compact and aesthetically pleasing.\n\n5) ```camera_elevator``` ([STL](cad/rc_truck_body/camera_elevator.stl), [STEP](cad/rc_truck_body/camera_elevator.step))\n6) ```electronics_cover``` \\[x2\\] ([STL](cad/rc_truck_body/electronics_cover.stl), [STEP](cad/rc_truck_body/electronics_cover.step))\n7) ```spacer``` \\[x4\\] ([STL](cad/rc_truck_body/spacer.stl), [STEP](cad/rc_truck_body/spacer.step))\n8) ```front_light_spacer``` \\[x2\\] ([STL](cad/rc_truck_body/front_light_spacer.stl), [STEP](cad/rc_truck_body/front_light_spacer.step))\n\nFor all the above parts, your build plate needs to be at least 260mmx220mm, which is the print size of the ```main_frame```.\n\nSince a lot of common 3D printers have a smaller build volume (usually 220mmx220mm), there are two more options that can work. \nFirst option is to print the ```main_frame``` at 45 degrees with additional support material. \nSecond option requires modifying the original ```main_frame``` part. We recommend using [Autodesk Fusion 360](https://www.autodesk.com/products/fusion-360/overview) for such CAD modifications (Fusion 360 has a free 1-year academic license available). \nFor this option, we make its [STEP](/body/cad/rc_truck_body/main_frame.step) file available, which you can cut into two/three smaller parts. \nThe resulting sub-parts will then fit on a standard (i.e., 220mmx220mm) build plate and can be joined together after printing. \nIn future, we may also release such a modular version of the ```main_frame``` here. All other parts require a minimum build plate of 220mmx60mm.\n\nOn an Ultimaker S5, we achieved good results with the following settings:\n\n- layer height: 0.2mm\n- wall thickness: 1.5mm\n- infill density: 20%\n- infill pattern: grid\n- print speed 80 mm/s\n- no support\n\nWe were able to print the chassis with PLA, CPE and ABS. In our experience the print was not affected very much by the print settings. However, if you have the patience, printing slower and with smaller layer height will improve the print. Also adding a support structure can improve the print, but it will require additional work to remove afterwards.\n\nBefore you proceed with the build, you may need to clean the 3D print. However, using the above settings, we did not need any filing or cleaning during our build process. If possible, we recommend using a combination of two different colors (for example green/black or red/black) for printing different parts of the same OpenBot RC-Truck as shown below. \n\n**Tip:** Click on the images to open them in full resolution in a new tab.\n\n<p float=\"left\">\n  <img src=\"/docs/images/3d_print_rc_1.png\" width=\"32%\" />\n  <img src=\"/docs/images/3d_print_rc_2.png\" width=\"32%\" /> \n  <img src=\"/docs/images/3d_print_rc_3.png\" width=\"32%\" />\n</p>\n\n\n## Assembly\n\nWhile it is possible to build your OpenBot RC-Truck with a DIY approach similar to the regular OpenBot (see DIY build components and instructions for OpenBot [here](/body/README.md)), we recommend using the OpenBot [custom PCB](/body/pcb) for building and assembling the OpenBot RC-Truck. This option is recommended if you desire a cleaner build or want to build multiple OpenBot RC-Trucks. An additional advantage of using our [custom PCB](/body/pcb) is that you can use the same components to build and switch between different OpenBot bodies.\n\n### Bill of materials\n\nOpenBot RC-Truck mainly relies on readily available hobby electronics. We provide Amazon links for Germany (EU) and the United States (US) with fast shipping. If you have the patience to wait a bit longer, you can also get the components a lot cheaper from AliExpress (AE). You will need the following components.\n\n#### Required components\n\n- 1x RC-toy truck/buggy ([EU](https://www.amazon.de/dp/B00M3J7DJW), [EU](https://www.amazon.de/dp/B088FGVYNW), [US](https://www.amazon.com/gp/product/B09C8XMPQ9))\n- 1x Arduino Nano ([EU](https://www.amazon.de/dp/B01MS7DUEM), [US](https://www.amazon.com/dp/B00NLAMS9C), [AE](https://www.aliexpress.com/item/32866959979.html))\n- 1x OpenBot [Custom PCB](/body/pcb)\n- 1x USB OTG cable ([EU](https://www.amazon.de/gp/product/B075M4CQHZ) ,[US](https://www.amazon.com/dp/B07LBHKTMM), [AE](https://www.aliexpress.com/item/10000330515850.html))\n- 1x spring or rubber band ([EU](https://www.amazon.de/gp/product/B01N30EAZO/), [US](https://www.amazon.com/dp/B008RFVWU2), [AE](https://www.aliexpress.com/item/33043769059.html))\n- 6x M3x25 screw ([EU](https://www.amazon.de/dp/B07KFL3SSV), [US](https://www.amazon.com/dp/B07WJL3P3X), [AE](https://www.aliexpress.com/item/4000173341865.html))\n- 6x M3 nut ([EU](https://www.amazon.de/dp/B07JMF3KMD), [US](https://www.amazon.com/dp/B071NLDW56), [AE](https://www.aliexpress.com/item/32977174437.html))\n- Dupont cables ([EU](https://www.amazon.de/dp/B07KYHBVR7), [US](https://www.amazon.com/dp/B07GD2BWPY), [AE](https://www.aliexpress.com/item/4000766001685.html))\n\n#### Optional components\n\n- 1x Ultrasonic Sensor ([EU](https://www.amazon.de/dp/B00LSJWRXU), [US](https://www.amazon.com/dp/B0852V181G/), [AE](https://www.aliexpress.com/item/32713522570.html))\n- 2x On/Off Switch ([EU](https://www.amazon.de/dp/B07QB22J62), [US](https://www.amazon.com/dp/B01N2U8PK0), [AE](https://www.aliexpress.com/item/1000005699023.html))\n- 4x Orange LED 5mm ([EU](https://www.amazon.de/gp/product/B01NCL0UTQ), [US](https://www.amazon.com/dp/B077XD7MVB), [AE](https://www.aliexpress.com/item/4000329069943.html))\n- 4x Red LED 5mm ([EU](https://www.amazon.de/dp/B083HN3CLY), [US](https://www.amazon.com/dp/B077X95F7C), [AE](https://www.aliexpress.com/item/4000329069943.html))\n- 2x White LED lamps ([EU](https://www.amazon.de/-/en/gp/product/B06XTQSZDX), [US](https://www.amazon.com/gp/product/B01N2UPAD8), [AE](https://de.aliexpress.com/item/1005002991235830.html))\n- Variable Resistor for LEDs ([EU](https://www.amazon.de/gp/product/B081TXJJGV), [US](https://www.amazon.com/dp/B0711MB4TL), [AE](https://de.aliexpress.com/item/1005003610664176.html))\n\n\n### Build instructions\n\n**Tip:** Click on the images to open them in full resolution in a new tab.\n\n1. Disassemble the RC-toy truck. Remove its top cover and unscrew the four mouting pins from the base as shown in the figures below. Keep all four mounting pins and their respective screws safe, since you will be using them to mount the ```main_frame``` onto the RC-Truck body after all the wiring is done. All compatible RC-toy trucks come with two motors: one for throttle and the other for steering, a speed controller (with a built-in 5-7V UBEC) for the throttle motor, and a 2S 7.4V LiPo battery pack. Unmount and remove the battery pack from the base of the truck and recharge it with the charger that came with the truck. Expose/losen the wire connectors for both motors as well as the UBEC output from the speed controller. In our case, the UBEC output was 6V.\n    <p float=\"left\">\n      <img src=\"/docs/images/rc_truck_disassembly_1.JPG\" width=\"32%\" />\n      <img src=\"/docs/images/rc_truck_disassembly_2.JPG\" width=\"32%\" /> \n      <img src=\"/docs/images/rc_truck_disassembly_3.JPG\" width=\"32%\" />\n    </p>\n2. Notice that the two dimensions d1 amd d2 (as shown below) on the ```main_frame``` are dependent on the model of the RC-toy truck used. We designed our ```main_frame``` part for [this](https://www.amazon.de/dp/B00M3J7DJW) RC-toy truck model. Based on what (1:16 scale) truck you use, you may need to adjust these dimensions slightly using the ```main_frame``` [STEP](/body/cad/rc_truck_body/main_frame.step) file. We recommend using [Autodesk Fusion 360](https://www.autodesk.com/products/fusion-360/overview) for such CAD modifications (Fusion 360 has a free 1-year academic license available). Also, note that the small wedge/triangle on the ```main_frame``` represents the forward direction.\n    <p float=\"left\">\n      <img src=\"/docs/images/main-frame-dimensions.png\" width=\"32%\" />\n      <img src=\"/docs/images/main-frame-direction.png\" width=\"32%\" />\n    </p>   \n3. (Optional) Install the ON/OFF switch for powering the robot. You can simply do this by cutting the positive wire that goes from speed controller to the battery and soldering the switch in-between the two split parts of this wire. Please ensure that the switch connectors are insulated via shrink tube or electric tape and the power cable is long enough so that the switch can fit through the rectangular opening on the back side of the ```main_frame``` after assembly (see the figure below).\n    <p float=\"left\">\n      <img src=\"/docs/images/main-frame-switch.png\" width=\"32%\" />\n      <img src=\"/docs/images/switch-power.jpg\" width=\"32%\" />\n    </p>\n4. (Optional) Install the ultrasonic sensor through the front grill of the ```main_frame```. You can use hot glue to keep it in place if needed. Gently push the connector into a straight position before putting it in place. This will make accessing the connector easier after assembly. Run the dupont cables from the ultrasonic connector all the way back to the rectangular opening on the back side of the ```main_frame```.\n    <p float=\"left\">\n      <img src=\"/docs/images/install-ultrasonic-1.png\" width=\"32%\" />\n      <img src=\"/docs/images/ultrasonic-sensor.jpg\" width=\"32%\" />\n      <img src=\"/docs/images/install-ultrasonic-2.png\" width=\"32%\" />\n    </p>\n5. (Optional) Install the orange LEDs for the indicator signals both at front and back of the ```main_frame```. You can use hot glue to keep them in place if needed. For each side i.e., left and right, you need to connect the front and back LEDs in parallel. To achieve this, simply connect their positive and negative terminals together respectively. Similar to the ultrasonic sensor cable, run the postive and negative dupont cables from both left and right indicator signals all the way back to the rectangular opening on the back side of the ```main_frame``` where they will connect to their respective indicator signal pins (both +ve and -ve) on the PCB. \n    <p float=\"left\">\n      <img src=\"/docs/images/insert-leds-orange-1.png\" width=\"32%\" />\n      <img src=\"/docs/images/orange-led.jpg\" width=\"32%\" />\n      <img src=\"/docs/images/insert-leds-orange-2.png\" width=\"32%\" />\n    </p>\n**Tip:** To avoid cluttering and potential grounding mistakes during wiring, it is recommended to form a unified ground loop for the negative terminals of all the LEDs. This simply means running a wire underneath the ```main_frame``` which connects all the negative terminals of the LEDs. This ground loop can then be connected to the Arduino Nano ground pin using a single dupont cable, which is run to the rectangular opening on the back side of the ```main_frame```.\n\n6. (Optional) Install the front LED lamps. You can use hot glue to keep the base in place and screw the lamp into its respective base through the front opening on each side. Connect both front LED lamps in parallel by connecting their positive and negative terminals together respectively. Since these lamps operate on 6V, you can connect them directly to the UBEC output by their positive terminals. Connect the negative terminals to the ground loop (see the tip above). The internal resistance of these LEDs is fairly high so there is no need to add any external resistance. After installing the LED lamps, insert and hot glue the two ```front_light_spacers``` on each side to lock the LEDs in place.\n    <p float=\"left\">\n      <img src=\"/docs/images/insert-lamps-1.png\" width=\"32%\" />\n      <img src=\"/docs/images/led-lamp-wiring.jpg\" width=\"32%\" />\n      <img src=\"/docs/images/add_front_light_spacer.png\" width=\"32%\" />\n    </p>\n7. (Optional) Install the Red LEDs for rear lights. You can use hot glue to keep them in place if needed. Connect all four Red LEDs in parallel; i.e., connect their positive and negative terminals together repectively. The negative terminals will go to the ground, while the positive terminals will be collectively connected to the UBEC output via an appropriate voltage divider (see the next step for details on voltage divider construction). \n    <p float=\"left\">\n      <img src=\"/docs/images/insert-leds-red.png\" width=\"32%\" />\n      <img src=\"/docs/images/red-led.jpg\" width=\"32%\" />\n    </p>\n8. (Optional) Install the voltage divider for rear Red LEDs. Most color LEDs (e.g. Red, Orange, Yellow etc.) operate on 2-3V and not the traditional 5V, which is the normal operating voltage of the Arduino Nano. Therefore, a voltage divider is needed in order to operate these LEDs safely. For indicator signals, we already have a built-in voltage divider in our custom PCB. So, you do not need to do anything for using the indicator signal (i.e., orange) LEDs. However, if you choose to add rear light i.e., Red LEDs as well, then an external voltage divider is required for them. We recommend using a variable resistor of 10kÎ© or higher for making your voltage divider. Based on your UBEC output voltage (6V in our case), you need to set up a voltage divider with 2-3V output. This can be done by applying the UBEC output on the external ends of the resistor and by turning the screw on its top and monitoring the output voltage using a digital multimeter in between the ground and the middle terminal (see figure below). Once the output voltage of the variable resistance i.e., the voltage divider is set to the appropriate 2-3V range, lock its screw in place using some hot glue and fix its position underneath the ```main_frame``` in a convenient position.\n    <p float=\"left\">\n      <img src=\"/docs/images/variable-resistor.jpg\" width=\"32%\" />\n      <img src=\"/docs/images/voltage-divider-animation.png\" width=\"32%\" />\n    </p>\n9. (Optional) You can also use a single or two separate ON/OFF switches for turning the front and rear LEDs ON and OFF. Please follow instructions in Step 3 to install a switch (or multiple switches) for this purpose.\n10. Now you are almost done with the wiring of the robot. At this point, take some time to ensure that all wires and connections underneath the ```main_frame``` are correct and well insulated using either shrink tube or electric tape. Use hot glue to keep any loose wires in place so they do not come in contact with the wheels or any moving parts of the robot after assembly. Make sure all cables from motors, speed controller UBEC, LEDs, and ultrasonic sensor can freely make it out of the rectangular opening on the back side of the ```main_frame```.\n11. Mount the ```phone_mount_bottom``` to the ```main_frame``` using two M3x25 screws and nuts. Optionally, you can insert one or more ```camera_elevators``` in between if you would like to adjust the vertical height of your phone mount. If you use a ```camera_elevator``` you will need M3x35 or longer screws for mounting the phone mount onto the ```main_frame```.\n    <p float=\"left\">\n      <img src=\"/docs/images/add_phone_mount_bottom.png\" width=\"32%\" />\n      <img src=\"/docs/images/add_phone_mount_bottom_elevator.png\" width=\"32%\" /> \n    </p>\n10. Insert the ```phone_mount_top``` and install the spring or rubber band.\n    <p float=\"left\">\n      <img src=\"/docs/images/add_phone_mount_top.png\" width=\"32%\" />\n    </p>\n11. Insert the two ```side_covers``` into their respective slots.\n    <p float=\"left\">\n      <img src=\"/docs/images/add_side_covers.png\" width=\"32%\" />\n      <img src=\"/docs/images/add_side_covers_2.png\" width=\"32%\" />\n    </p>    \n12. Mount the ```main_frame``` onto the RC-Truck body using the four mounting pins and their respective screws. Make sure all cable connectors and the power switch for the robot are accessible through the rectangular opening on the back side of the ```main_frame``` for PCB connections. Pull out the battery connector from the triangular opening on the front of the ```main_frame```.\n    <p float=\"left\">\n      <img src=\"/docs/images/add_main_frame_1.JPG\" width=\"32%\" />\n      <img src=\"/docs/images/add_main_frame_2.png\" width=\"32%\" />\n      <img src=\"/docs/images/add_main_frame_3.JPG\" width=\"32%\" />\n    </p>\n12. Mount the PCB with four M3x25 screws and nuts with four ```spacers``` in between on the back side of ```main_frame```. Mount the Arduino Nano onto the PCB and attach the USB OTG cable to the Arduino Nano's USB port.\n    <p float=\"left\">\n      <img src=\"/docs/images/pcb_assembly.JPG\" width=\"32%\" />\n    </p>\n13. Connect the ultrasonic sensor cables to the connector marked \"sonar\" on the PCB. Make sure the +ve/-ve polarity and the data lines are correctly matched between the sensor and the PCB ports.\n14. Connect the left and right indicator LED cables to their respective indicator signal connectors on the PCB. Ensure the correct polarity of +ve and -ve LED terminals.\n15. Connect the UBEC output (+6V) to the Vin pin of the Arduino Nano (optional, Arduino can also be powered by phone), and the UBEC GND to the Arduino GND pin (next to Vin).\n16. Connect the UBEC output (+6V) to the +ve terminals of the steering servo, the front LED lamps, and the rear Red LEDs through the voltage divider.\n17. Connect the ground cable of the steering servo to the GND pin of Arduino as well.\n18. Connect the PWM cable of the throttle servo (from the speed controller) to pin A0 on the Arduino Nano or PCB breakout.\n19. Connect the PWM cable of the steering servo to pin A1 on the Arduino Nano or PCB breakout.\n**Tip:** If you have created a unified ground loop for the LED wiring, then connect the ground loop cable to one of the Arduino GND pins as well. Arduino Nano has three GND pins available. If you have not constructed a ground loop, then make sure that all LEDs, the steering servo, sensors, the Arduino Nano, and the speed controller's UBEC share the same ground with appropriate wiring and connections.\n21. Connect the battery pack at the front and keep it in place using some velcro or mounting tape. Having the battery at front makes it easily accessible for recharging. This placement also helps with balancing the robot weight when a smartphone is mounted on top.\n22. Put on the front and back ```electronics_covers```. Pull out the USB OTG cable from the rear ```electronics_cover``` gap for connecting it to an android smartphone.\n<p float=\"left\">\n      <img src=\"/docs/images/add_covers_1.png\" width=\"32%\" />\n      <img src=\"/docs/images/add_covers_2.JPG\" width=\"32%\" />\n    </p>\n\n## Next\n\nFlash the [Arduino Firmware](../../firmware/README.md)\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/body/rtr/README.md": {
    "summary": "OpenBot RTR (Ready-To-Run) vehicles are pre-assembled with integrated electronics and tested software/hardware. Available in indoor (RTR_TT) and outdoor (RTR_520) models. Users can order ready-built vehicles or build their own by printing parts, manufacturing PCBs, and purchasing additional components. The README includes detailed instructions for building the RTR yourself, including 3D printing files, PCB board versions, and component lists. After building the RTR, users should flash the Arduino firmware to complete the setup.",
    "content": "# OpenBot: Ready-To-Run (RTR) vehicles\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nThe ready-to-run (RTR) versions of the OpenBot vehicle are targetting an audience which does not have the will or time to build its own robot. The RTR vehicles come with fully integrated electronics, are already supported at the firmware level and have been thoroughly tested both from a software and hardware perspective. The RTR vehicles are available in two different flavours, referred to as \"RTR_TT\" and \"RTR_520\". Both vehicles are built around the same splash-proof ABS shell, but are intended for different purposes. While the RTR_TT is primarily intended for indoor use, the RTR_520 comes with a more powerful processor, better motors, stronger metal gearboxes and also has a set of all-terrain wheels supporting both indoor and outdoor use. \n<p align=\"center\">\n  <a> <img src=\"/docs/images/RTR_TT.jpg\" width=\"35.8%\" /> &nbsp\n  </a>\n  <a> <img src=\"/docs/images/RTR_520.jpg\" width=\"33%\" />\n  </a>\n</p>\n\n### Ordering\n\nThe RTR OpenBot vehicles can be ordered [here](http://www.openbot.info/).\n\n## Building the RTR yourself\n\nIn case you want to build your own OpenBot RTR, you will need to print the chassis, manufacture the PCBs and buy the motors and a phone mount.\n\n### 3D printing\n\nIn case you still want to print your own OpenBot RTR, you will need to print the following parts.\n\n1) ```shell_bottom``` ([STL](cad/rtr_bottom.stl), [STEP](cad/rtr_bottom.step))\n2) ```shell_top``` ([STL](cad/rtr_top.stl), [STEP](cad/rtr_top.step)) \n3) ```phone_mount``` ([STL](cad/rtr_mount.stl), [STEP](cad/rtr_mount.step))\n\n<p align=\"center\">\n  <img src=\"../../docs/images/rtr_tt_assembly.gif\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n### PCBs\n\nFor each of the PCBs, there are three files. The gerber file contains the actual PCB, the BOM (bill of materials) file contains all components to be soldered onto the PCB and the centroid file contains the coordinates of each componnent for automatic PCB assembly. The base board contains the majority of the components. There are three variants of the base board. Variant A is a bare board with connectors for external motor driver boards and an external microcontroller board. Variant B is a modular board with a pin header for an external microcontroller. Variant C is the fully integrated base board which we would recommend for most users. The front bump sensor board contains two bump sensors, a sonar sensor and the USB driver. There are two variants of the front bump sensor board, one with the cheaper CH340G USB driver and one with the more reliable CP2102N USB driver. Depending on which version (TT-motor or 520-motor) you want to build, you will need the following PCBs.\n\n#### TT-motor\n\n- 1x Base board (Arduino)\n- 1x Status LED board\n- 1x Front/Top/Back bump sensor board\n- 4x Speed sensor board (Arduino)\n\n#### 520-motor\n\n- 1x Base board (ESP32)\n- 1x Status LED board\n- 1x Front/Top/Back bump sensor board\n\n#### Board reference\n\n- Status LED Board ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_Status_LED_Board_V1.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_Status_LED_Board_V1.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_Status_LED_Board_V1.csv))\n- Top Bump Sensor Board ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_BumpSensorTop_V1.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_BumpSensorTop_V1.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_BumpSensorTop_V1.csv))\n- Back Bump Sensor Board ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_BumpSensorBack_V1.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_BumpSensorBack_V1.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_BumpSensorBack_V1.csv))\n- Front Bump Sensor Board (CH340G) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_SensorBoardFront_CH340G_V1.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_SensorBoardFront_CH340G_V1.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_SensorBoardFront_CH340G_V1.csv))\n- Front Bump Sensor Board (CP2102N) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_SensorBoardFront_CP2102N_V1.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_SensorBoardFront_CP2102N_V1.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_SensorBoardFront_CP2102N_V1.csv))\n- Speed Sensor Board (Arduino) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_SpeedSensor_Arduino_V1.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_SpeedSensor_Arduino_V1.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_SpeedSensor_Arduino_V1.csv))\n- Integrated Base Board C (Arduino) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_BaseBoard_Arduino_V1C.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_BaseBoard_Arduino_V1C.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_BaseBoard_Arduino_V1C.csv))\n- Integrated Base Board C (ESP32) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_BaseBoard_ESP32_V1C.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_BaseBoard_ESP32_V1C.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_BaseBoard_ESP32_V1C.csv))\n- Modular Base Board B (Arduino) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_BaseBoard_Arduino_V1B.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_BaseBoard_Arduino_V1B.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_BaseBoard_Arduino_V1B.csv))\n- Modular Base Board B (ESP32) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_BaseBoard_ESP32_V1B.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_BaseBoard_ESP32_V1B.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_BaseBoard_ESP32_V1B.csv))\n- Bare Base Board A (Arduino) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_BaseBoard_Arduino_V1A.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_BaseBoard_Arduino_V1A.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_BaseBoard_Arduino_V1A.csv))\n- Motor Driver DRV8870 Board (Arduino) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_MotorBoard_Arduino_V1_DRV8870.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_MotorBoard_Arduino_V1_DRV8870.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_MotorBoard_Arduino_V1_DRV8870.csv))\n- Bare Base Board A (ESP32) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_BaseBoard_ESP32_V1A.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_BaseBoard_ESP32_V1A.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_BaseBoard_ESP32_V1A.csv))\n- Motor Driver DRV8870 Board (ESP32) ([gerber](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/Gerber_MotorBoard_ESP32_V1_DRV8870.zip),[bom](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/BOM_MotorBoard_ESP32_V1_DRV8870.csv),[centroid](https://github.com/isl-org/OpenBot/blob/thias15/rtr/body/rtr/pcb/PickAndPlace_MotorBoard_ESP32_V1_DRV8870.csv))\n\n## Next\n\nFlash the [Arduino Firmware](../../firmware/README.md)\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/controller/flutter/ios/Runner/Assets.xcassets/LaunchImage.imageset/README.md": {
    "summary": "Customize launch screens by replacing image files in the specified directory or directly within the Xcode project under `Runner/Assets.xcassets`.",
    "content": "<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n# Launch Screen Assets\n\nYou can customize the launch screen with your own desired assets by replacing the image files in this directory.\n\nYou can also do it by opening your Flutter project's Xcode project with `open ios/Runner.xcworkspace`, selecting `Runner/Assets.xcassets` in the Project Navigator and dropping in the desired images.\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/controller/flutter/README.md": {
    "summary": "The Flutter Controller app serves as a remote controller for OpenBot, providing video/audio streaming and control. To use the app, install Flutter and navigate to the controller directory, then run the application in your terminal or editor. To connect the app to OpenBot, set the robot's control mode to Phone. Operation includes on-screen controls with dual drive mode, turn indicators, and camera/audio toggles, as well as tilt-to-drive mode with accelerometer controls.",
    "content": "# Flutter Controller App\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nThis Controller app serves as a `remote controller` for the [OpenBot](https://www.openbot.org) vehicle similar as a BT controller (e.g. PS3/4 or Xbox). It runs on another Android/iOS device and supports live video/audio streaming in addition to control.\n\n ## Getting Started\nBegin by installing [Flutter](https://flutter.dev/) on your system. Choose the appropriate download for your operating system, which includes options for Windows, macOS, Linux, and ChromeOS. Follow the official Flutter installation guide for detailed instructions: [Flutter Installation Guide](https://docs.flutter.dev/get-started/install)\n\n### Using Terminal\n- Once Flutter is installed successfully, open your **terminal** or **command prompt**.\n- Change your current directory to the location where the OpenBot project is stored and then navigate to `OpenBot/controller/flutter`.\n- Use the following commands to run the Flutter application from the terminal.\n\n  ####  Install Dependencies:\n    ```bash\n     flutter pub get \n    ```\n    Run the project:\n    ```bash\n     flutter run\n    ```\n    If you encounter any issues, run the following command:\n    ```bash\n     flutter doctor\n    ```\n### Using Editor\n- Follow the official Flutter guide for setting up an editor:  [Set up an editor ](https://docs.flutter.dev/tools/android-studio) \n- Ensure that your editor is configured for Flutter development. Install any required plugins or extensions, following the editor-specific instructions in the Flutter documentation for the best development experience.\n\n- Once you open your project in the editor after the setup, it will appear as shown in the following image.\n\n  <p float=\"left\">\n    <img src=\"../../docs/images/android_editor.jpg\" width=\"50%\" />\n  </p>\n\n- Please follow the instructions similar to the ones mentioned above for running Flutter in the terminal and directly run using the ``run`` button for future repetitions.\n\n  <p float=\"left\">\n    <img src=\"../../docs/images/run_editor.jpg\" width=\"50%\" />\n  </p>\n\n## Connection \n\nWhen the controller app is started, it immediately tries to connect to the robot and shows the following screen:\n\n<p float=\"left\">\n  <img src=\"../../docs/images/flutter_controller_home.jpg\" width=\"50%\" />\n</p>\n\nTo connect the controller to the robot, set the robot's control mode to **Phone**.\nFor example, in the `FreeRoamFragment` the phone mode is activated like this:\n\n<p float=\"left\">\n  <img src=\"../../docs/images/phone_selection.gif\" width=\"50%\" />\n</p>\n\nOnce connected, the controller app will look like this:\n\n<p float=\"left\">\n  <img src=\"../../docs/images/flutter_controller_connected.jpg\" width=\"50%\" />\n</p>\n\nHere you can select to drive the robot by tilting the phone, or by using the on-screen controls.\n\n***Note:*** This should be sufficient to connect, but if the connection cannot be established after 30 seconds, toggle\nthe `Control` setting on the bot app to `Gamepad` and then to `Phone` again to re-initiate the connection. If that\nfails, exit the controller app and start it again. Toggle the control mode again on the robot app.\n\n## Operation\n\n### On-screen controls\n\nThis mode allows the user to control the robot car via two sliders in `Dual Drive` mode. You can turn left/right by\nmoving the slider thumb up and down on each side. The wheels on each side turn forward/backward when moving the thumb\nabove/below the center of the slider.\n\n<p float=\"left\">\n  <img src=\"../../docs/images/flutter_controller_dual_drive_mode.jpg\" width=\"50%\" />\n</p>\n\n- ``Indicators``: You can also set the left/right turn indicators <img src=\"../../docs/images/keyboard_arrow_left-24px.svg\" height=\"24\"/> <img src=\"../../docs/images/keyboard_arrow_right-24px.svg\" height=\"24\"/> by clicking on the arrows on the top-left of the screen.\n\n- ``Switch Camera``: switch between the front and back camera modes.\n- ``Mute``: enable/disable audio transmission.\n- ``Mirror view``: mirror the the video feed. \n\n### Tilt to drive\n\nThe controller can also use its accelerometer motion sensor to drive the robot. If you select this option, the\ncontroller will enter a full-screen (Zen) mode with only the video showing and `brake` and `accelerator` pedals. To\nexit this mode, double-tap on the screen.\n\nHere is a picture of the `tilt mode` screen:\n\n<p float=\"left\">\n  <img src=\"../../docs/images/flutter_controller_tilt_mode.jpg\" width=\"50%\" />\n</p>\n\nUse the `accelerator` and `brake` buttons to move forward/backward.\n\n- Pressing the `accelerator` will accelerate the robot to full speed within 2 seconds. When you release the button, the\n  robot will slow down to a stop (stop speed set to 0% of the maximum speed, can be adjusted).\n- Pressing the `brake` button will immediately stop the robot. If we hold the brake for another second, the robot will\n  start moving backwards until it reaches the maximum reverse speed in one second. When we let go of the brake, the\n  robot will come to a stop.\n- The robot is steered by tilting the controller phone left or right.\n\nHere is a [Technical Overview](../../docs/technical/OpenBotController.pdf) of the controller app.\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/firmware/README.md": {
    "summary": "This firmware provides low-level control and sensor readings for the OpenBot robot. It supports various configurations for different hardware setups and enables features such as motor control, indicator lights, speed sensing, ultrasonic distance measurement, and collision detection. The firmware can be uploaded to an Arduino Nano or ESP32 development kit and tested using the Serial Monitor to verify functionality. For testing without a smartphone, the \"No Phone Mode\" allows the robot to drive at a predefined speed and respond to obstacles. The firmware also provides flexibility for use with other microcontrollers that meet specific hardware requirements.",
    "content": "# Firmware\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nWe use a microcontroller unit (MCU) to act as a bridge between the robot body and the smartphone.  We provide our [firmware](openbot/openbot.ino) for the Arduino Nano with an ATmega328P microcontroller as well as for the ESP32 development kit.\n\n## Features\n\nThe main task of the MCU is to handle the low-level control of the vehicle and provide readings from low-level vehicle-mounted sensors. The MCU receives the vehicle controls and indicator signals via the serial connection. It converts the controls to PWM signals for the motor controller and toggles the LEDs according to the indicator signal. The Arduino program also keeps track of the wheel rotations by counting the interrupts of optical sensors on the left and right front wheels. It calculates the battery voltage by a scaled moving average of measurements at the voltage divider circuit. It can also measure the distance to obstacles in front of the car with an optional ultrasonic sensor. These measurements are sent back to the Android application through the serial link.\n\n## Setup\n\nFirst you have to set up your hardware configuration at the beginning of the code. If you did the DIY build (using the L298N motor driver), set `OPENBOT DIY`.\nIf you used the custom PCB, check the version and set either `OPENBOT PCB_V1` or `OPENBOT PCB_V2`. If you have a OpenBot kit set `OPENBOT RTR_TT`. If you have retrofitted an RC truck, set `OPENBOT RC_CAR`. If you use the smaller DIY version for education, set `OPENBOT LITE`. If you use the OpenBot Ready-to-Run kit with 520-motors, set `OPENBOT RTR_520`. if you built the Multi Terrain Vehicle, you should set `OPENBOT MTV`. To run the `OpenBot DIY` with the ESP32 set OpenBot `DIY_ESP32`.\n\n## Bluetooth\n\nYou can run the OpenBot via bluetooth as well, for that you can enable the bluetooth by setting `BLUETOOTH 1` (disable: 0). For bluetooth to work you need OpenBot with ESP32 boards like `(RTR_520, MTV, DIY_ESP32)`.\n\n## Config\n\nNext, you need to configure which features you want to enable. Disabled features are not compiled to save memory and make the code faster. If a flag is not defined, the feature will be disabled. Each model has some default settings, that you may need to change depending on your configuration.\n\n- Enable the voltage divider by setting `HAS_VOLTAGE_DIVIDER 1` (disable: 0). If you have a voltage divider, you should also specify the `VOLTAGE_DIVIDER_FACTOR` which is computed as (R1+R2)/R2, `VOLTAGE_MIN` which is the minimum voltage to drive the motors, `VOLTAGE_LOW` which is the minimum battery voltage and `VOLTAGE_MAX` which is the maximum battery voltage.\n- Enable the indicator LEDs by setting `HAS_INDICATORS 1` (disable: 0).\n- Enable the front/back speed sensors by setting `HAS_SPEED_SENSORS_FRONT 1` / `HAS_SPEED_SENSORS_BACK 1` (disable: 0).\n- Enable the ultrasonic sensor by setting `HAS_SONAR 1` (disable: 0). Enable the median filter for sonar measurements by setting `USE_MEDIAN 1` (disable: 0).\n- Enable the bumper sensor which is used to detect collisions by setting `HAS_BUMPER 1` (disable: 0).\n- Enable the OLED display by setting `HAS_OLED 1` (disable: 0).\n- Enable the front/back/status LEDs by setting `HAS_LEDS_FRONT 1` / `HAS_LEDS_BACK 1` / `HAS_LEDS_STATUS 1` (disable: 0).\n\n### Dependencies\n\nIf you have enabled the speed sensors or the ultrasonic sensor, you need to install the [PinChangeInterrupt](https://github.com/NicoHood/PinChangeInterrupt) library. The Arduino Nano only has two external interrupt pins (D2 and D3) and D3 is also one of only six pins that support PWM. Fortunately, it also has three port interrupts that cover all pins on the Arduino. This library parses these port interrupts allowing all pins of the Arduino to be used as interrupts.\n\nIf you have enabled the OLED, you need to install the libraries [Adafruit_SSD1306](https://github.com/adafruit/Adafruit_SSD1306) and [Adafruit_GFX Library](https://github.com/adafruit/Adafruit-GFX-Library).\n\nYou can install libraries by following these steps:\n\n1. Open the Library Manager: `Tools` :arrow_right: `Manage Libraries`\n2. Enter the name of the library in the search bar.\n3. Select the latest version and click install. If you have already installed the library it will show and you may be able to update it.\n\n<p float=\"left\">\n  <img src=\"../docs/images/manage_libraries.jpg\" height=\"300\" />\n  <img src=\"../docs/images/install_library.jpg\" height=\"300\" /> \n</p>\n\n### Chinese clone Nano (e.g. US link)\n\nYou may need to download the [WCH340](http://www.wch.cn/product/CH340.html) drivers from the chip manufacturer (Chinese):\n\n- [Windows](http://www.wch.cn/downloads/CH341SER_EXE.html)\n- [Linux](http://www.wch.cn/download/CH341SER_LINUX_ZIP.html)\n- [Mac](http://www.wch.cn/download/CH341SER_MAC_ZIP.html)\n\n### ESP32 development kit\n\nTo install the ESP32 board in your Arduino IDE, follow these next instructions:\n\n1. In your Arduino IDE, go to **File> Preferences**:\n<p align=\"center\">\n  <img src=\"../docs/images/arduino-ide-open-preferences.png\" width=\"300\" alt=\"App GUI\"/>\n</p>\n\n2. Enter *https://dl.espressif.com/dl/package_esp32_index.json* into the â€œ_Additional Board Manager URLs_â€ field as shown in the figure below. Then, click the â€œOKâ€ button:\n<p align=\"center\">\n  <img src=\"../docs/images/arduino_preferences.png\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n**Note:** if you already have the ESP8266 boards URL, you can separate the URLs with a comma as follows:\n\n    https://dl.espressif.com/dl/package_esp32_index.json,\n    http://arduino.esp8266.com/stable/package_esp8266com_index.json\n\n3. Open the Boards Manager. Go to **Tools > Board > Boards Manager**:\n<p align=\"center\">\n  <img src=\"../docs/images/arduino_boardsManager.png\" width=\"800\" alt=\"App GUI\"/>\n</p>\n\n4. Go to tools and select the upload speed as 115200 (For newer ESP-32 chips such as ESP32-D0WD-V3 (revision v3.0)) .\n<p align=\"center\">\n<img src=\"../docs/images/arduino_upload-speed-select.png\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n5. Search for ESP32 and press install button for the â€œESP32 by Espressif Systemsâ€œ:\n<p align=\"center\">\n  <img src=\"../docs/images/arduino_installing.png\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n6. You should now have everything to successfully flash the ESP32 board of your OpenBot using the Arduino development envinronment\n<p align=\"center\">\n  <img src=\"../docs/images/arduino_ESP32-Board-add-on-in-Arduino-IDE-installed.png\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n7. To flash the OpenBot with your new code, simply select **ESP32 Dev Module** in the menu **Tools > Board > ESP32 Arduino**. Note that additional content as well as troubleshooting of the ESP32 flashing prcess can be found in the following [link](https://randomnerdtutorials.com/installing-the-esp32-board-in-arduino-ide-windows-instructions/).\n<p align=\"center\">\n  <img src=\"../docs/images/arduino_windows-select-board.png\" width=\"600\" alt=\"App GUI\"/>\n</p>\n\n\n## Upload\n\n### Settings (Arduino nano setup)\n\n- `Tools` :arrow_right: `Board` :arrow_right: `Arduino AVR Boards` :arrow_right: `Arduino Nano`\n- `Tools` :arrow_right: `Processor` :arrow_right: `ATmega328P (Old Bootloader)`\n- `Tools` :arrow_right: `Port` :arrow_right: `*Select the USB port*`\n\n:memo: NOTE: Currently, most cheap Arduino Nano boards come with the _Old Bootloader_. However, depending on the seller you may also get one with the new bootloader. So if you are unable to upload the firmware, chances are that you need to change the processor to _ATmega328P_.\n\n### Settings (ESP32 setup)\n\n- `Tools` :arrow_right: `Board` :arrow_right: `ESP32 Arduino` :arrow_right: `ESP32 Dev Module`\n- `Tools` :arrow_right: `Port` :arrow_right: `*Select the USB port*`\n\n### Uploading the firmware\n\nThe firmware can now be uploaded through `Sketch` :arrow_right: `Upload` or by pressing the upload button (right arrow).\n![Firmware Upload](../docs/images/firmware_upload.png)\n\n### Testing\n\nThis section explains how to test all functionalities of the car after the firmware was flashed successfully.\n\n1. Confirm that:\n   1. the wheels are not connected to the car\n   2. the Arduino is connected to the computer\n   3. the correct USB port is selected\n2. Open the Serial Monitor: `Tools` :arrow_right: `Serial Monitor`\n\n#### Sending messages to the OpenBot\n\nYou can also send messages to the Arduino by typing a command into the input field on the top and then pressing send. The following commands are available (provided the necessary features are supported by the robot):\n\n- `c<left>,<right>` where `<left>` and `<right>` are both in the range [-255,255]. A value of `0` will stop the motors. A value of `255` applies the maximum voltage driving the motors at the full speed forward. Lower values lead to proportionally lower voltages and speeds. Negative values apply the corresponding voltages in reverse polarity driving the motors in reverse.\n- `i<left>,<right>` where `<left>` and `<right>` are both in the range [0,1] and correspond to the left and right indicator LEDs. For example, `i1,0` turns on the left indicator, `i0,1` the right indicator and `i1,1` both indicators. Enabled indicator lights will flash once per second. A value of `i0,0` turns the indicators off. Only one state at a time is possible.\n- `l<front>,<back>` where `<front>` and `<back>` are both in the range [0,255] and correspond to the brightness of the front and back LEDs.\n- `s<time_ms>` where `<time_ms>` corresponds to the time in ms between sonar measurements triggered (default = 1000). After the sonar reading is aquired the message is sent to the robot. If it times out, the specified `MAX_SONAR_DISTANCE` is sent.\n- `w<time_ms>` where `<time_ms>` corresponds to the time in ms between wheel odometry measurements sent to the robot (default = 1000). The wheel speed is monitored continuously and and the rpm is computed as average over the specified time interval.\n- `v<time_ms>` where `<time_ms>` corresponds to the time in ms between voltage measurements sent to the robot (default = 1000). The voltage is monitored continuously and filtered via a moving average filter of size 10. In addition to setting the time interval for voltage readings, sending this command will also trigger messages that report the minimum voltage to drive the motors (`vmin:<value>`), minimum battery voltage (`vlow:<value>`) and maximum battery vollage (`vmax:<value>`).\n- `h<time_ms>` where `<time_ms>` corresponds to the time in ms after which the robot will stop if no new heartbeat message was received (default = -1).\n- `b<time_ms>` where `<time_ms>` corresponds to the time in ms after which the bumper trigger will be reset (default = 750).\n- `n<color>,<state>` where `<color>` corresponds to a status LED (`b` = blue, `g` = green, `y` = yellow) and `state` to its value (`0` = off, `1` = on).\n- `f` will send a request to the OpenBot to return a message with the robot type and its features, e.g. voltage measurement (`v`), indicators (`i`), sonar (`s`), bump sensors (`b`), wheel odometry (`wf`, `wb`), LEDs (`lf`, `lb`, `ls`), etc. For example, for the `RTR_V1` version of OpenBot the message would look like this: `fRTR_V1:v:i:s:b:wf:wb:lf:lb:ls:`.\n\n#### Receiving messages from the OpenBot\n\nDepending on your configuration you may see different messages.\n\n![Serial Monitor](../docs/images/serial_monitor.png)\n\n- Messages that start with `v` report the battery voltage. If you connect the battery to the car (i.e. turn on the switch), it should show the battery voltage. If you disconnect the battery (i.e. turn off the switch), it should show a small value.\n- Messages that start with `w` report readings of the speed sensors measured in revolutions per second (rpm). Each hole in the encoder disk will increment a counter by plus/minus one depending on the direction. You can set the number of holes with the parameter `DISK_HOLES`. If you are using the standard disk with 20 holes, there will be 20 counts for each revolution of the wheel.\n- Messages that start with `s` report the estimated free space in front of the ultrasonic sensor in cm.\n- Messages that start with `b` report collisions. The codes `lf` (left front), `rf` (right front), `cf` (center front), `lb` (left back), `rb` (right back) indicate which sensor triggered the collision.\n\n#### Test procedure\n\nBefore you proceed, make sure the tires are removed. You will need the Serial Monitor open to send commands and you will see the messages received from your OpenBot. If you have the OLED display installed, you will also see the vehicle status displayed there in a more human-readable format. The following test procedure can be used to test all functionalities of the car:\n\n1. Turn on the car and observe the battery voltage (the number after the `v`). You can verify the reading with a multimeter and adjust the `VOLTAGE_DIVIDER_FACTOR` if necessary.\n2. If you have an ultrasonic sensor installed:\n   1. Hold your hand in front of the sensor and move it back and forth. You should see the readings (the number after the `s`) change correspondingly.\n   2. We have observed that the ultrasonic sensor is very sensitive to vibrations! So it is advisable to make sure you will get reliable readings during operation by performing the following test:\n      1. Place the OpenBot with the ultrasonic sensor installed such that there is at least 200cm of free space in front of it. You should see a reading of `200` or more.\n      2. Observe the readings on the serial monitor for some time and then enter the command `c128,128`.\n      3. If the sensor readings change significantly, you will need to dampen the vibrations transmitted to the ultrasonic sensor from the chassis (e.g. add some silicon, adjust the mounting position).\n3. If you have the speed sensors installed:\n   1. Make sure, you have plenty of free space in front of the ultrasonic sensor. The reading (the number after the `s`) needs to be at least above the `STOP_DISTANCE` which is `10` by default.\n   2. Send the command `c128,128`. The motors will start spinning at _slow speed_ (50% PWM). The speed sensor readings (values after the `w`) are reported in rpm and should be between 250 and 300 for the RTR_TT version depending on the SOC of the battery. If you are using the DIY version or a weaker battery, values may be lower. Check that all motors are spinning forward and that the speed sensor readings are positive.\n   3. Try sending different controls and observe the speed sensor readings. For example, the command `c-128,-128` will spin all motors backward at _slow speed_ (50% PWM). The command `c255,-255` will spin the left motors forward and the right motors backward at _fast speed_ (100% PWM). The command `c-192,192` will spin the left motors backward and the right motors forward at _normal speed_ (75% PWM).\n4. Stop the motors by sending the command `c0,0` or by holding your hand in front of the ultrasonic sensor\n5. If you have the indicator LEDs installed, send the command `i1,0` and observe the left indicator light flashing. The send the command `i0,1` and observe the right indicator light flashing. Finally, turn the indicator off by sending the command `i0,0`.\n\n### No Phone Mode\n\nBefore testing the car with a smartphone that has the OpenBot application installed, you can also test the car without a phone first. Simply set the option `NO_PHONE_MODE` to `1`. The car will now drive at _normal_speed_ (75% PWM) and slow down as it detects obstacles with the ultrasonic sensor. Once it gets close to the `TURN_THRESHOLD` (default: 50cm), it will start turning in a random direction and turn on the LED on that side. If the estimated free space in front of the car falls below the `TURN_THRESHOLD`, it will slowly go backwards and both LEDs will turn on. Note that both the car and the Arduino need to be powered. The Arduino can be powered by connecting the 5V pin to the 5V output of the L298N motor driver, or by connecting the USB cable to a power source (e.g. phone).\n\nBefore running the car, we recommend to remove the tires, connect the Arduino to a computer and observe the serial monitor like in the section [Testing](#testing). The output on the serial monitor is a bit easier to parse (same as OLED) and shows the battery voltage, the rpm for the left and right motors and the estimated free space in front of the car. You can move a large object back and forth in front of ultrasonic sensor and observe the speed of the motors changing.\n\n:warning: WARNING: If you do not have an ultrasonic sensor installed or if it is disabled, the car will just drive forward at _normal_speed_ (75% PWM) and will eventually collide. Even with the sensor installed, the car may collide occasionally due to noisy readings.\n\n## Using other MCUs (requirements)\n\nYou can use any other MCU with the following features:\n\n- 1x USB-to-TTL Serial (communication with the smartphone)\n- 4x PWM output (control the motors)\n- 1x analog pin for battery monitoring\n- 2x digital pin for the speed sensors\n- 1x digital pin for the ultrasonic sensor (optional)\n- 2x digital pin for the indicator LEDs (optional)\n\n## Next\n\nCompile and run the [Android App](../android/README.md)\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/ios/OpenBot/OpenBot/Authentication/README.md": {
    "summary": "Google Firebase is a platform for mobile and web development that provides various services and tools for building high-quality apps. It includes features like real-time database, authentication, hosting, and storage, all integrated into a single platform.\n\nIn this application, Firebase's Google Sign-In authentication feature is used to allow users to sign in using their Google credentials. To integrate this feature into your iOS OpenBot application, you'll need a Google account, Cocoapods installed, and to follow the setup process outlined in the README. The guide includes instructions on creating a Firebase project, adding an iOS app to your project, enabling Google Sign-In authentication, installing the Firebase SDK using Cocoapods, and configuring the iOS project. Troubleshooting tips are also provided to address common issues that may arise during the configuration process.",
    "content": "## Google Firebase\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nGoogle Firebase is a mobile and web application development platform that offers a variety of services and tools to help\ndevelopers build high-quality apps quickly and efficiently. It includes features such as real-time database, user\nauthentication, hosting, cloud storage and many more, all these are integrated into a single platform. Firebase provides\na convenient and scalable solution for developers to manage their backend infrastructure, allowing them to focus on\nbuilding great user experiences.\n\n- ### Firebase Google Sign-In Authentication\n\n  Firebase Google Sign-In Authentication is a feature of the Firebase platform that allows users to sign in to mobile or\n  web apps using their Google credentials. This service provides a secure and convenient way for users to access apps\n  without having to remember and manage separate login credentials. Firebase manages the entire authentication process,\n  from verifying the user's identity with Google to providing a unique user ID that can be used to personalize the user'\n  s experience within the app. This feature also includes additional security measures, such as two-factor\n  authentication, to help protect user's account from unauthorized access.\n\n- ### Usage\n  In this application, we use Firebase for Google Sign-In authentication to\n  access [OpenBot Playground](../../../../open-code/README.md) projects\n  uploaded on Google Drive.\n\n- ### Note\n  If you plan to clone this IOS application and build it on your device, it's important to note that you will need\n  to [set up Firebase](../../../../open-code/README.md) for\n  the [OpenBot Playground](https://www.playground.openbot.org/) web application as well. This is because the IOS app\n  retrieves files from the user's Google Drive, which is created by Firebase Google Drive services. It's important to\n  use the same Firebase project for both the IOS and web applications for Google Drive services to work properly.\n\n- ### Prerequisites\n  To integrate Firebase into an IOS OpenBot application for Google Sign-In, we will need a few prerequisites.\n- **Google Account:** To use Google Sign-In with Firebase, you must have a Google account. If you don't have one, click\n  here to [create](https://accounts.google.com/signup) free Google account.\n- **Cocoapods:** It is a dependency manager for Swift and Objective-C projects. To install the Firebase SDK, you need to\n  have Cocoapods installed on your system.\n\n### Set up your Firebase project\n\n- Go to the [Firebase Console](https://console.firebase.google.com/) and create a `new project` following these steps.\n    1. Click on the \"Create Project\" button.\n    2. Enter a name for your Firebase project.\n    3. Click \"Next\" and disable Google Analytics services if you don't want to use them.\n    4. Click on the \"Create Project\" button.\n\n    <p>\n    <img src=\"../../../../docs/images/firebase_create_app_project.jpg\" alt=\"Create project\" width=\"25%\"/>\n    <img src=\"../../../../docs/images/firebase_enter_project_name.jpg\" alt=\"Enter project name\" width=\"40%\"/>\n    <img src=\"../../../../docs/images/firebase_disable_analytics.jpg\" alt=\"Disable analytics\" width=\"27.5%\"/>\n    </p>\n\n- To add a new IOS app to your Firebase project, do the following:\n    1. Click on the IOS icon in the Firebase project.\n    2. Enter your app's bundle ID. This should be the same bundle ID as the one used in your Xcode project.\n    3. Enter your app's nickname.\n    4. Click on the \"Register app\" button to complete the process.\n    5. Download the GoogleService-Info.plist file and add it to your Xcode project. This file contains the configuration\n       information needed to use Firebase in your app.\n\n       <p>\n       <img src=\"../../../../docs/images/firebase_add_ios_app.jpg\" alt=\"Add IOS Application\" width=\"47.5%\"/>\n       <img src=\"../../../../docs/images/firebase_bundle_id.jpg\" alt=\"Bundle ID Name\" width=\"30.5%\"/>\n       </p>\n\n    6. Click on the `Next` button and skip the third (Add Firebase SDK) and fourth (Add initialization code) steps as\n       it's already done for this project.\n    7. Continue to the Firebase Console to configure the Firebase services you want to use in your IOS app.\n\n   <p>\n     <img src=\"../../../../docs/images/firebase_google_service_info_plist.jpg\" alt=\"Add IOS Application\" width=\"35%\"/>\n     <img src=\"../../../../docs/images/firebase_continue_to_console_ios.jpg\" alt=\"Bundle ID Name\" width=\"35%\"/>\n   </p>\n\n- To `enable Google Sign-In authentication` for your Firebase project, follow these steps:\n    1. Go to the Firebase Console and select your project.\n    2. Click on the `All products` option in the left `sidebar menu`.\n    3. Click on `Authentication`.\n    4. Click on the `Get Started` button.\n    5. Click on the `Google icon`.\n    6. Click on the `toggle button` to `enable` Google Sign-In authentication.\n\n    <p>\n    <img src=\"../../../../docs/images/firebase_product_services.jpg\" alt=\"Firebase product services\" width=\"44.5%\"/>\n    <img src=\"../../../../docs/images/firebase_app_authentication.jpg\" alt=\"Firebase authentication\" width=\"48%\"/>\n    </p>\n    <p>\n    <img src=\"../../../../docs/images/firebase_app_google_signin.jpg\" alt=\"Google Sign-In\" width=\"60%\"/>\n    <img src=\"../../../../docs/images/firebase_google_signin_enable.jpg\" alt=\"Google Sign-In enable\" width=\"31.5%\"/>\n    </p>\n\n### Set up the iOS Project\n\nInstall the Firebase SDK using CocoaPods. Open the Terminal app on your Mac and navigate to your Xcode project's root\ndirectory. Run the following command to create a Podfile in your Xcode project's root directory:\n\n```\npod init\n```\n\nOpen the Podfile using your preferred text editor and add the following lines at the end of the file:\n\n```\n  pod 'Firebase/Core'\n  pod 'Firebase/Storage'\n  pod 'Firebase/Auth'\n  pod 'GoogleSignIn'\n  pod 'GoogleSignInSwiftSupport'\n  pod 'GoogleAPIClientForREST/Drive' \n  ```\n\nSave and close the Podfile, then Run the following command to install the Firebase SDKs:\n\n  ```\n  pod install\n```\n\n### Troubleshooting\n\nSome common issues that may occur during the Firebase configuration process and their solutions:\n\n```shell\n1. CocoaPods installation errors: If you encounter issues during the CocoaPods installation, such as pod install failing to run or not installing the correct Firebase SDK version, try the following solutions:\n```\n\n- Update your CocoaPods version by running sudo gem install cocoapods.\n- Delete the Podfile.lock file and run pod install again.\n- Make sure you have added the Firebase SDK pod to your Podfile correctly, using the exact version specified in the\n  Firebase Console.\n\n```shell\n2. Firebase configuration errors: If you are unable to configure Firebase correctly, such as not being able to initialize Firebase in your app, try the following solutions:\n```\n\n- Double-check that you have followed all the steps in the \"Set up the iOS Project\" section of this document correctly.\n- Make sure you have added the Firebase configuration file (GoogleService-Info.plist) to your Xcode project correctly.\n- Ensure that the Firebase SDK has been added to your Xcode project correctly and is being imported in your code.\n- Verify that your Firebase project is set up correctly in the Firebase Console, including the correct bundle ID and\n  other project settings.\n- Conflicts with other libraries: If you experience conflicts with other libraries in your project, such as having\n  conflicting dependencies or incompatible SDK versions, try the following solutions:\n- Ensure that you have specified the correct Firebase SDK version in your Podfile.\n- Try updating your other libraries to the latest version to see if the issue is resolved.\n- Check for any conflicting dependencies or library versions and try to resolve them by removing or updating the\n  conflicting libraries."
  },
  "https://github.com/ob-f/OpenBot/blob/master/ios/OpenBot/README.md": {
    "summary": "**iOS Robot App Beta Release**\n\n**Disclaimers:**\n\n* Safety: Operate in a safe environment.\n* App under development: Expect crashes and bugs.\n* App soon available on App Store.\n\n**App Screens:**\n\n* **Main Menu:**\n    * Menu with Bluetooth connection, settings, and various navigation screens.\n    * Home tab displays user's saved projects in \"openbot-opencode\" folder on Google Drive.\n* **Bluetooth Connection:**\n    * Wirelessly connects to OpenBot vehicle via Bluetooth Low-Energy (BLE).\n* **Free Roam:**\n    * Controls robot remotely, displays battery, speed, distance, and controller info.\n* **Control:**\n    * Select control mode (gamepad or phone) and drive mode (D/N/R).\n    * Adjust speed mode (slow, normal, fast).\n* **Data Collection:**\n    * Simple UI for collecting sensor data.\n* **Controller Mapping:**\n    * Check button and joystick mapping for connected controller.\n* **Robot Info:**\n    * Displays robot type, supported features, and sensor readings.\n* **Autopilot:**\n    * Run trained autopilot models.\n* **Object Tracking:**\n    * Track objects using AI models.\n* **Model Management:**\n    * Download and manage AI models.\n* **Navigation:**\n    * Navigate robot to specified goal location in 3D space.\n* **Projects Screen:**\n    * List and execute saved OpenBot Playground projects.\n* **Profile Screen:**\n    * Signed out: Google Sign-in button.\n    * Signed in: Edit profile, logout.\n* **OpenBot PlayGround Screen:**\n    * Access OpenBot Playground services.\n\n**Code Structure:**\n\n* Integrates TensorFlow Lite Object Detection iOS Demo for camera feed and model integration.\n* Contains model definitions for Autopilot and Detector networks.\n\n**Future Steps (optional):**\n\n* Train a custom Driving Policy.",
    "content": "# Robot iOS App - Beta Release\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n## DISCLAIMERS\n\n1. **Safety:** Always make sure you operate in a safe environment. Keep in mind, that your phone could be damaged in a collision! Special\n   care is necessary when using automated control (e.g. person following or driving policy). Make sure you always have a game controller connected and are familiar with the key mapping so you can stop the vehicle at any time. Use at your own risk!\n\n2. **App under development:** The application is under development and may crash or exhibit unexpected behaviour depending on your phone model and version of the operating system. Make sure to test all functionalities with no wheels connected. Use at your own risk!\n\n3. **The app will be `available` soon on the `App Store`.**\n\n## App Screens\n\n### Main Menu\n\nThe app starts with a menu screen that shows all available screens. The Bluetooth connection screen can be opened by clicking on the Bluetooth icon on top right hand side. The settings screen can be opened with a click on the settings icon right next to it. By clicking on the other icons, the user can access various screens whose functionalities are explained in subsequent sections.\n\nThe bottom of the app displays a tab bar with tabs for `Home, Projects, and Profile`. By default, the Home tab is displayed. If a user is logged in, all their saved projects in the \"openbot-opencode\" folder on Google Drive will be listed in Projects tab. The Profile tab includes buttons for accessing the user's profile and signing out.\n\n<p align=\"left\">\n<img style=\"padding-right: 2%;\" src=\"../../docs/images/ios_main_screen.jpg\" alt=\"Main Menu\" width=\"25%\"/>\n<img style=\"padding-right: 2%;\" src=\"../../docs/images/ios_bluetooth_screen.jpg\" alt=\"Bluetooth\" width=\"25%\"/>\n<img style=\"padding-right: 2%;\" src=\"../../docs/images/ios_settings_screen.jpg\" alt=\"Settings\" width=\"25%\"/>\n</p>\n\n#### Bluetooth Connection\n\nUnlike the Android app, which allows connecting the smartphone to the low-level control board of an OpenBot via a USB cable, the iOS app relies `solely` on a Bluetooth Low-Energy (BLE) wireless connection. When opening the Bluetooth connection screen in the iOS application (by clicking on the bluetooth logo from the main screen or from any fragment), a list of all compatible devices is displayed. Compatibility is here enforced by using a range of specific UUIDs assigned to an OpenBot vehicle at both the [app](https://github.com/isl-org/OpenBot/blob/090dcb28206195a7ee45a13b8ded968a8d365abe/ios/OpenBot/OpenBot/Utils/Constants.swift#L57) and [firmware](https://github.com/isl-org/OpenBot/blob/090dcb28206195a7ee45a13b8ded968a8d365abe/firmware/openbot_nano/openbot_nano.ino#L115) levels. You must ensure that these UUIDs match. Pairing an iOS device to an OpenBot vehicle then simply requires to select that vehicle from the list and press the \"Connect\" button. The default baud rate for the connection is set to 115200 and can be changed at the app and firmware level.\n\n<p align=\"left\">\n<img src=\"../../docs/images/ios_ble.gif\" alt=\"BLE connection\" width=\"25%\" />\n</p>\n\n### Free Roam\n\nFree Roam offers simple robot control with real time updates and information about battery, speed and distance from surfaces. It also offers controls related to controller, drive mode and speed.\n\n<p align=\"left\">\n<img src=\"../../docs/images/ios_free_roam_screen.jpg\" alt=\"Alt text\" width=\"50%\" />\n</p>\n\n- **Battery**: The battery icon shows realtime battery levels of the connected robot.\n\n- **Drive Mode**: There are 3 drive modes displayed on the view:\n\n  - D -> Drive, when the robot is driving forward\n\n  - N -> Neutral, when the robot is stationary\n\n  - R -> Reverse, when the robot is moving backwards\n\n- **Speed**: The speedometer shows the realtime speed of the robot.\n\n- **Sonar**: The sonar view distance of robot from an oncoming object in cm.\n\n- **Bluetooth**: Shows the status of bluetooth connection with the microcontroller. on tapping the icon, the user can also be redirected to the Bluetooth screen to view/modify the connection.\n\n#### Control\n\nThe first button is for selecting the **control mode**. There are two different control modes:\n\n- **Gamepad**: The app receives controls from a connected BT controller.\n- **Phone**:  The robot can be controlled via another smartphone with the controller app installed or though a Python script running on a computer connected to the same network.\n\nThe second button is for selecting the **drive mode**. There are three different drive modes when using a game controller (e.g. PS4):\n\n- **Game**: Use the right and left shoulder triggers (R2, L2) for forward and reverse throttle and either joystick for steering. This mode imitates the control mode of car racing video games.\n- **Joystick**: Use either one of the joysticks to control the robot.\n- **Dual**: Use the left and right joystick to control the left and right side of the car. This is raw differential steering.\n\nThe third button is for selecting the **speed mode**. There are three different speed modes:\n\n- **Slow**: The voltage applied to the motors is limited to 50% of the input voltage (~6V).\n- **Normal**: The voltage applied to the motors is limited to 75% of the input voltage (~9V).\n- **Fast**: There is no limit. The full input voltage will be applied to the motors at full throttle (~12V). *This is the default setting for running the neural networks.*\n\nRunning at higher speeds will reduce the lifetime of the motors but is more fun. The controls that are sent to the robot are displayed on the right side. When using the game controller, the speed mode can be increased by pressing down the right joystick (R3) and decrased by pressing down the left joystick (L3).\n\n[//]: # (#### Data Log)\n\n[//]: # ()\n[//]: # (There are four different logging modes:)\n\n[//]: # ()\n[//]: # (- **only_sensors**: All sensor data but no images are saved.)\n\n[//]: # (- **crop_img**: All sensor data and a cropped images that have the input size of the network are saved. This is the default setting and is what should be used for data collection.)\n\n[//]: # (- **preview_img**: All sensor data and a full-size images are saved. This will require a lot of memory and can be slow. However, it is nice for compiling FPV videos.)\n\n[//]: # (- **all_imgs**: All sensor data and both cropped and full-size images are saved. This will require a lot of memory and can be slow.)\n\n[//]: # ()\n[//]: # (The switch on the right is used to toggle logging on and off. On the game controller this switch can be toggled with the X button.)\n\n[//]: # ()\n[//]: # (#### Camera)\n\n[//]: # ()\n[//]: # (The first item shows the preview resolution. The second item shows the crop resolution. This is the image that is used as input to the neural networks. You will notice that this resolution changes depending on which model you select below. If you train your own autopilot, make sure to select the `AUTOPILOT_F` model. The crop resolution should show `256x96`. The switch on the right is used to toggle between the rear and the front camera.)\n\n[//]: # ()\n[//]: # (#### Model)\n\n[//]: # ()\n[//]: # (There are two models that come with the app:)\n\n[//]: # ()\n[//]: # (- **MobileNetV1-300**: This model is used for person following. It uses a SSD object detector with MobileNet V1 backbone. The model is quantized for better performance on embedded devices. It comes with the app.)\n\n[//]: # (- **CIL-Mobile**: This model is used for autonomous navigation. It will predict controls directly from the camera input. Chances are that it will not work in your environment. You should follow our instructions to train your own [Driving Policy]&#40;../../policy&#41; and replace it.)\n\n[//]: # ()\n[//]: # (Additonal models can be downloaded from the Model Management screen.)\n\n[//]: # ()\n[//]: # (The switch on the right is used to turn the network on and off. When the network is running, it produces the controls for the robot and the game controller is disabled. However, you may still use the buttons on the game controller, for example to toggle this switch with the R1 trigger button to regain control of the robot.)\n\n[//]: # ()\n[//]: # (#### Device)\n\n[//]: # ()\n[//]: # (Use the drop-down menu to select the device on which the neural network should be executed. You have the following choices:)\n\n[//]: # ()\n[//]: # (- **CPU**: Using the CPU works on most phones and is the default choice. You can adjust the number of threads to optimize performance.)\n\n[//]: # (- **GPU**: Most smartphones have a GPU. Networks with large inputs such as images often run faster on a GPU.)\n\n[//]: # (- **NNAPI**: This will use the [TensorFlow Lite NNAPI delegate]&#40;https://www.tensorflow.org/lite/performance/nnapi&#41;. Modern smartphones often come with dedicated AI accelerators. The [Neural Network API]&#40;https://developer.android.com/ndk/guides/neuralnetworks&#41; &#40;NNAPI&#41; provides acceleration for TensorFlow Lite models on Android devices with Graphics Processing Unit &#40;GPU&#41;, Digital Signal Processor &#40;DSP&#41; and Neural Processing Unit &#40;NPU&#41;. Note that on some older phones this can be very slow!)\n\n[//]: # ()\n[//]: # (If a model is active, the inference speed in [ms] will be displayed next to the device which is running the model.)\n\n### Data Collection\n\n\nSimple UI for collection of data sets.\n\n<p align=\"left\">\n\n<img src=\"../../docs/images/ios_data_collection_screen.jpg\" alt=\"Data Collection\" width=\"50%\" />\n\n</p>\n\n\n- **Preview Resolution**: Used to switch between resolutions of camera preview. There are 3 settings:\n\n  - ***HIGH*** (1920x1080p)\n\n  - ***MEDIUM*** (1280x720p)\n\n  - ***LOW*** (640x360)\n\n\n- **Model Resolution**: Used to switch between resolutions of images saved for training different models.\n\n- **Server**: Server functionality is under Development.\n\n- **Log Collected Data**: the data collection process can be controlled from the screen or remotely, for instance from a bluetooth controller. When using a bluetooth controller, you may:\n\n  - press the **A button** to **start** the data collection process\n\n  - press the **A button again** to **stop** data collection and save the collected data in a .zip file\n\n  - alternatively press the **R1 button** to **stop** data collection **without saving** the collected data (for instance because of an unexpected collision with the environment)\n\n  - remember to use the controller mapping fragment to ensure you are using the correct buttons.\n\n- **Vehicle Status**: The field **Battery** displays the battery voltage as measured by the microcontroller via the voltage divider. The field **Speed (l,r)** reports the left and right speed of the (front) wheels in rpm. It is measured by the microcontroller via the optical wheel speed sensors. The field **Sonar** shows the free space in front of the car in centimeters. It is measured by the microcontroller via the ultrasonic sensor. Note, you will only receive values a few seconds after the USB connections has been established.\n\n- **Sensors**: Reports measurements from vehicle sensors. Currently, we record readings from following sensors: camera, gyroscope, accelerometer, magnetometer, ambient light sensor, and barometer. Using the iOS API, we are able to obtain the following sensor readings: RGB images, angular speed, linear acceleration, gravity, magnetic field strength, light intensity, atmospheric pressure, latitude, longitude, altitude, bearing, and speed. In addition to the phone sensors, we record body sensor readings (wheel odometry, obstacle distance and battery voltage), which are transmitted via the serial link. We also record and timestamp control signals received from a connected controller, if present. Lastly, we integrate several neural networks for person following and autonomous navigation.\n\n### Controller Mapping\n\nSimple UI to check the button and joystick mapping of a connected BT controller.\n\n<p align=\"left\">\n<img src=\"../../docs/images/ios_controller_mapping.jpg\" alt=\"Controller mapping\" width=\"30%\" />\n</p>\n\n### Robot Info\n\nSimple UI to get robot info and test basic functionality. The **Robot Type** as configured in the firmware is displayed as text and animation. The checkmarks in the sections **Sensors**, **Wheel Odometry** and **LEDs** show which features are supported by the connected robot. The section **Readings** provides the most important sensor measurements. In the section **Send Commands**, users can send basic motor commands by pressing the corresponding buttons and control the front and rear LEDs with a slider.\n\n<p align=\"left\">\n<img src=\"../../docs/images/ios_screen_robot_info.gif\" alt=\"Robot Info\" width=\"50%\" />\n</p>\n\n### Autopilot\n\n\nSimple UI for running autopilot models.\n\n\n<p align=\"left\">\n\n<img src=\"../../docs/images/ios_autopilot_screen.jpg\" alt=\"Autopilot\" width=\"50%\" />\n\n</p>\n\n- **Server**: If you have the [web app](../../policy#web-app) for policy training running, you can select it here and send trained autopilot models to the robot.\n- **Model**: Choose a trained model to use for autopilot mode.\n- **Device**: Use CPU, GPU or NNAPI for inference (more details [here](#device)).\n- **Threads**: Number of threads to use (only makes a difference when CPU is selected as device).\n- **Control**: Controller, Drive Mode and Speed are used to control robot settings as described in the [control section](#control).\n\n### Object Tracking\n\n\nSimple UI for tracking objects of 80 different classes. A short description of the different AI models for object tracking and performance benchmarks can be found in [Model Management](#model-management).\n\n\n<p align=\"left\">\n<img src=\"../../docs/images/ios_object_tracking_screen.jpg\" alt=\"Object Tracking\" width=\"50%\" />\n</p>\n\n- **Dynamic Speed**: reduces the robot speed in \"Auto Mode\" if it gets closer to the tracked object.\n  The speed is scaled based on the area of the bouding box (works best in landscape orientation).\n- **Model**: Choose an object detector based on your phone performance.\n- **Object**: Pick the object you want to track. The models can detect the 80 COCO [object classes](https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/).\n- **Confidence**: Confidence threshold to determine if detections are accepted. Increase if you get false detections, decrease if the object of interest it not detected.\n- **Device**: Use CPU, GPU or NNAPI for inference (more details [here](#device)).\n- **Threads**: Number of threads to use (only makes a difference when CPU is selected as device).\n- **Control**: Controller, Drive Mode and Speed are used to control robot settings as described in the [control section](#control).\n\n### Model Management\n\nAll models are quantized for better performance on embedded devices. Note that models with larger input resolution might be better for smaller objects despite lower mAP.\n\n<p align=\"left\">\n<img src=\"../../docs/images/ios_screen_model_management.gif\" alt=\"Model Management\" width=\"25%\" />\n</p>\n\n\n### Navigation\n\nThe `Point Goal Navigation` screen allows the user to set a goal location for the robot to navigate to using forward and left values in 3D space. To access this screen, simply tap on the corresponding button in the app.\n\nUpon tapping, a popup will appear with two input fields labeled `Forward` and `Left`. The user can enter values into these fields to set the goal location for the robot to navigate to. The popup also contains two buttons: `Cancel` and `Start`.\n\n- `Cancel` button: This button will return the user to the home screen and cancel the navigation process.\n\n\n- `Start` button: This button will create a point in 3D space using the forward and left values entered by the user and start the navigation process. The robot will begin moving towards the goal location and adjusting its trajectory and speed as needed to reach the destination.\n\nIf the robot successfully reaches the goal location, a message will appear indicating that the goal has been reached, and the robot will stop moving.\n\nNote that this feature uses `ARKit`, a framework developed by Apple for augmented reality applications. The user will need to have an ARKit-compatible device to use this feature.\n\n<p align=\"left\">\n<img src=\"../../docs/images/ios_set_navigation_screen.jpg\" alt=\"Model Management\" width=\"25%\" />\n<img src=\"../../docs/images/ios_navigation_screen.jpg\" alt=\"Model Management\" width=\"25%\" />\n</p>\n\n\n### Projects Screen\n\nThe Projects Screen displays a list of your OpenBot Playground projects if you are signed in with your Google account. You can execute these projects to connect with your OpenBot, or scan their QR codes by clicking the scanner icon in the top right corner. If you are not signed in, the screen will display a Google Sign-In button, but you can still scan your project's QR code without signing in. If you get the message `Oops, no project found` on the screen after signing in, make sure that the account has projects stored on Google Drive.\n\nIf you don't see your latest projects in the project list, you can reload them by pulling down on the project screen.\n\n<p align=\"left\">\n<img src=\"../../docs/images/projects_tab_screen_ios.gif\" alt=\"Project Screen\" width=\"25%\"/>\n<img src=\"../../docs/images/no_projects_found_ios.jpg\" alt=\"No project screen\" style=\"padding-left: 0.3%\" width=\"26.5%\"/>\n<img src=\"../../docs/images/reload_projects_ios.gif\" alt=\"Reload project screen\" width=\"25%\"/>\n</p>\n\n- **Google Drive projects**: To run a Google Drive project, tap on the project you want to execute and wait for the contents of the project file to be read. If the file is successfully retrieved without any errors, a pop-up will appear with two buttons: `Start` and `Cancel`. The pop-up will also display the name of the project you are about to run. To execute the project, click on the Start button. If you want to stop the activity, click on the Cancel button. If you receive a pop-up message stating `Something went wrong`, there may be an error with the Google Drive file. To resolve this issue, refresh the project screen by pulling down and then repeating the same process.\n\n\n- **Qr code scanner**: To scan the QR code of a Playground project, click on the QR code icon located in the top right corner of the screen. Grant camera access to the app so that it can scan the QR code. Once the code is scanned, wait for the contents of the file to be read. If the file is retrieved successfully without any errors, a pop-up will appear with two buttons: `Start` and `Cancel`. The pop-up will also display the name of the project you are about to run. To execute the project, click on the Start button. If you want to stop the activity, click on the Cancel button. If you receive a pop-up message stating `Something went wrong`, there may be an error with the Google Drive file. To resolve this issue, generate a new QR code in Playground and repeat the process.\n\n\n- **Executing Project**: If your OpenBot Playground project runs successfully, the screen will display the names of code blocks along with a stop button that can be used to stop the execution of playground block commands.\n\n\n- **Delete Project**: To delete a project, long-press on the project you wish to delete. This will bring up a popup screen asking to confirm the deletion. Tap on 'Yes' to delete the project.\n\n<p align=\"left\">\n<img src=\"../../docs/images/google_drive_projects_execute_ios.gif\" alt=\"Google Drive project execute\" width=\"25%\" />\n<img src=\"../../docs/images/ios_qr_scan.gif\" alt=\"Qr code scanner project execute\" width=\"25%\" />\n<img src=\"../../docs/images/delete_project_ios.jpg\" alt=\"Delete project popup\" style=\"padding-right: 1.2%\" width=\"26%\" />\n</p>\n\n\n### Profile Screen\nThe Profile Screen in the app provides different options based on whether the user is signed in or not.\nIf the user is not signed in, a `Google Sign-in` button will appear, prompting the user to sign in their Google account. Once signed in, the user will be able to access their profile and other features.\nIf the user is signed in, two buttons will be listed in the  `Profile` tab: `Edit Profile` and `Logout`.\n\n<p align=\"left\">\n<img src=\"../../docs/images/logged_out_profile_screen_ios.jpg\" alt=\"Logged out profile screen\" width=\"25%\"/>\n<img src=\"../../docs/images/logged_in_profile_screen_ios.jpg\" alt=\"Logged in profile screen\" width=\"25%\"/>\n</p>\n\n- **Edit Profile**: Tapping on this button will open a new screen where the user can update their profile information, such as their name and profile picture.\n\n\n- **Logout**: This button allows the user to log out of their account. Tapping on this button will log the user out and return them to the login screen.\n\n<p align=\"left\">\n<img src=\"../../docs/images/ios_edit_profile_screen.jpg\" alt=\"Edit profile screen\" width=\"25%\"/>\n<img src=\"../../docs/images/logout_dialog_box_ios.jpg\" alt=\"Logout dialog box\" width=\"25%\"/>\n</p>\n\n\n### OpenBot PlayGround Screen\n\nTo access OpenBot Playground services, click on the OpenBot Playground icon located at the top of the screen in project's screen toolbar options. If you want to learn more about OpenBot Playground, [Click here](../../open-code/README.md).\n\n<p align=\"left\">\n<img src=\"../../docs/images/playground_services_ios.gif\" alt=\"Playground Services\" width=\"25%\" />\n<img src=\"../../docs/images/playground_sign-in_ios.gif\" alt=\"Playground sign-in\" width=\"25%\" />\n</p>\n\n## Code Structure\n\nThe [TensorFlow Lite Object Detection iOS Demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/ios) was used as starting point to integrate TFLite models and obtain the camera feed. The [tflite](OpenBot/tflite) folder contains the model definitions for the [Autopilot](OpenBot/tflite/Autopilot.swift) and [Detector](OpenBot/tflite/Detector.swift) networks.\n\n## Next (optional)\n\nTrain your own [Driving Policy](../../policy/README.md)\n\nFirebase Authentication [Firebase](../OpenBot/OpenBot/Authentication/README.md)\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/open-code/src/components/blockly/README.md": {
    "summary": "OpenBot PlayGround provides visual blocks for programming an OpenBot robot. These blocks cover various categories, including:\n\n* Control: Logic blocks for controlling program flow (loops, conditionals).\n* Operators: Arithmetic and mathematical operations.\n* Variables: Data storage and manipulation.\n* Lights: LED brightness control.\n* Controller: Gamepad or phone control selection.\n* Sound: Play sounds based on speed and drive modes.\n* Sensors: Readings from phone and car sensors (e.g., gyroscope, bumpers).\n* Movement: Robot speed and direction control.\n* Artificial Intelligence: Object tracking, autopilot, and point goal navigation features.\n* Advanced Artificial Intelligence: Multiple object detection and autopilot functionality.",
    "content": "## OpenBot PlayGround:\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n### OpenBot Robot Info:\n\n- OpenBot Robot configures the following components inside it.\n    - Sensors: Voltage divider, Sonar, Bumpers, Speed.\n    - Wheel Odometer: Front and Back wheels.\n    - Led's: Indicators, Front, Back, status.\n    - Motors: Forward and Backward.\n\n### OpenBot PlayGround Categories:\n\n- ### Control:\n\n  OpenBot PlayGround includes customizable blocks that can be used to control the flow of program such as loops, events\n  and conditionals. It provides a visual way for users to structure the logic of their programs.\n\n    <img src=\"../../../../docs/images/playground_blockly_control.jpg\" height=\"50%\" width=\"50%\"/>\n\n  A brief overview of some control blocks:\n    - Start: Initiates the execution of program and execute the block code single time.\n    - Conditionals: ``If`` and ``If-else`` blocks are used to create conditional branches in your code.\n        - Wait: Brings pauses or delays in the code execution.\n        - Forever: Once the Forever block is embedded in place then it will create an infinite loop which indicates that\n          loop will continue indefinitely with each iteration.\n\n- ### Loops:\n\n  Loops category provides various blocks that helps to control the flow of your program through repetition.\n\n     <img src=\"../../../../docs/images/playground_blockly_loops.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Some loop blocks examples are listed here below:\n\n    - Repeat: The ``Repeat`` block enables you to define the number of iterations for a set of blocks to be executed.\n    - While: The ``While`` block continues executing a set of blocks as long as a specified condition remains true.\n\n- ### Operators:\n\n  Operators allow you to perform several operations or calculations within your program. The blocks allow you to build\n  complex expressions and conditions according to the requirement.\n\n  <img src=\"../../../../docs/images/playground_operator_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Here are some common types of operators that you might find in OpenBot PlayGround:\n\n    - Arithmetic: Addition, subtraction, multiplication, division, and other arithmetic operations are available in this\n      category.\n    - Math Operators: Blocks like \"Power,\" \"Square Root,\" and \"Random Fraction\" are used to perform more advanced\n      mathematical computations.\n\n\n- ### Variables:\n\n  Variables are used for data storage within your blocks and inside variables category blocks allow you to declare, set,\n  change and manipulate variables.The concept of variables in OpenBot PlayGround help you to manage and manipulate data\n  in your programs.\n\n  <img src=\"../../../../docs/images/playground_variable_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Have a look on some Variable block examples:\n\n    - Set: Set Variable block is going to assign a value to a variable.\n    - Change: It will help you to modify the value of an existing variable.\n\n- ### Lights:\n\n  Lights are another type of category that is provided by OpenBot PlayGround which helps to make the use of indicators\n  and can set the values of brightness dynamically.\n\n  <img src=\"../../../../docs/images/playground_light_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Below are some examples:\n    - Indicators: Block used to enable indicators by turning them ON/OFF.\n    - Brightness: used to set the brightness of tail and head LED by taking dynamic values.\n\n  NOTE: Keeping the brightness at zero will make the brightness mode OFF and if the brightness is at the highest point\n  ie.100 will turn ON the brightness mode.\n\n- ### Controller:\n\n  Certainly! When selecting a mode within the controller block, it will be applied uniformly across all other fragments\n  within the OpenBot robot app.\n\n  <img src=\"../../../../docs/images/playground_controller_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Below are the examples of Controller Block:\n\n    - Switch Controller: It helps you to choose the Controller method by either Gamepad or Phone.\n    - Drive Mode: It helps you to switch the Drive Mode by either Joystick or Game or dual.\n\n   <p style=\"color:yellow \">TIP: If you are selecting Phone as a controller then drive mode automatically sets to dual in robot app irrespective of block chosen drive mode. </p>\n\n- ### Sound:\n\n  Sound Blocks can be utilized to play sound for drive modes and robot static speed.\n\n  <img src=\"../../../../docs/images/playground_sound_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Let's have some examples:\n\n    - Speed: Helps you to play the sound as slow, medium and fast.\n    - Mode: Helps you to play the sound as dual, joystick or game.\n\n- ### Sensors:\n\n  Sensors are the blocks which are going to return different readings for OpenBot condition and environment status .\n\n  <img src=\"../../../../docs/images/playground_sensors_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Overview:\n    - Phone Sensors: Help to measure Gyroscope,Acceleration, and Magnetic readings at different axis(3-Dimensional).\n    - Car Sensors: Help to provide the different readings like Sonar, Speed. Also, it will check if bumper gets collide\n      with an obstacle.\n\n- ### Movement:\n\n  As the name suggests it is responsible for the movement of Robot at any speed and in any direction and the speed limit\n  is 0-255.\n\n  <img src=\"../../../../docs/images/playground_movement_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Let's have some examples:\n\n    - Set speed: Helps to set the speed as slow, medium and fast.\n    - Move: Helps to make the movement in forward or backward and left or right direction at required speed.\n\n  Key Points:\n    - if the left speed value is set lower than the right, the robot will move counterclockwise, or vice versa.\n    - If you equalize the left and right speeds, it will move straight.\n    - Setting a positive value on the left and a negative value on the right will cause the robot to spin.\n\n\n- ### Artificial Intelligence(AI):\n\n  OpenBot Playground provides another important category named Artificial Intelligence which further configures many\n  features such as Object Tracking, Autopilot, Point Goal Navigation.\n\n  <img src=\"../../../../docs/images/playground_ai_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  Lets understand this concept by some examples of blocks:\n    - ``Object Tracking``: Its primary function revolves around detecting objects. This AI fragment allows you to pick\n      any\n      object for tracking. Depending on your phone's performance, you have the flexibility to choose an object detector\n      model. By default, this block comes equipped with the \"MobileNetV1-300\" model. Additionally, you have the option\n      to manually add any model of your choice.\n    - ``AutoPilot``: This snippet is also available through OpenBot Playground, utilizing data collection, wherein a\n      pre-trained\n      dataset (ML model CIL-Mobile-Cmd) is already integrated. Subsequently, the camera fragment is displayed on the\n      screen,\n      initiating the tracking of the captured path.\n    - ``Point Goal Navigation``: The primary objective of this block is to reach a designated point through navigation.\n      You can\n      configure the forward and left values in 3-dimensional view using the navigation models within it. When the\n      project is\n      executed on a phone, the point navigation fragment will be displayed on the screen with an Augmented Reality (AR)\n      view. Subsequently, the robot will initiate movement until it successfully reaches the goal.\n\n   <p style=\"color: yellow\"> TIP: If you've incorporated an external modal, ensure to enable AutoSync in the playground. This feature will assist you in display newly added model in block and verifying the availability and successful download of the modal in robot app.</p>\n\n- ### Advanced Artificial Intelligence(AI):\n\n  The OpenBotPlayground introduces several advancements, featuring an Advanced Artificial Intelligence (AI) that offers\n  modular blocks for detection and autopilot functionality\n\n  <img src=\"../../../../docs/images/playground_advance_ai_blocks.jpg\" height=\"50%\" width=\"50%\"/>\n\n  #### Multiple Detection Block:\n\n    - This advanced module is designed for object tracking, accommodating various classes such as a person, car, book,\n      traffic light, etc. The identification of the object is carried out by the integrated AI model. The functionality\n      of this module is contingent upon the specified conditions.\n    - The block is designed to enable multiple object detections, initializing the process for the specified class. Once\n      the chosen class is detected, the robot will execute all tasks outlined in the subsequent 'do' statement. If the\n      specified class is not detected within the defined number of continuous frames, the robot will proceed to execute\n      the tasks specified in the subsequent ``do`` statement. The block can be use multiple times within the playground\n      for different classes as well. \n\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/open-code/src/services/README.md": {
    "summary": "This README describes how to set up Firebase Google Sign-In Authentication to upload OpenBot Playground projects to Google Drive. It includes instructions on:\n\n- Creating a Firebase project and configuring the web app\n- Enabling Firebase Authentication and Google Sign-In\n- Setting up Google Drive services and enabling the API\n- Adding environment variables for Firebase configuration\n- Troubleshooting common errors related to invalid credentials, disabled accounts, and CORS.",
    "content": "## Firebase Google Sign-In Authentication\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n- #### Usage\n  In web application, we use Firebase for Google sign-in authentication to upload OpenBot Playground projects on Google\n  Drive. If you clone this project and run on your device, you must set up your own Firebase project because the\n  firebase configuration is required for sign-in authentication.\n- #### About  Google Sign-In\n  Firebase Google Sign-In Authentication is a feature of the Firebase platform that allows users to sign in to mobile or\n  web apps using their Google credentials. This service provides a secure and convenient way for users to access apps\n  without having to remember and manage separate login credentials. Firebase manages the entire authentication process,\n  from verifying the user's identity with Google to providing a unique user ID that can be used to personalize the user'\n  s experience within the app. This feature also includes additional security measures, such as two-factor\n  authentication, to help protect user accounts from unauthorized access.\n\n****\n\n### Setting up Firebase Project\n\n- Go to the Firebase Console (https://console.firebase.google.com/) and sign in with your Google account.\n\n- Click on the `Add Project` button to create a new Firebase project.\n\n- Enter a name for your project, select your country/region, and then click on the `Create Project` button.\n    <p align=\"left\">\n    <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%\" src=\"../../../docs/images/firebase_create_project.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n    <img style=\"padding-right: 2%;padding-top: 2%; padding-bottom: 2% \" src=\"../../../docs/images/firebase_success_creation.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n    </p>\n\n- Once your project is created, click on the `Web` icon to add Firebase to your web app and then enter an App nickname\n  and click on the `Register App` button.\n  <p align=\"left\">\n  <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_web_icon.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n  <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_register_app.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n  </p>\n\n    - Add `firebase SDK` to your project's `env` file.\n        - When creating project you will get firebase here, or you can get it from project setting.\n          <p align=\"left\">\n          <img style=\"padding-right: 2%;padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_sdk.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n          <img style=\"padding-right: 2%;padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_project_setting.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n          <img style=\"padding-right: 2%;padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_project_setting_config.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n          </p>\n\n        - Using Environment Variables When using Firebase Authentication, you may need to store sensitive information\n          such as API keys, database credentials, and other secrets. To do this securely, you can use environment\n          variables to store this information outside your code. by doing following steps.\n\n            1. Create a new file in OpenBot Playground called .env.\n                 <p align=\"left\">\n                <img style=\"padding-right: 2%;padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_env.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n                 </p> \n\n            3. Add following environment variables to the .env file that will be used in firebase.js file.\n\n            ```bash\n              REACT_APP_FIREBASE_API_KEY=<REACT_APP_FIREBASE_API_KEY>\n              REACT_APP_AUTH_DOMAIN=<REACT_APP_AUTH_DOMAIN>\n              REACT_APP_PROJECT_ID=<REACT_APP_PROJECT_ID>\n              REACT_APP_STORAGE_BUCKET=<REACT_APP_STORAGE_BUCKET>\n              REACT_APP_MESSAGING_SENDER_ID=<REACT_APP_MESSAGING_SENDER_ID>\n              REACT_APP_APP_ID=<REACT_APP_APP_ID>\n              REACT_APP_MEASUREMENT_ID=<REACT_APP_MEASUREMENT_ID>\n              GENERATE_SOURCEMAP=false\n            ```\n\n- Enable Firebase Authentication SignIn method using Google.\n\n  <p align=\"left\">\n\n  <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_authentication.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n\n  <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_google_option.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n\n  <img style=\"padding-right: 2%;padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_google_signin_enable.jpg\" alt=\"Create New Project\" width=\"22.6%\"/>\n\n  </p>\n\n\n- Enabling Firestore database, navigate to the Build menu on the left sidebar.\n  Click on ``Firestore Database`` from the options. Then, Click on ``Create database`` button.\n\n  <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firestore_database_setup.jpg\" alt=\"Google Cloud Console\" width=\"50%\"/>\n\n    - For secure rules, select ``Start in production mode`` and choose firestore location for the\n      app and click on the ``Enable`` button.\n\n      <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_database_production_build.jpg\" alt=\"Google Cloud Console\" width=\"30%\"/>\n      <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_database_location.jpg\" alt=\"Google Cloud Console\" width=\"30%\"/>\n\n        - Once your database is created, click on the ``Rules`` to configure permissions for read and write.\n\n          <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_database_rules.jpg\" alt=\"Google Cloud Console\" width=\"30%\"/>\n\n        - Replace the default rules with below code and click on ``Publish`` button.\n\n          ```bash\n          rules_version = '2';\n          service cloud.firestore {\n              match /databases/{database}/documents {\n                  match /{document=**} {\n                      allow read, write: if request.auth != null;\n                  }\n              }\n          }\n          ```\n        \n### Setting up Google Drive Services\n\n- #### To Enable API\n  Go to the Google Cloud\n  Console (https://console.cloud.google.com/) and sign\n  in using the same Google account that you\n  use for Firebase. This ensures seamless integration between the services. At the top of the page, you'll see the current project name. Click on it to open the project selector. Under the `ALL` section, select the project you added to firebase and switch to it.\n\n  <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_google_cloud_console.jpg\" alt=\"Google Cloud Console\" width=\"30%\"/>\n  <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_google_cloud_project.jpg\" alt=\"Google Cloud Console\" width=\"30%\"/>\n\n- After switching, under Quick access, you should see an option\n  labeled ``APIs & Services``. Click on it.\n  If you don't see it immediately, you might need to click on the menu icon (usually three horizontal lines) at the\n  top left corner to expand the menu and reveal the options.\n\n  <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_google_api_services.jpg\" alt=\"Google Cloud Console\" width=\"50%\"/>\n\n    - After opening \"APIs & Services\", navigate to the ``Library`` section. This is where you can search for Google\n      Drive API.\n      <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_google_drive_library.jpg\" alt=\"Google Cloud Console\" width=\"50%\"/>\n\n    - The Google Drive API should appear in the search results. Click on it.\n      On the next page, you'll find information about the API. Click the \"Enable\" button to enable it for your project.\n      Once enabled, you'll be able to access and manage the Google Drive and Drive API settings.\n  \n      <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_google_drive_result.jpg\" alt=\"Google Cloud Console\" width=\"30%\"/>\n      <img style=\"padding-right: 2%; padding-top: 2%; padding-bottom: 2%;\" src=\"../../../docs/images/firebase_google_drive_enable_api.jpg\" alt=\"Google Cloud Console\" width=\"30%\"/>\n\n### Troubleshooting\n\nHere are some common issues that may occur during the Firebase configuration process and their corresponding solutions.\n\n```bash\n  1. Invalid Credentials error: Inspect the browser console for any error messages or warnings related to Invalid Credentials.\n```\n\n- Verify that you have entered the correct client ID and API key in the Firebase Console.\n- Double-check that there are no typos or errors in the values entered in environment variables.\n- Make sure you have enabled the configuration settings properly when calling the firebase.auth().signInWithPopup()\n  function.\n- Ensure that you have specified correct firebase SDK version, and you are signing in with the valid Google account.\n\n```bash\n  2.  User account disabled error.\n```\n\n- The only way to fix this issue is to reactivate the existing account or create a new one.\n- Additionally, you can check if account has been disabled or deleted before attempting to authenticate them with\n  Firebase Google Sign-in, and display an error message if account is not active.\n\n```bash\n  3.  Cross-Origin Resource Sharing (CORS) error: If you notice that expected behavior of the web application is not occurring, such as data not being loaded or displayed correctly.\n```\n\n- Go to the Firebase Console, in the Authentication section select the \"Sign-in method\" tab. Under the \"Authorized\n  domains\" section, make sure that your web application domain is added and that CORS is enabled for it.\n- If you are using a server-side authentication flow, make sure that you have added the necessary CORS headers to your\n  server response to allow requests from your web application domain.\n- If you are hosting your web application on Firebase Hosting, it automatically enables CORS for your domain. You can\n  also use Firebase Cloud Run to serve API requests with CORS headers included. \n\n\n\n\n\n\n\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/open-code/README.md": {
    "summary": "**OpenBot Playground** is a drag-and-drop platform that empowers users to create instructions for OpenBot robots without coding.\n\n**Features:**\n\n* Sync with Google Drive for automatic data storage.\n* Store data locally for offline access.\n* Scan QR codes to run programs directly on OpenBot apps.\n* Design instructions with zero code.\n* Fully responsive design for mobile and tablet optimization.\n\n**Key Components:**\n\n**Header:**\n* Theme switching (light/dark modes)\n* Sign-in and user profile options\n\n**Carousal:**\n* Explains how the playground works\n\n**Project Section:**\n* Lists user projects stored on Google Drive and local storage\n\n**Playground Page:**\n\n**Workspace:**\n* Drag-and-drop blocks for code generation (JavaScript and Python)\n\n**Playground Bottom Bar:**\n\n* Generate QR code for program sharing and execution on OpenBot apps\n* Upload project code and XML configuration to Google Drive\n* Code editor for language selection (JavaScript/Python)\n* Model integration for AI functionality",
    "content": "<img src=\"../docs/images/playground_banner.png\" alt=\"banner\">\n\n# OpenBot Playground\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nOpenBot Playground is a drag and drop platform to support OpenBot application, where anyone can build instructions for\nthe robot.\n\n## Getting Started\n\nYou can run this application directly from the [Link](https://www.playground.openbot.org/ \"Link\").\n\nYou can also run it locally via creating a local copy of the project. To achieve this, navigate into\nthe `openBot/open-code` folder, [set firebase project](src/services/README.md) and run application.\nAfter [firebase setup](src/services/README.md) run following commands:\n\nIf you're using npm\n\n```bash\nnpm install\n```\n\nIn case of yarn\n\n```bash\nyarn install\n```\n\nRun application\n\n```bash\nnpm start\n```\n\n### Application Features\n\n1. Sync your Google Drive with the OpenBot, and it will automatically save the data on it.\n2. Store the data into local storage.\n3. Scan the output QR directly from the OpenBot application to run the program.\n4. In OpenBot mobile apps, after logging in, you can retrieve the saved files from Google Drive and load them with just\n   one click.\n5. Design the instructions for OpenBot with zero code.\n6. Fully responsive design optimized for mobile and tablet browsing.\n\n### Project Storage\n\nThis project allows users to store their data both locally and on `Google Drive`. When the project is created, it is\nautomatically stored in the `local storage` of the user's device. As changes are made to the project, the local storage\nis updated in real-time.\n\nAdditionally, users can upload their project to Google Drive by clicking on the [upload button](#generate-Code). This\nallows users to access their project from any device with internet access, making it easier to work on the project from\ndifferent locations.\n\n- #### Local Storage\n  Local storage is a built-in web technology that allows web applications to store data locally within the user's\n  browser. This means that the project is stored on the user's device and can be accessed without an internet\n  connection.\n\n  In this project, the local storage is used to store the project whenever changes are made to it. The project is stored\n  in the browser's cache, which means that it will persist even if the user closes the tab or the browser.\n\n- #### Google Drive Storage\n  Google Drive is a cloud-based storage service provided by Google. It allows users to store and share files online, as\n  well as access them from any device with internet access.\n\n  In this project, users can upload their project to Google Drive by clicking on the upload icon when they are signed in\n  to the website. The project is then stored on the user's Google Drive account, which means that it can be accessed\n  from any device with internet access.\n\n  To access their project from Google Drive, users can simply log in to their Google account and navigate\n  to [my projects](#project-section), where all their stored projects will be displayed.\n\n## OpenBot Playground Screens\n\n### Home Page\n\nThe `OpenBot Playground` starts with homepage that contains following component:\n\n- [Header](#header) : Header contains the following two sections, change theme and sign-in user.\n- [Carousel](#Carousal):Carousal's Content Explains how the Playground works.\n- [Project Section](#project-section) :Project section contains List of Projects and Create new Project button.\n\n### Playground Page\n\nThe `Playground` page is a key feature of the `OpenBot Playground` platform that provides a variety of coding blocks for\nusers to create different types of functionality, such as Control, Loops, Movement, Operators, Sensors, and many more.\n\n- [Header](#header) : Header contains project name, help centre, AutoSync ,change theme and signIn user section.\n- [Workspace](#workSpace): Space where users can drag and drop the coding blocks to generate their code, which can be\n  converted into both JavaScript and Python.\n- [Playground Bottom Bar](#Playground-Bottom-Bar) : Bottom bar Contains buttons to generate code ,upload project in\n  drive, zoom in and out blocks ,Add model ,undo and redo changes in workspace.\n\n### Header\n\nThe header of the `Openbot-Playground` website has its logo in the top left section. The right side of the header have\ntwo buttons.\n\n- #### Change theme\n  Theme icon allows you to switch between light mode and dark mode, and vice versa.\n\n  <p align=\"left\">\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_home_light_theme_screen.jpg\" alt=\"light theme screen\" width=\"45%\"/>\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_home_dark_theme_screen.jpg\" alt=\"dark theme screen\" width=\"45%\"/>\n  </p>\n\n- #### Sign-in\n\n  The \"Sign-in\" button opens a Google sign-in popup on the screen and prompts you to enter your email for login, with\n  all necessary permissions granted, including modifying ***Google Drive***.\n  <p align=\"left\">\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_sign-in.gif\" alt=\"Playground Sign In\" width=\"60%\" height=\"20%\"/>\n  </p>\n\n- #### Profile Options\n  Upon successful sign-in, you will have options to edit your profile and log out. The \"Edit Profile\" button opens a\n  popup where you can update your profile image, display name and date of birth.\n  <p align=\"left\">\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_edit_profile_logout_popup.jpg\" alt=\"Playground Sign In\" width=\"45%\"/>\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_edit_profile_modal.jpg\" alt=\"Playground Sign In\" width=\"45%\" />\n  </p>\n\n- #### AutoSync:\n    - AutoSync enables users to seamlessly synchronize all machine learning models (Tflite models), from the OpenBot\n      robot app and conveniently display them in their respective ``Artificial Intelligence`` blocks. Additionally,\n      users have the flexibility to select the desired AI model directly within the block interface while structuring\n      the code.\n    - #### How it works\n        - The robot app uploads an updated config.json file to the user's Google Drive, including any newly added\n          models. This file lists all the models along with their configurations in JSON format.\n        - When the user clicks on ``Auto Sync`` all downloaded models, including those for detection, autopilot, and\n          point goal navigation, are filtered and displayed in their respective AI blocks.\n        - Following this process, the model will then appear within the OpenBot playground blocks. With the assistance\n          of\n          Google Drive, you can seamlessly select this model directly from the respective AI blocks.\n\n- #### Playground page additional\n\n    - The Playground page header retains the same design as the homepage header, while incorporating additional\n      functionalities. In the center, the project name is displayed with a downward arrow, providing options for\n      renaming and deleting the project.\n       <p align=\"left\">\n       <img style=\"padding-right: 2%;margin-top: 2%\" src=\"../docs/images/playground_workspace_rename.jpg\" alt=\"Playground Sign In\" width=\"50%\" height=\"50%\" />\n       </p>\n\n    - On the right side, a help button has been added, featuring three sections that explain how to effectively\n      drag and drop blocks, save and download project progress, and upload to drive for seamless collaboration.\n\n        <p align=\"left\">\n        <img style=\"padding-right: 2%;margin-top: 2%\" src=\"../docs/images/playground_help.jpg\" alt=\"Playground Help\" width=\"50%\"/>\n        </p>\n\n### Carousal\n\nCarousal's container explains how Application works.\n<p>\n<img style=\"padding-right: 2%;\" src=\"../docs/images/playground_home_carousal1.jpg\" alt=\"home_carousal1\" width=\"30%\"/>\n<img style=\"padding-right: 2%;\" src=\"../docs/images/playground_home_carousal2.jpg\" alt=\"home_carousal2\" width=\"30%\"/>\n<img style=\"padding-right: 2%;\" src=\"../docs/images/playground_home_carousal3.jpg\" alt=\"home_carousal3\" width=\"30%\"/>\n</p>\n\n### Project Section\n\nThe 'My Projects' section display the projects stored in local storage and Google Drive (if the user is signed in), with\neach project showing its name, creation/edit date, and previous block versions. Clicking on a project redirects the user\nto its playground page. To create a new project, simply click on the `create icon`.\n\nClicking the 'Create' icon opens a 'Create New Project' popup with an input for the project name and a 'Create' button.\nOnce a suitable name is entered and the 'Create' button or enter is pressed, the project's playground screen will open.\nIf the user enters a name already assigned to another project, the system will automatically generate a unique name by\nappending an integer to the end of the name.\n\n<p align=\"left\">\n<img style=\"padding-right: 2%;\" src=\"../docs/images/playground_create_new_project.jpg\" alt=\"Create New Project\" width=\"30%\"/>\n<img style=\"padding-right: 2%;\" src=\"../docs/images/playground_my_project.jpg\" alt=\"my Project\" width=\"30%\"/>\n<img style=\"padding-right: 2%;\" src=\"../docs/images/playground_my_project_option.jpg\" alt=\"option\" width=\"30%\"/>\n</p>\n\n### WorkSpace\n\nTo generate code, users can drag and drop coding blocks into the workspace. The code can be converted into both\nJavaScript and Python.\n\n- Blocks can be selected from the left section and dropped into the workspace as needed.\n- To delete a block, users can simply drag it to the trash icon located in the bottom right corner.\n- If a block does not fit into the \"Start\" or \"Forever\" block, it will be disabled to prevent errors in the generated\n  code.\n- Users can restore a deleted block from the trash by clicking on it, which will display a list of deleted blocks.\n  They can then drag and drop the desired block from the trash back into the workspace.\n- Know More About Blocks: [Blocks](src/components/blockly/README.md)\n  <p align=\"left\">\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_workspace.gif\" alt=\"Create New Project\" width=\"50%\"/>\n  </p>\n\n### Playground Bottom Bar\n\n- To ensure a successful web experience of the openBot-PlayGround using Google Drive, users should fulfill the following\n  conditions:\n    - User should not have any other folder in their Google Drive with the same name as the website generated\n      openBot-PlayGround folder.\n    - User should not create same name file in openBot-PlayGround folder.\n  <p align=\"left\">\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_google_drive_folder.jpg\" alt=\"Generate Code\" width=\"25%\" />\n    <p></p>\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_drive.jpg\" alt=\"Generate Code\" width=\"45%\"/>\n\n- #### Generate Code\n  Generate Code button on the Playground bottom bar serves three important functions. Firstly, it generates a QR code\n  that represents the link of the JavaScript/Python file uploaded to the user's Google Drive as part of the project. This QR\n  code is displayed in a side window for easy access and sharing. Secondly, the button uploads a JavaScript/Python\n  file containing the code for the project to the user's Google Drive. And lastly, uploading an XML file which\n  represents the current project's block configuration. This XML file contains the structure and arrangement of the blocks used in the\n  project.\n\n    - `Convenient Sharing` -\n      The QR code generated by the button provides a public shareable link to the JavaScript/Python file on Google\n      Drive.\n      This link can be accessed by scanning the QR code using the OpenBot IOS/Android app. This allows users to run the\n      car\n      based on the code generated using the coding blocks directly from their mobile device. The ability to share the QR\n      code and access the code on mobile devices adds another level of convenience and accessibility to the openBot\n      playground.\n      The integration with Google Drive allows you to have a comprehensive backup of their project. By including the XML\n      file, the exact structure and logic of the blocks used in the project are preserved. This is beneficial for you to\n      share,\n      collaborate, and revisiting projects in the future.\n\n  <br></br>\n  Here is an upload in Drive and generate Code Demo :\n  <p align=\"left\">\n  <img style=\"padding-right: 2%;\" src=\"../docs/images/playground_google_drive.gif\" alt=\"Generate Code\" width=\"50%\"/>\n  </p>\n\n- #### Code Editor\n  Code editor button on right side of generate QR button, opens a side window displaying block code in a scripting\n  language. The button provides options to choose between two languages, either JavaScript or Python, and once selected,\n  users can only view their code snippets in the side window. They can toggle between JavaScript and Python to see the\n  corresponding code in the side window simultaneously. The options to choose a language enables you to examine and\n  evaluate the correctness of the blocks.\n  <p align=\"left\">\n  <img style=\"padding-right: 2%;margin-top: 2%\" src=\"../docs/images/playground_code_editor.jpg\" alt=\"Playground code editor\" width=\"50%\" height=\"50%\" />\n  </p>\n\n- #### Add Model\n  The OpenBot playground provides a feature to externally add AI model (.tflite) to robot application. The model popup\n  allows user to edit the configuration of our model, including its name, type, class, and input size. Note that the\n  model will\n  automatically saved in the user's Google Drive, along with the updated config.json file.\n  <p align=\"left\">\n  <img style=\"padding-right: 2%;margin-top: 2%\" src=\"../docs/images/playground_workspace_model_option.jpg\" alt=\"Playground code editor\" width=\"40%\" height=\"50%\" />\n  <img style=\"padding-right: 2%;margin-top: 2%\" src=\"../docs/images/playground_workspace_model_popup.jpg\" alt=\"Playground code editor\" width=\"40%\" height=\"50%\" />\n  </p>\n\n\n- #### WorkSpace Controller\n  The undo and redo button helps to do undo redo functionalities in the playground. The plus icon is for zoom-in and the\n  minus icon is for zoom-out.\n\n## Next(optional)\n\nFirebase Authentication troubleshooting [Firebase](src/services/README.md#troubleshooting)\n\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/policy/frontend/README.md": {
    "summary": "OpenBot Policy Frontend is a React app bootstrapped with Create React App. It supports multiple languages. The available scripts are:\n\n* `yarn start`: Runs the app in development mode.\n* `yarn test`: Launches the interactive test runner.\n* `yarn build`: Builds the app for production, optimizing performance and minifying the build.",
    "content": "# OpenBot Policy Frontend\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nThis project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).\n\n## Available Scripts\n\nIn the project directory, you can run:\n\n### `yarn start`\n\nRuns the app in the development mode.\\\nOpen [http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nThe page will reload if you make edits.\\\nYou will also see any lint errors in the console.\n\n### `yarn test`\n\nLaunches the test runner in the interactive watch mode.\\\nSee the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.\n\n### `yarn build`\n\nBuilds the app for production to the `build` folder.\\\nIt correctly bundles React in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.\\\nYour app is ready to be deployed!\n\nSee the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/policy/README.md": {
    "summary": "**Driving Policy Training for Advanced Users**\n\n**Disclaimer:** Safety is crucial. Operate in a secure environment and keep a game controller connected for manual control. Training requires substantial computing resources.\n\n**Dependencies:**\n- Install the OpenBot environment with conda.\n- Ensure GPU support is enabled (if available).\n\n**Dataset:**\n- Collect driving data using a Bluetooth game controller.\n- Store data in folders with a specific structure.\n- Optionally, convert data into TFRecord for better training efficiency.\n\n**Policy Training:**\n- Use the provided Jupyter Notebook or train via shell commands.\n- Adjust hyperparameters as needed.\n- Large batch sizes and longer training epochs are beneficial for deployment models.\n\n**Deployment:**\n- Replace the default TFlite model in Android Studio with the trained model (autopilot_float.tflite).\n\n**Web App:**\n- (Beta) Provides an easy way to upload logs, preview data, and train models with basic parameters.\n- Run the Python web server (`python -m openbot.server`) to access the app.",
    "content": "\n# Driving Policy (Advanced)\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\n## DISCLAIMERS\n\n1. **Safety:** Driving policies are not perfect and may crash the robot. Always make sure you operate in a safe environment! Keep in mind, that your phone could be damaged in a collision! Make sure you always have a game controller connected and are familiar with the key mapping so you can stop the vehicle at any time. Use at your own risk!\n2. **Compute hardware:** Training a driving policy requires a lot of resources and may slow down or even freeze your machine. It is recommended to use a high-end laptop or workstation with large amount of RAM and dedicated GPU, especially when training with larger batch sizes. The documentation is currently also not very detailed. Use at your own risk!\n3. **Patience required:** To get a good driving policy for your custom dataset will require some patience. It is not straight-forward, involves data collection, hyperparameter tuning, etc. If you have never trained machine learning models before, it will be challenging and may even get frustrating.\n\nYou first need to setup your training environment.\n\n## Dependencies\n\nWe recommend to create a conda environment for OpenBot. Instructions on installing conda can be found [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/). The easiest way to create a new environment with all dependencies is to use one of the provided environment files. On Windows, you will also need to install [Microsoft C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/). Make sure you are in the folder `policy` within your local OpenBot repository. Based on your operating system, run the corresponding command:\n\n- **MacOS**: `conda env create -f environment_mac.yml`\n- **Windows**: `conda env create -f environment_win.yml`\n- **Linux**: `conda env create -f environment_linux.yml`\n\nFor GPU support, make sure you also have the appropriate drivers installed. On Mac and Windows, everything should work out of the box. On Linux, you can install the drivers with the following command:\n```\nsudo apt-get install nvidia-driver-510\n```\nOn Linux, you will probably also need to run the following to add cuda and cudnn to your path:\n```\necho 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/' >> ~/.bashrc\nsource ~/.bashrc\n```\n\nDone! You are ready to train your own models. If this doesn't work for you, below are instructions for setting up such an environment manually. \n\n### Manual environment setup\n\nFirst create a new conda environment with the following command:\n\n```bash\nconda create -n openbot pip python=3.9 -y\n```\n\nNext, you need to activate your conda environment:\n\n```bash\nconda activate openbot\n```\n\nIf this does not work (e.g. on Windows), you may need to activate the environment with `activate openbot` instead.\n\nOnce the environment is active, you need to install tensorflow. Note that training will be very slow on a laptop. So if you have access to a computer with dedicated GPU, we highly recommend to use it by installing the neccessary libraries; make sure you have recent GPU drivers installed. Below are the commands to install tensorflow for different operating systems.\n\n#### **Mac OS**\n```\nconda install -c apple tensorflow-deps -y\npip install tensorflow-macos~=2.9.0\n```\nGPU support\n```\npip install tensorflow-metal~=0.5.0\n```\n[Troubleshooting](https://developer.apple.com/metal/tensorflow-plugin/)\n\n#### **Linux**\n```\npip install tensorflow~=2.9.0\n```\nGPU support\n```\nsudo apt-get install nvidia-driver-510\nconda install -c conda-forge cudatoolkit=11.2 cudnn=8.1 -y\necho 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/' >> ~/.bashrc\nsource ~/.bashrc\n```\n[Troubleshooting](https://www.tensorflow.org/install/pip#linux)\n\n#### **Windows**\n```\npip install tensorflow~=2.9.0\n```\nGPU support\n```\nconda install cudatoolkit=11.3 cudnn=8.2 -y\n```\n\n#### **Additional requirements**\n\nMake sure you are in the folder `policy` within your local OpenBot repository. Now, you can install all the remaining dependencies with the following command:\n\n```bash\npip install -r requirements.txt\n```\n\nYou can also install pydot (`pip install pydot`) and graphviz ([see instructions](https://graphviz.gitlab.io/download/)) if you want to visualize the the network architecture.\n\nIf you want to use the [WebApp](#web-app) for data collection and training, you need to install the following dependencies in addition. (On Mac, the `brotlipy` package is currently broken on pip, so you need to install it first using conda: `conda install brotlipy=0.7`)\n\n```bash\npip install -r requirements_web.txt\n```\n\n### Essential packages\n\nFor reference and troubleshooting, below is a list of the essential packages.\n\nTraining:\n\n- [tensorflow](https://pypi.org/project/tensorflow/)\n- [jupyter notebook](https://pypi.org/project/notebook/)\n- [matplotlib](https://pypi.org/project/matplotlib/)\n- [numpy](https://pypi.org/project/numpy/)\n- [PIL](https://pypi.org/project/Pillow/)\n- [black[jupyter]](https://pypi.org/project/black/)\n\nWeb interface:\n\n- [aiohttp](https://pypi.org/project/aiohttp/)\n- [aiozeroconf](https://pypi.org/project/aiozeroconf/)\n- [imageio](https://pypi.org/project/imageio/)\n\n### Notes\n\n- Remember to activate the environment before running commands in the terminal: `conda activate openbot`\n- If your tensorflow import does not work, try installing via `pip install tensorflow --user`. (See this [issue](https://github.com/intel-isl/OpenBot/issues/98).)\n\n## Dataset\n\n### Data Collection\n\nIn order to train an autonomous driving policy, you will first need to collect a dataset. The more data you collect, the better the resulting driving policy. For the experiments in our paper, we collected about 30 minutes worth of data. Note that the network will imitate your driving behaviour. The better and more consistent you drive, the better the network will learn to drive.\n\n1. Connect a bluetooth game controller to the phone (e.g. PS4 controller: to enter pairing mode press the PS and share buttons until the LED flashes quickly).\n2. Select the `CIL-Mobile-Cmd` model in the app.\n3. Now drive drive the car via a game controller and record a dataset. On the PS4 controller logging can be toggled with the **X** button.\n\nYou will now find a folder called *Documents/OpenBot* in the internal storage of your smartphone. For each recording, there will be zip file. The name of the zip file will be in the format *yyyymmdd_hhmmss.zip* corresponding to the timestamp of when the recording was started.\n\nThe Jupyter notebook expects a folder called `dataset` in the same folder. In this folder, there should be two subfolders, `train_data` and `test_data`. The training data is used to learn the driving policy. The test data is used to validate the learned driving policy on unseen data during the training process. This provides some indication how well this policy will work on the robot. Even though the robot may drive along the same route as seen during training, the exact images observed will be slightly different in every run. The common split is 80% training data and 20% test data. Inside the `train_data` and `test_data` folders, you need to make a folder for each recording session and give it a name such as `my_openbot_1`, `my_openbot_2`, etc. The idea here is that each recording session may have different lighting conditions, a different robot, a different route. In the Jupyter notebook, you can then train only on a subset of these datasets or on all of them. Inside each recording session folder, you drop all the recordings from that recording session. Each recording corresponds to an extracted zip file that you have transferred from the *Openbot* folder on your phone. Your dataset folder should look like this:\n\n<img src=\"../docs/images/folder_structure.png\" width=\"200\" alt=\"folder structure\" />\n\nRather than copying all files manually from the phone, you can also upload the logs automatically to a [Python server](#web-app) on your computer. In this case, the zip files will be uploaded and unpacked into the folder `dataset/uploaded`. You will still need to move them into the folder structure for training. You can simply treat the `uploaded` folder as a recording session and move it into `train_data`. The recordings will then be recognized as training data by the Jupyter notebook. If you do not already have a recording session in the `test_data` folder, you also need to move at least one recording from `train_data/uploaded` into `test_data/uploaded`.\n\n### Data Conversion (optional)\n\nFor better training performance, you can convert the collected dataset into a specialized format. You can create a tfrecord of the train and test datasets with the following commands:\n\n```bash\nconda activate openbot\npython -m openbot.tfrecord -i dataset/train_data -o dataset/tfrecords -n train.tfrec\npython -m openbot.tfrecord -i dataset/test_data -o dataset/tfrecords -n test.tfrec\n```\n\nBy default this conversion will be done automatically at the start of training.\n\n## Policy Training\n\nMake sure your conda environment for openbot is activated by executing the following command:\n\n```bash\nconda activate openbot\n```\n\n### Jupyter Notebook\n\nWe provide a [Jupyter Notebook](policy_learning.ipynb) that guides you through the steps for training an autonomous driving policy. Open the notebook with the following command.\n\n```bash\njupyter notebook policy_learning.ipynb\n```\n\nNow a web-browser window will open automatically and load the Jupyter notebook. Follow the steps in order to train a model with your own data.\n\n### Shell\n\nThis method assumes that the data is in the correct place. To adjust the hyperparameters you can pass the following arguments.\n\n```bash\n'--no_tf_record', action='store_true', help='do not load a tfrecord but a directory of files'\n'--create_tf_record', action='store_true', help='create a new tfrecord'\n'--model', type=str, default='pilot_net', choices=['cil_mobile', 'cil_mobile_fast', 'cil', 'pilot_net'], help='network architecture (default: cil_mobile)'\n'--batch_size', type=int, default=16, help='number of training epochs (default: 16)'\n'--learning_rate', type=float, default=0.0001, help='learning rate (default: 0.0001)'\n'--num_epochs', type=int, default=10, help='number of epochs (default: 10)'\n'--batch_norm', action='store_true', help='use batch norm'\n'--flip_aug', action='store_true', help='randomly flip images and controls for augmentation'\n'--cmd_aug', action='store_true', help='add noise to command input for augmentation'\n'--resume', action='store_true', help='resume previous training'\n```\n\nIf your dataset has already been converted to a tfrecord, you can train the policy from the shell with the command:\n\n```bash\npython -m openbot.train\n```\n\nIf you would like to convert your dataset to a tfrecord, before training, you need to add the following flag:\n\n```bash\npython -m openbot.train --create_tf_record\n```\n\nIf you do not want to convert the dataset to a tfrecord, and train using the files direclty, you need to add the following flag:\n\n```bash\npython -m openbot.train --no_tf_record\n```\n\nTo train a model for final deployment, you want to use a large batch size and number of epochs. Enabling batch norm usually improves training as well. The model `pilot_net` is larger than the default `cil_mobile` but can achieve better performance on some tasks while still runnining in real time on most smartphones.\n\n```bash\npython -m openbot.train --model pilot_net --batch_size 128 --num_epochs 100 --batch_norm\n```\n\n### Deployment\n\nAt the end of the training process, two tflite files are generated: one corresponds to the best checkpoint according to the validation metrics and the other to the last checkpoint. Pick one of them and rename it to autopilot_float.tflite. Replace the existing model in Android Studio and recompile the app.\n\n<p align=\"center\">\n  <img src=\"../docs/images/android_studio_tflite_dir.jpg\" width=\"200\" alt=\"App GUI\" />\n</p>\n\nIf you are looking for the folder in your local directory, you will find it at: `app/src/main/assets/networks`.\n\n## Web App\n\nWe provide a web app and a python web server for easy policy training. (Beta)\n\n### Features\n\n- Automatic log (session) upload \n  - see Troubleshooting for details\n- List uploaded sessions, with GIF preview \n- List datasets, with basic info\n- Move session to a dataset\n- Delete session\n- List trained models, and show plots about training\n- Train a model with basic parameters, show progress bar\n\n### Preview\n\n<img src=\"../docs/images/web-app.gif\" width=\"100%\" alt=\"Web App preview\" />\n\n### Quickstart\n\n```bash\nconda activate openbot\npython -m openbot.server\n```\n\nYou can now open your browser to visualize the dataset and see incoming uploads by going to:\n[http://localhost:8000/#/uploaded](http://localhost:8000/#/uploaded)\n\n### Running the server\n\nYou can run the python server with the command:\n\n```bash\npython -m openbot.server\n```\n\nThere is also a developer mode:\n\n```bash\nadev runserver openbot/server\n```\n\nFor frontend development (react app):\n\n```\nFE_DEV=1 adev runserver openbot/server\n```\n\nWhen you run the server you should see something like:\n\n```\nSkip address 127.0.0.1 @ interface lo\nFound address 192.168.x.x @ interface wlp2s0\nRegistration of a service, press Ctrl-C to exit...\nRunning frontend: 0.7.0\nFrontend path: /home/USERNAME/miniconda3/envs/openbot/lib/python3.7/site-packages/openbot_frontend\n======== Running on http://0.0.0.0:8000 ========\n(Press CTRL+C to quit)\n```\n\n### Troubleshooting\n\nIf the upload to the server is not working, here are some troubleshooting tips:\n\n- Try restarting the server (computer) and the OpenBot app (smartphone)\n- Make sure the smartphone and your computer are connected to the same WiFi network\n- If your router has both 2.4 GHz and 5 GHz networks with the same name, disable the 5 GHz network\n- Keep the phone connected to Android Studio while running the app. In the Logcat tab, select Debug from the dropdown. Type `NSD` into the filter field to see the debug messages concerning the server connection. Type `Upload` into the filter field for debug messages concerning the recording file upload.\n- If a published models gets downloaded continiously, make sure the time on your phone and laptop / workstation are set correctly\n"
  },
  "https://github.com/ob-f/OpenBot/blob/master/python/README.md": {
    "summary": "This Python module is an alternative control system for the OpenBot vehicle. It allows you to control the robot using a computer and a Realsense D435i camera. The robot can be controlled through inference from a trained Neural Network policy or via joystick. The module includes testing and example code to demonstrate its functionality. Installation requires setting up Python modules, drivers, and potentially modifying the PYTHONPATH variable for TensorFlow inference.",
    "content": "# Python\n\n<p align=\"center\">\n  <span>English</span> |\n  <a href=\"README.zh-CN.md\">ç®€ä½“ä¸­æ–‡</a> |\n  <a href=\"README.de-DE.md\">Deutsch</a> |\n  <a href=\"README.fr-FR.md\">FranÃ§ais</a> |\n  <a href=\"README.es-ES.md\">EspaÃ±ol</a> |\n  <a href=\"README.ko-KR.md\">í•œêµ­ì–´</a>\n</p>\n\nThis module is an embedded Linux alternative to the smartphone control of an OpenBot vehicle. Written in Python, the OpenBot can be controlled using a linux-based computer and a camera for sensing.\n\nThe robot can be controlled in two ways: through inference of a Neural Network policy or via joystick.\n\n```\nâ”œâ”€â”€ __init__.py\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ requirements.txt\nâ”œâ”€â”€ run.py\nâ”œâ”€â”€ generate_data_for_training.py\nâ”œâ”€â”€ export_openvino.py\nâ”œâ”€â”€ infer.py\nâ”œâ”€â”€ joystick.py\nâ”œâ”€â”€ realsense.py\nâ””â”€â”€ tests\n    â”œâ”€â”€ test_data\n    â”‚Â Â  â””â”€â”€ logs1\n    â”‚Â Â      â””â”€â”€ ...\n    â”œâ”€â”€ test_models\n    â”‚Â Â  â”œâ”€â”€ openvino\n    â”‚Â Â  â”œâ”€â”€ tflite\n    â”‚Â Â  â””â”€â”€ tf.zip\n    â”œâ”€â”€ test_export_openvino.py\n    â”œâ”€â”€ test_infer.py\n    â”œâ”€â”€ test_joystick.py\n    â”œâ”€â”€ test_motor.py\n    â””â”€â”€ test_realsense.py\n\n```\n## Running Robot\n\nTo operate the robot, run the `run.py`, which is the main Python script. The robot can be run in 3 modes:\n- Debug: This mode runs the policy off-line. I.e., instead of real camera images and joystick input commands, it uses data (command and images) loaded from a dataset (see `tests/test_data/logs1/data`) as input to the policy.\n- Inference: This mode runs the policy on-line. It uses real camera images and joystick input commands as input to the policy. This mode can be toggled to Joystick mode by pressing the `A` key on the joystick.\n- Joystick: This mode operates the robot via joystick command in either \"Dual\" (controlling left and right wheel via left and right joystick) or \"Joystick\" (controlling forward, backward, left, right direction via one joystick) `control_mode`. Data collection for training is conducted in Joystick mode. This mode can be toggled to Inference mode by pressing the `A` key on the joystick.\n\nThe run.py script accepts six arguments (further details, see `run.py`):\n```\n--policy_path: Path to policy file.\n--dataset_path: Path to dataset. Only used for debug mode.\n--log_path: Path to log folder, where runs are saved.\n--inference_backend: Backend to use. Consider exporting all models as openvino model for maximum performance. Options: tf, tflite, openvino.\n--mode: Running mode. Options: debug, inference, joystick.\n--control_mode: Control mode during joystick mode. Options: dual, joystick.\n```\n## Generating Training Data\nThe script `generate_data_for_training.py` generates a log data folder that is required for training a policy via the `OpenBot/policy/openbot/train.py` script. The log data folder contains an `images` and a `sensor_data` folder in the format required by `train.py`.\n\nSee `tests/test_generate_data.py` for an example.\n\n## OpenVino: Optimising Policy Inference Performance\nTo optimise the inference speed on supported Intel hardware (such as the [Up Core Plus](https://up-board.org/upcoreplus/specifications/) board), the trained model needs to be exported to OpenVino.\n\nThe `export_openvino.py` script exports a trained TensorFlow model to an OpenVino model. This OpenVino model is then loaded via `get_openvino_interpreter()` in `infer.py`.\n\nSee `tests/test_export_openvino.py` for an example.\n\n## Tests and example code\n\n**Note:** For testing the code, the test data and test model called `test_data` and `test_model` respectively are required to be in `OpenBot/python/tests`. The function `get_data()` in `download_data.py` provides download functionality and is called at the beginning of `test_infer.py`, `test_export_openvino.py`, and `test_generate_data.py`. Alternatively,\n please run the script `get_test_data.sh` (unix systems only) that downloads and unzips a zip file containing `test_data` and `test_models` with the data for debug mode and models for inference respectively.\n\nRun `pytest` in the folder `tests` or run the `test_*.py` files individually to test the functionalities of\n\n- downloading test data and test model from the cloud via `test_download_data.py`\n- export to OpenVino via `test_export_openvino.py`\n- generating training data via `test_generate_data.py`.\n- inference in debug mode for OpenVino, Tensorflow, and Tflite via `test_infer.py`.\n    - *Note*: The test data in logs1 is generated using the `associate_frames.py` script in `OpenBot.policy.openbot`, where the path to the images is hardcoded in `logs1/data/sensor_data/matched_frame_ctrl_cmd_processed.txt`.\n    - Thus, please replace the `path_to_openbot` with the actual path to the `OpenBot` repository in `test_infer.py`.\n- joystick connection via `test_joystick.py`\n- motor connection from serial port to Arduino via `test_motor.py`.\n- video stream to Realsense camera via `test_realsense.py`.\n\n# Installation\nThe installation process is detailed in the following.\n\nThe python implementation for controlling OpenBot requires a few Python modules for inference, joystick control, sensing, and actuation.\nFurther, drivers for the camera or controller might be required.\n\n## Setup\nCurrently, the code is tested on:\n- Board: [Up Core Plus](https://up-board.org/upcoreplus/specifications/)\n- Camera: [Realsense D435i](https://www.intelrealsense.com/depth-camera-d435i/)\n- Controller: [Xbox One](https://www.microsoft.com/en-gb/store/collections/xboxcontrollers?source=lp)\n- Arduino: [OpenBot Firmware](https://github.com/isl-org/OpenBot/blob/master/firmware/README.md)\n\n## Python modules\n\nThe code is tested with Python 3.9. Using Anaconda3:\n```\nconda create --name openbot python==3.9\n```\n\nFirst, install the requirements of OpenBot.policy via\n```\n../policy && pip install -r requirements.txt\n```\n\nThen, install the required modules via\n```\npip install -r requirements.txt\n```\n\nIn particular,\n- `pyserial` communicates with the Arduino and thus motors via serial port\n- `pyrealsense2` and `opencv-python` are required for camera image processing.\n- `pygame` is used for joystick control and processing the joystick inputs\n- `openvino-dev[tensorflow2,extras]` is used for boosted performance on supported Intel hardware. For further details on optimised AI inference on Intel hardware, please see [OpenVino](https://docs.openvino.ai/latest/home.html). OpenVino is the recommended inference backend. Tensorflow and Tflite are also supported (see Tests). For running PyTorch modules, please consider converting PyTorch to an OpenVino backend (see [this Tutorial](https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_PyTorch.html)).\n\n## Drivers\nIf the code is executed on Ubuntu, the Xbox One controller USB Wireless Dongle requires a driver, which can be found at [this link](https://github.com/medusalix/xone).\n\n## Tensorflow for Inference\nIf TensorFlow is used for inference, please add the Python `policy` module to `PYTHONPATH` via `export PYTHONPATH=$PYTHONPATH:/path/to/OpenBot/policy`. This workaround avoids having to install openbot as module and to find `openbot.utils.load_model()`, which is required to load the tensorflow model. Further details, see `get_tf_interpreter()` in `infer.py` and the test code `tests/test_infer.py`.\n\n## Support for non-linux distributions (MacOS, Windows)\n\nPlease note that the code is intended to run on Linux-based computers, e.g., Up Core Plus. Some python modules may not be available for MacOs or Windows.\n\nThe code can run on MacOS for debugging purposes with the following changes:\n- Use `pyrealsense2-macosx` instead of `pyrealsense2` in requirements.txt\n- For tflite follow [these instructions](https://github.com/milinddeore/TfLite-Standalone-build-Linux-MacOS)\n"
  }
}